<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>应用搭建案例 on FastGPT</title><link>https://doc.tryfastgpt.ai/docs/use-cases/app-cases/</link><description>Recent content in 应用搭建案例 on FastGPT</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><atom:link href="https://doc.tryfastgpt.ai/docs/use-cases/app-cases/index.xml" rel="self" type="application/rss+xml"/><item><title>如何提交应用模板</title><link>https://doc.tryfastgpt.ai/docs/use-cases/app-cases/submit_application_template/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/use-cases/app-cases/submit_application_template/</guid><description>什么模板可以合并 link目前合并进仓库的应用模板，会在「模板市场」中全部展示给用户。
为了控制模板的质量以及避免数量过多带来的繁琐，并不是所有的模板都会被合并到开源仓库中，你可以提前 PR 与我们沟通模板的内容。
预估最后总体的数量不会很多，控制在 50 个左右，一半来自 FastGPT Team，一半来自社区用户。
如何写一个应用模板 link 跑通 FastGPT dev 环境 link 需要在 dev 环境下执行下面的操作。
可参照 FastGPT｜快速开始本地开发
在 FastGPT 工作台中，创建一个应用 link 创建空白工作流即可。
创建应用模板 link 应用模板配置以及相关资源，都会在 packages/templates/src 目录下。
在packages/templates/src 目录下，创建一个文件夹，名称为模板对应的 id。 在刚刚创建的文件夹中，再创建一个 template.json 文件，复制粘贴并填写如下配置： { &amp;#34;name&amp;#34;: &amp;#34;模板名&amp;#34;, &amp;#34;intro&amp;#34;: &amp;#34;模板描述，会展示在模板市场的展示页&amp;#34;, &amp;#34;author&amp;#34;: &amp;#34;填写你的名字&amp;#34;, &amp;#34;avatar&amp;#34;: &amp;#34;模板头像，可以将图片文件放在同一个文件夹中，然后填写相应路径&amp;#34;, &amp;#34;tags&amp;#34;: [&amp;#34;模板标签&amp;#34;], // writing(文本创作)，image-generation(图片生成)，web-search(联网搜索), // roleplay(角色扮演), office-services(办公服务) 暂时分为 5 类，从中选择相应的标签 &amp;#34;type&amp;#34;: &amp;#34;模板类别&amp;#34;, // simple(简易应用), advanced(工作流), plugin(插件) &amp;#34;workflow&amp;#34;: { // 这个对象先不管，待会直接粘贴导出的工作流即可 &amp;#34;nodes&amp;#34;: [], &amp;#34;edges&amp;#34;: [], &amp;#34;chatConfig&amp;#34;: {} } } 完成应用编排并测试 link 完成应用编排后，可以点击右上角的发布。</description></item><item><title>长字幕翻译</title><link>https://doc.tryfastgpt.ai/docs/use-cases/app-cases/translate-subtitle-using-gpt/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/use-cases/app-cases/translate-subtitle-using-gpt/</guid><description>直接使用 LLM 来翻译长字幕会遇到很多难点，这些难点也正是直接使用 AI 无法有效处理的问题：
Tokens 限制：这是最明显的障碍。大语言模型 (LLM) 通常有输出 tokens 的限制，这意味着对于长文本，如果不使用特殊的工作流，可能需要手动将文本分段，逐段输入 AI 进行翻译，然后再手动拼接结果。这个过程不仅繁琐，还容易出错。
字幕格式的保持：对于字幕来说，时间轴信息至关重要。然而，AI 模型有时会产生 “幻觉”，即无中生有地修改或生成不存在的信息。在字幕翻译中，这可能导致 AI 错误地修改时间轴，使字幕与音频不同步。
翻译质量：简单的机器翻译往往无法满足观众的需求。即使是大语言模型，单轮翻译的质量也常常不尽如人意。对于字幕来说，翻译质量直接影响观看体验，糟糕的翻译会严重影响观众的沉浸感。
本案例将展示如何利用 FastGPT 工作流代码结合 LLM 来有效解决这些问题。我们的方法不仅能克服技术限制，还能显著提升翻译质量。
提取字幕信息 link工作流的一大优势在于可以结合额外的操作，使 AI 能更精准地处理信息。在字幕翻译中，我们可以先分离 SRT 字幕文件的各个组成部分，然后只让 LLM 翻译文本部分。这种方法既节约了 token 使用，又确保了时间轴信息不被误改。
具体实现如下：
使用代码执行模块，对输入的原始字幕文本进行解析。 将字幕信息分类为三部分：时间信息、序号信息和文本信息。 只保留文本信息用于后续的 AI 翻译。 这种预处理步骤大大提高了整个翻译过程的效率和准确性。
切分文本 link为了进一步优化翻译过程，我们需要将提取出的文本信息重新组织。这一步的目的是将文本分割成适合 LLM 处理的大小，同时保持上下文的连贯性。
在本例中，我们采用以下策略：
将文本按照每 40 句为一组进行切分。这个数字是经过多次测试后得出的平衡点，既能保证翻译质量，又不会超出 LLM 的处理能力。 使用 标签分割每句文本。这种标记方法便于后续的重新组装，同时也为 AI 模型提供了清晰的句子边界。 这种切分方法既考虑了 AI 模型的能力限制，又保证了翻译的连贯性。通过保持适当的上下文，我们可以得到更加准确和自然的翻译结果。
格式化原文本 link在这一步，我们构建了最终输入给 LLM 的原文本。这个步骤的关键在于如何在控制 tokens 数量的同时，为 AI 提供足够的上下文信息。我们采用了以下策略：
传入所有文本作为背景上下文。这确保 AI 能理解整段对话的语境。 使用&amp;lt;TRANSLATE_THIS&amp;gt;标签明确指出当前需要翻译的片段。这种方法既能控制 AI 的输出范围，又不会丢失整体语境。 这种格式化方法使得 AI 能在理解全局的基础上，专注于翻译特定部分，从而提高翻译的准确性和连贯性。</description></item><item><title>多轮翻译机器人</title><link>https://doc.tryfastgpt.ai/docs/use-cases/app-cases/multi_turn_translation_bot/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/use-cases/app-cases/multi_turn_translation_bot/</guid><description>吴恩达老师提出了一种反思翻译的大语言模型(LLM)翻译工作流程——GitHub - andrewyng/translation-agent，具体工作流程如下：
提示一个 LLM 将文本从 source_language 翻译到 target_language； 让 LLM 反思翻译结果并提出建设性的改进建议； 使用这些建议来改进翻译。 这个翻译流程应该是目前比较新的一种翻译方式，利用 LLM 对自己的翻译结果进行改进来获得较好的翻译效果
项目中展示了可以利用对长文本进行分片，然后分别进行反思翻译处理，以突破 LLM 对 tokens 数量的限制，真正实现长文本一键高效率高质量翻译。
项目还通过给大模型限定国家地区，已实现更精确的翻译，如美式英语、英式英语之分；同时提出一些可能能带来更好效果的优化，如对于一些 LLM 未曾训练到的术语（或有多种翻译方式的术语）建立术语表，进一步提升翻译的精确度等等
而这一切都能通过 Fastgpt 工作流轻松实现，本文将手把手教你如何复刻吴恩达老师的 translation-agent
单文本块反思翻译 link先从简单的开始，即不超出 LLM tokens 数量限制的单文本块翻译
初始翻译 link第一步先让 LLM 对源文本块进行初始翻译（翻译的提示词在源项目中都有）
通过文本拼接模块引用 源语言、目标语言、源文本这三个参数，生成提示词，传给 LLM，让它给出第一版的翻译
反思 link然后让 LLM 对第一步生成的初始翻译给出修改建议，称之为 反思
这时的提示词接收 5 个参数，源文本、初始翻译、源语言、目标语言 以及限定词地区国家，这样 LLM 会对前面生成的翻译提出相当多的修改建议，为后续的提升翻译作准备
提升翻译 link 在前文生成了初始翻译以及相应的反思后，将这二者输入给第三次 LLM 翻译，这样我们就能获得一个比较高质量的翻译结果
完整的工作流如下
运行效果 link由于考虑之后对这个反思翻译的复用，所以创建了一个插件，那么在下面我直接调用这个插件就能使用反思翻译，效果如下
随机挑选了一段哈利波特的文段
可以看到反思翻译后的效果还是好上不少的，其中反思的输出如下
长文反思翻译 link在掌握了对短文本块的反思翻译后，我们能轻松的通过分片和循环，实现对长文本也即多文本块的反思翻译
整体的逻辑是，首先对传入文本的 tokens数量做判断，如果不超过设置的 tokens 限制，那么直接调用单文本块反思翻译，如果超过设置的 tokens限制，那么切割为合理的大小，再分别进行对应的反思翻译处理
计算 tokens link 首先，我使用了 Laf函数 模块来实现对输入文本的 tokens 的计算</description></item><item><title>英语作文纠错机器人</title><link>https://doc.tryfastgpt.ai/docs/use-cases/app-cases/english_essay_correction_bot/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/use-cases/app-cases/english_essay_correction_bot/</guid><description>FastGPT 提供了一种基于 LLM Model 搭建应用的简便方式。
本文通过搭建一个英语作文纠错机器人，介绍一下如何使用 工作流
搭建过程 link1. 创建工作流 link 可以从 多轮翻译机器人 开始创建。
多轮翻译机器人是 @米开朗基杨 同学创建的，同样也是一个值得学习的工作流。
2. 获取输入，使用大模型进行分析 link我们期望让大模型处理文字，返回一个结构化的数据，由我们自己处理。
提示词 是最重要的一个参数，这里提供的提示词仅供参考：
## 角色 资深英语写作专家 ## 任务 对输入的原文进行分析。 找出其中的各种错误， 包括但不限于单词拼写错误、 语法错误等。 注意： 忽略标点符号前后空格的问题。 注意： 对于存在错误的句子， 提出修改建议是指指出这个句子中的具体部分， 然后提出将这一个部分修改替换为什么。 ## 输出格式 不要使用 Markdown 语法， 输入 JSON 格式的内容。 输出的&amp;#34;reason&amp;#34;的内容使用中文。 直接输出一个列表， 其成员为一个相同类型的对象， 定义如下 您正在找回 FastGPT 账号 ``` { “raw”: string; // 表示原文 “reason”: string; // 表示原因 “suggestion”: string; // 修改建议 } ``` 可以在模型选择的窗口中设置禁用 AI 回复。</description></item><item><title>固定开头和结尾内容</title><link>https://doc.tryfastgpt.ai/docs/use-cases/app-cases/fixingevidence/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/use-cases/app-cases/fixingevidence/</guid><description>如上图，可以通过指定回复编排一个固定的开头和结尾内容。
模块编排 link复制下面配置，点击「高级编排」右上角的导入按键，导入该配置。
编排配置 { &amp;#34;nodes&amp;#34;: [ { &amp;#34;nodeId&amp;#34;: &amp;#34;7z5g5h&amp;#34;, &amp;#34;name&amp;#34;: &amp;#34;流程开始&amp;#34;, &amp;#34;intro&amp;#34;: &amp;#34;&amp;#34;, &amp;#34;avatar&amp;#34;: &amp;#34;/imgs/workflow/userChatInput.svg&amp;#34;, &amp;#34;flowNodeType&amp;#34;: &amp;#34;workflowStart&amp;#34;, &amp;#34;position&amp;#34;: { &amp;#34;x&amp;#34;: -269.50851681351924, &amp;#34;y&amp;#34;: 1657.6123698022448 }, &amp;#34;inputs&amp;#34;: [ { &amp;#34;key&amp;#34;: &amp;#34;userChatInput&amp;#34;, &amp;#34;renderTypeList&amp;#34;: [ &amp;#34;reference&amp;#34;, &amp;#34;textarea&amp;#34; ], &amp;#34;valueType&amp;#34;: &amp;#34;string&amp;#34;, &amp;#34;label&amp;#34;: &amp;#34;问题输入&amp;#34;, &amp;#34;required&amp;#34;: true, &amp;#34;toolDescription&amp;#34;: &amp;#34;用户问题&amp;#34;, &amp;#34;type&amp;#34;: &amp;#34;systemInput&amp;#34;, &amp;#34;showTargetInApp&amp;#34;: false, &amp;#34;showTargetInPlugin&amp;#34;: false, &amp;#34;connected&amp;#34;: false, &amp;#34;selectedTypeIndex&amp;#34;: 0, &amp;#34;value&amp;#34;: [ &amp;#34;7z5g5h&amp;#34;, &amp;#34;userChatInput&amp;#34; ] } ], &amp;#34;outputs&amp;#34;: [ { &amp;#34;id&amp;#34;: &amp;#34;userChatInput&amp;#34;, &amp;#34;type&amp;#34;: &amp;#34;static&amp;#34;, &amp;#34;key&amp;#34;: &amp;#34;userChatInput&amp;#34;, &amp;#34;valueType&amp;#34;: &amp;#34;string&amp;#34;, &amp;#34;label&amp;#34;: &amp;#34;core.</description></item><item><title>实验室预约</title><link>https://doc.tryfastgpt.ai/docs/use-cases/app-cases/lab_appointment/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/use-cases/app-cases/lab_appointment/</guid><description>本示例演示了利用工具调用，自动选择调用知识库搜索实验室相关内容，或调用 HTTP 模块实现数据库的 CRUD 操作。
以一个实验室预约为例，用户可以通过对话系统预约、取消、修改预约和查询预约记录。
1. 全局变量使用 link通过设计一个全局变量，让用户输入姓名，模拟用户身份信息。实际使用过程中，通常是直接通过嵌入 Token 来标记用户身份。
2. 工具调用 link 背景知识中，引导模型调用工具去执行不通的操作。
🤗
Tips: 这里需要增加适当的上下文，方便模型结合历史纪录进行判断和决策~
3. HTTP 模块 link HTTP模块中，需要设置 3 个工具参数：
预约行为：可取 get, put, post, delete 四个值，分别对应查询、修改、新增、删除操作。当然，你也可以写4个HTTP模块，来分别处理。 labname: 实验室名。非必填，因为查询和删除时候，不需要。 time: 预约时间。 总结 link 工具调用模块是非常强大的功能，可以在一定程度上替代问题分类和内容提取。 通过工具模块，动态的调用不同的工具，可以将复杂业务解耦。 附件 link编排配置 link可直接复制，导入到 FastGPT 中。
编排配置 { &amp;#34;nodes&amp;#34;: [ { &amp;#34;nodeId&amp;#34;: &amp;#34;userChatInput&amp;#34;, &amp;#34;name&amp;#34;: &amp;#34;流程开始&amp;#34;, &amp;#34;intro&amp;#34;: &amp;#34;当用户发送一个内容后，流程将会从这个模块开始执行。&amp;#34;, &amp;#34;avatar&amp;#34;: &amp;#34;/imgs/workflow/userChatInput.svg&amp;#34;, &amp;#34;flowNodeType&amp;#34;: &amp;#34;workflowStart&amp;#34;, &amp;#34;position&amp;#34;: { &amp;#34;x&amp;#34;: 309.7143912167367, &amp;#34;y&amp;#34;: 1501.2761754220846 }, &amp;#34;inputs&amp;#34;: [ { &amp;#34;key&amp;#34;: &amp;#34;userChatInput&amp;#34;, &amp;#34;renderTypeList&amp;#34;: [ &amp;#34;reference&amp;#34;, &amp;#34;textarea&amp;#34; ], &amp;#34;valueType&amp;#34;: &amp;#34;string&amp;#34;, &amp;#34;label&amp;#34;: &amp;#34;问题输入&amp;#34;, &amp;#34;required&amp;#34;: true, &amp;#34;toolDescription&amp;#34;: &amp;#34;用户问题&amp;#34;, &amp;#34;type&amp;#34;: &amp;#34;systemInput&amp;#34;, &amp;#34;showTargetInApp&amp;#34;: false, &amp;#34;showTargetInPlugin&amp;#34;: false, &amp;#34;connected&amp;#34;: false, &amp;#34;selectedTypeIndex&amp;#34;: 0, &amp;#34;value&amp;#34;: [ &amp;#34;userChatInput&amp;#34;, &amp;#34;userChatInput&amp;#34; ] } ], &amp;#34;outputs&amp;#34;: [ { &amp;#34;id&amp;#34;: &amp;#34;userChatInput&amp;#34;, &amp;#34;type&amp;#34;: &amp;#34;static&amp;#34;, &amp;#34;key&amp;#34;: &amp;#34;userChatInput&amp;#34;, &amp;#34;valueType&amp;#34;: &amp;#34;string&amp;#34;, &amp;#34;label&amp;#34;: &amp;#34;core.</description></item><item><title>Dalle3 绘图</title><link>https://doc.tryfastgpt.ai/docs/use-cases/app-cases/dalle3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/use-cases/app-cases/dalle3/</guid><description>OpenAI Dalle3 接口 link先来看下官方接口的参数和响应值：
Body
{ &amp;#34;model&amp;#34;: &amp;#34;dall-e-3&amp;#34;, &amp;#34;prompt&amp;#34;: &amp;#34;A cute baby sea otter&amp;#34;, &amp;#34;n&amp;#34;: 1, &amp;#34;size&amp;#34;: &amp;#34;1024x1024&amp;#34; } Response
{ &amp;#34;created&amp;#34;: 1589478378, &amp;#34;data&amp;#34;: [ { &amp;#34;url&amp;#34;: &amp;#34;https://...&amp;#34; }, { &amp;#34;url&amp;#34;: &amp;#34;https://...&amp;#34; } ] } 编排思路 link 通过 AI 来优化图片绘制的提示词（这步省略了，自己找提示词即可） 通过 【HTTP 请求】模块 调用 Dalle3 接口，获取图片的 URL。 通过 【文本加工】模块 来构建 Markdown 的图片格式。 通过 【指定回复】模块 来直接输出图片链接。 1. 构建 HTTP 模块 link请求参数直接复制 Dalle3 接口的即可，并求改 prompt 为变量。需要增加一个 Headers.Authorization 。
Body:
{ &amp;#34;model&amp;#34;: &amp;#34;dall-e-3&amp;#34;, &amp;#34;prompt&amp;#34;: &amp;#34;{{prompt}}&amp;#34;, &amp;#34;n&amp;#34;: 1, &amp;#34;size&amp;#34;: &amp;#34;1024x1024&amp;#34; } Headers:</description></item><item><title>接入谷歌搜索</title><link>https://doc.tryfastgpt.ai/docs/use-cases/app-cases/google_search/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/use-cases/app-cases/google_search/</guid><description>工具调用模式 工具调用模式 非工具调用模式 非工具调用模式 如上图，利用「HTTP请求」模块，你可以外接一个搜索引擎作为 AI 回复的参考资料。这里以调用 Google Search API 为例。注意：本文主要是为了介绍 「HTTP请求」模块，具体的搜索效果需要依赖提示词和搜索引擎，尤其是【搜索引擎】，简单的搜索引擎无法获取更详细的内容，这部分可能需要更多的调试。
注册 Google Search API link参考这篇文章，每天可以免费使用 100 次。
写一个 Google Search 接口 link这里用 Laf 快速实现一个接口，即写即发布，无需部署。务必打开 POST 请求方式。
Laf 谷歌搜索Demo import cloud from &amp;#39;@lafjs/cloud&amp;#39; const googleSearchKey = &amp;#34;xxx&amp;#34; const googleCxId = &amp;#34;3740cxxx&amp;#34; const baseurl = &amp;#34;https://www.googleapis.com/customsearch/v1&amp;#34; type RequestType = { searchKey: string } export default async function (ctx: FunctionContext) { const { searchKey } = ctx.body as RequestType console.log(ctx.body) if (!</description></item><item><title>发送飞书webhook通知</title><link>https://doc.tryfastgpt.ai/docs/use-cases/app-cases/feishu_webhook/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/use-cases/app-cases/feishu_webhook/</guid><description>该文章展示如何发送一个简单的飞书webhook通知，以此类推，发送其他类型的通知也可以这么操作。
1. 准备飞书机器人 link 2. 导入编排代码 link复制下面配置，点击「高级编排」右上角的导入按键，导入该配置，导入后将飞书提供的接口地址复制到「HTTP 模块」。
编排配置 { &amp;#34;nodes&amp;#34;: [ { &amp;#34;nodeId&amp;#34;: &amp;#34;userGuide&amp;#34;, &amp;#34;name&amp;#34;: &amp;#34;系统配置&amp;#34;, &amp;#34;intro&amp;#34;: &amp;#34;可以配置应用的系统参数&amp;#34;, &amp;#34;avatar&amp;#34;: &amp;#34;/imgs/workflow/userGuide.png&amp;#34;, &amp;#34;flowNodeType&amp;#34;: &amp;#34;userGuide&amp;#34;, &amp;#34;position&amp;#34;: { &amp;#34;x&amp;#34;: 303.41163758039283, &amp;#34;y&amp;#34;: -552.297639861266 }, &amp;#34;version&amp;#34;: &amp;#34;481&amp;#34;, &amp;#34;inputs&amp;#34;: [], &amp;#34;outputs&amp;#34;: [] }, { &amp;#34;nodeId&amp;#34;: &amp;#34;workflowStartNodeId&amp;#34;, &amp;#34;name&amp;#34;: &amp;#34;流程开始&amp;#34;, &amp;#34;intro&amp;#34;: &amp;#34;&amp;#34;, &amp;#34;avatar&amp;#34;: &amp;#34;/imgs/workflow/userChatInput.svg&amp;#34;, &amp;#34;flowNodeType&amp;#34;: &amp;#34;workflowStart&amp;#34;, &amp;#34;position&amp;#34;: { &amp;#34;x&amp;#34;: 529.3935295017156, &amp;#34;y&amp;#34;: 197.114018410347 }, &amp;#34;version&amp;#34;: &amp;#34;481&amp;#34;, &amp;#34;inputs&amp;#34;: [ { &amp;#34;key&amp;#34;: &amp;#34;userChatInput&amp;#34;, &amp;#34;renderTypeList&amp;#34;: [ &amp;#34;reference&amp;#34;, &amp;#34;textarea&amp;#34; ], &amp;#34;valueType&amp;#34;: &amp;#34;string&amp;#34;, &amp;#34;label&amp;#34;: &amp;#34;用户问题&amp;#34;, &amp;#34;required&amp;#34;: true, &amp;#34;toolDescription&amp;#34;: &amp;#34;用户问题&amp;#34; } ], &amp;#34;outputs&amp;#34;: [ { &amp;#34;id&amp;#34;: &amp;#34;userChatInput&amp;#34;, &amp;#34;key&amp;#34;: &amp;#34;userChatInput&amp;#34;, &amp;#34;label&amp;#34;: &amp;#34;core.</description></item></channel></rss>