<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>FastGPT</title><link>https://doc.tryfastgpt.ai/</link><description>Recent content on FastGPT</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><atom:link href="https://doc.tryfastgpt.ai/index.xml" rel="self" type="application/rss+xml"/><item><title>快速了解 FastGPT</title><link>https://doc.tryfastgpt.ai/docs/intro/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/intro/</guid><description>FastGPT 是一个AI Agent 构建平台，提供开箱即用的数据处理、模型调用等能力，同时可以通过 Flow 可视化进行工作流编排，从而实现复杂的应用场景！
🤖
FastGPT 在线使用：https://tryfastgpt.ai
FastGPT 能力 link1. 专属 AI 客服 link通过导入文档或已有问答对进行训练，让 AI 模型能根据你的文档以交互式对话方式回答问题。
2. 简单易用的可视化界面 linkFastGPT 采用直观的可视化界面设计，为各种应用场景提供了丰富实用的功能。通过简洁易懂的操作步骤，可以轻松完成 AI 客服的创建和训练流程。
3. 自动数据预处理 link提供手动输入、直接分段、LLM 自动处理和 CSV 等多种数据导入途径，其中“直接分段”支持通过 PDF、WORD、Markdown 和 CSV 文档内容作为上下文。FastGPT 会自动对文本数据进行预处理、向量化和 QA 分割，节省手动训练时间，提升效能。
4. 工作流编排 link基于 Flow 模块的工作流编排，可以帮助你设计更加复杂的问答流程。例如查询数据库、查询库存、预约实验室等。
5. 强大的 API 集成 linkFastGPT 对外的 API 接口对齐了 OpenAI 官方接口，可以直接接入现有的 GPT 应用，也可以轻松集成到企业微信、公众号、飞书等平台。
FastGPT 特点 link 项目开源
FastGPT 遵循附加条件 Apache License 2.0 开源协议，你可以 Fork 之后进行二次开发和发布。FastGPT 社区版将保留核心功能，商业版仅在社区版基础上使用 API 的形式进行扩展，不影响学习使用。
独特的 QA 结构</description></item><item><title>快速上手</title><link>https://doc.tryfastgpt.ai/docs/guide/course/quick-start/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/guide/course/quick-start/</guid><description>更多使用技巧，查看视频教程
知识库 link开始前，请准备一份测试电子文档，WORD、PDF、TXT、excel、markdown 都可以，比如公司休假制度、不涉密的销售说辞、产品知识等等。
这里使用 FastGPT 中文 README 文件为例。
首先我们需要创建一个知识库。
知识库创建完之后我们需要上传一点内容。
上传内容这里有四种模式：
手动输入：手动输入问答对，是最精准的数据 QA 拆分：选择文本文件，让AI自动生成问答对 直接分段：选择文本文件，直接将其按分段进行处理 CSV 导入：批量导入问答对 这里，我们选择 QA 拆分，让 AI 自动生成问答，若问答质量不高，可以后期手动修改。
点击上传后我们需要等待数据处理完成，直到我们上传的文件状态为可用。
应用 link点击「应用」按钮来新建一个应用，这里有四个模板，我们选择「知识库 + 对话引导」。
应用创建后来再应用详情页找到「知识库」模块，把我们刚刚创建的知识库添加进去。
添加完知识库后记得点击「保存并预览」，这样我们的应用就和知识库关联起来了。
然后我们就可以愉快的开始聊天啦。</description></item><item><title>AI 相关参数配置说明</title><link>https://doc.tryfastgpt.ai/docs/guide/course/ai_settings/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/guide/course/ai_settings/</guid><description>在 FastGPT 的 AI 对话模块中，有一个 AI 高级配置，里面包含了 AI 模型的参数配置，本文详细介绍这些配置的含义。
流响应（高级编排 AI 对话 特有） link旧版名字叫做：返回 AI 内容；新版改名：流响应。
这是一个开关，打开的时候，当 AI 对话模块运行时，会将其输出的内容返回到浏览器（API响应）； 如果关闭，会强制使用非流模式调用模型，并且 AI 输出的内容不会返回到浏览器，但是生成的内容仍可以通过【AI回复】进行输出。你可以将【AI回复】连接到其他模块中进行二次使用。
最大上下文 link代表模型最多容纳的文字数量。
函数调用 link支持函数调用的模型，在使用工具时更加准确。
温度 link越低回答越严谨，少废话（实测下来，感觉差别不大）
回复上限 link最大回复 token 数量。注意，是回复的Tokens！不是上下文 tokens。
通常，回复上限=min(模型允许的最大回复上限, 最大上下文-已用上下文)
所以，一般配置模型时，不会把最大上下文配置成模型实际最大上下文，而是预留预定空间给回答，例如 128k 模型，可以配置 max_context=115000
系统提示词 link被放置在上下文数组的最前面，role 为 system，用于引导模型。
记忆轮数（仅简易模式） link可以配置模型支持的记忆轮数，如果模型的超出上下文，系统会自动截断，尽可能保证不超模型上下文。
所以尽管配置 30 轮对话，实际运行时候，不一定会达到 30 轮。
引用模板 &amp;amp; 引用提示词 link进行知识库搜索后，你可以自定义组织检索结果构成的提示词，这个配置，仅工作流中 AI 对话节点可用。并且，只会在有引用知识库内容时才会生效。
AI 对话消息组成 link想使用明白这两个变量，首先要了解传递传递给 AI 模型的消息格式。它是一个数组，FastGPT 中这个数组的组成形式为：
[ 内置提示词（config.json 配置，一般为空） 系统提示词 （用户输入的提示词） 历史记录 问题（由引用提示词、引用模板和用户问题组成） ] 🍅</description></item><item><title>对话问题引导</title><link>https://doc.tryfastgpt.ai/docs/guide/course/chat_input_guide/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/guide/course/chat_input_guide/</guid><description> 什么是自定义问题引导 link你可以为你的应用提前预设一些问题，用户在输入时，会根据输入的内容，动态搜索这些问题作为提示，从而引导用户更快的进行提问。
你可以直接在 FastGPT 中配置词库，或者提供自定义词库接口。
自定义词库接口 link需要保证这个接口可以被用户浏览器访问。
请求：
curl --location --request GET &amp;#39;http://localhost:3000/api/core/chat/inputGuide/query?appId=663c75302caf8315b1c00194&amp;amp;searchKey=你&amp;#39; 其中 appId 为应用ID，searchKey 为搜索关键字，最多是50个字符。
响应
{ &amp;#34;code&amp;#34;: 200, &amp;#34;statusText&amp;#34;: &amp;#34;&amp;#34;, &amp;#34;message&amp;#34;: &amp;#34;&amp;#34;, &amp;#34;data&amp;#34;: [ &amp;#34;是你&amp;#34;, &amp;#34;你是谁呀&amp;#34;, &amp;#34;你好好呀&amp;#34;, &amp;#34;你好呀&amp;#34;, &amp;#34;你是谁！&amp;#34;, &amp;#34;你好&amp;#34; ] } data是一个数组，包含了搜索到的问题，最多只需要返回5个问题。
参数说明：
appId - 应用ID searchKey - 搜索关键字</description></item><item><title>知识库集合标签</title><link>https://doc.tryfastgpt.ai/docs/guide/course/collection_tags/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/guide/course/collection_tags/</guid><description>知识库集合标签是 FastGPT 商业版特有功能。它允许你对知识库中的数据集合添加标签进行分类，更高效地管理知识库数据。
而进一步可以在问答中，搜索知识库时添加集合过滤，实现更精确的搜索。
标签基础操作说明 link在知识库详情页面，可以对标签进行管理，可执行的操作有
创建标签 修改标签名 删除标签 将一个标签赋给多个数据集合 给一个数据集合添加多个标签 也可以利用标签对数据集合进行筛选
知识库搜索-集合过滤说明 link利用标签可以在知识库搜索时，通过填写「集合过滤」这一栏来实现更精确的搜索，具体的填写示例如下
{ &amp;#34;tags&amp;#34;: { &amp;#34;$and&amp;#34;: [&amp;#34;标签 1&amp;#34;,&amp;#34;标签 2&amp;#34;], &amp;#34;$or&amp;#34;: [&amp;#34;有 $and 标签时，and 生效，or 不生效&amp;#34;] }, &amp;#34;createTime&amp;#34;: { &amp;#34;$gte&amp;#34;: &amp;#34;YYYY-MM-DD HH:mm 格式即可，集合的创建时间大于该时间&amp;#34;, &amp;#34;$lte&amp;#34;: &amp;#34;YYYY-MM-DD HH:mm 格式即可，集合的创建时间小于该时间,可和 $gte 共同使用&amp;#34; } } 在填写时有两个注意的点，
标签值可以为 string 类型的标签名，也可以为 null，而 null 代表着未设置标签的数据集合 标签过滤有 $and 和 $or 两种条件类型，在同时设置了 $and 和 $or 的情况下，只有 $and 会生效</description></item><item><title>文件输入功能介绍</title><link>https://doc.tryfastgpt.ai/docs/guide/course/fileinput/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/guide/course/fileinput/</guid><description>从 4.8.9 版本起，FastGPT 支持在简易模式和工作流中，配置用户上传文件、图片功能。下面先简单介绍下如何使用文件输入功能，最后是介绍下文件解析的工作原理。
简易模式中使用 link简易模式打开文件上传后，会使用工具调用模式，也就是由模型自行决策，是否需要读取文件内容。
可以找到左侧文件上传的配置项，点击其右侧的开启/关闭按键，即可打开配置弹窗。
随后，你的调试对话框中，就会出现一个文件选择的 icon，可以点击文件选择 icon，选择你需要上传的文件。
工作模式
从 4.8.13 版本起，简易模式的文件读取将会强制解析文件并放入 system 提示词中，避免连续对话时，模型有时候不会主动调用读取文件的工具。
工作流中使用 link工作流中，可以在系统配置中，找到文件输入配置项，点击其右侧的开启/关闭按键，即可打开配置弹窗。
在工作流中，使用文件的方式很多，最简单的就是类似下图中，直接通过工具调用接入文档解析，实现和简易模式一样的效果。
当然，你也可以在工作流中，对文档进行内容提取、内容分析等，然后将分析的结果传递给 HTTP 或者其他模块，从而实现文件处理的 SOP。
文档解析工作原理 link不同于图片识别，LLM 模型目前没有支持直接解析文档的能力，所有的文档“理解”都是通过文档转文字后拼接 prompt 实现。这里通过几个 FAQ 来解释文档解析的工作原理，理解文档解析的原理，可以更好的在工作流中使用文档解析功能。
上传的文件如何存储在数据库中 linkFastGPT 的对话记录存储结构中，role=user 的消息，value 值会按以下结构存储：
type UserChatItemValueItemType = { type: &amp;#39;text&amp;#39; | &amp;#39;file&amp;#39; text?: { content: string; }; file?: { type: &amp;#39;img&amp;#39; | &amp;#39;doc&amp;#39; name?: string; url: string; }; }; 也就是说，上传的图片和文档，都会以 URL 的形式存储在库中，并不会存储解析后的文档内容。
图片如何处理 link文档解析节点不会处理图片，图片链接会被过滤，图片识别请直接使用支持图片识别的 LLM 模型。
文档解析节点如何工作 link文档解析依赖文档解析节点，这个节点会接收一个array&amp;lt;string&amp;gt;类型的输入，对应的是文件输入的 URL；输出的是一个string，对应的是文档解析后的内容。</description></item><item><title>简易模式</title><link>https://doc.tryfastgpt.ai/docs/guide/workbench/basic-mode/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/guide/workbench/basic-mode/</guid><description/></item><item><title>工作流&amp;插件</title><link>https://doc.tryfastgpt.ai/docs/guide/workbench/intro/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/guide/workbench/intro/</guid><description>FastGPT 从 V4 版本开始采用新的交互方式来构建 AI 应用。使用了 Flow 节点编排（工作流）的方式来实现复杂工作流，提高可玩性和扩展性。但同时也提高了上手的门槛，有一定开发背景的用户使用起来会比较容易。
查看视频教程
什么是节点？ link在程序中，节点可以理解为一个个 Function 或者接口。可以理解为它就是一个步骤。将多个节点一个个拼接起来，即可一步步的去实现最终的 AI 输出。
如下图，这是一个最简单的 AI 对话。它由用流程开始和 AI 对话节点组成。
执行流程如下：
用户输入问题后，【流程开始】节点执行，用户问题被保存。 【AI 对话】节点执行，此节点有两个必填参数“聊天记录” “用户问题”，聊天记录的值是默认输入的6条，表示此模块上下文长度。用户问题选择的是【流程开始】模块中保存的用户问题。 【AI 对话】节点根据传入的聊天记录和用户问题，调用对话接口，从而实现回答。 节点分类 link从功能上，节点可以分为 2 类：
系统节点：用户引导（配置一些对话框信息）、用户问题（流程入口）。 功能节点：知识库搜索、AI 对话等剩余节点。（这些节点都有输入和输出，可以自由组合）。 节点的组成 link每个节点会包含 3 个核心部分：输入、输出和触发器。
AI模型、提示词、聊天记录、用户问题，知识库引用为输入，节点的输入可以是手动输入也可以是变量引用，变量引用的范围包括“全局变量”和之前任意一个节点的输出。 新的上下文和AI回复内容为输出，输出可以被之后任意节点变量引用。 节点的上下左右有四个“触发器”可以被用来连接，被连接的节点按顺序决定是否执行。 重点 - 工作流是如何运行的 linkFastGPT的工作流从【流程开始】节点开始执行，可以理解为从用户输入问题开始，没有固定的出口，是以节点运行结束作为出口，如果在一个轮调用中，所有节点都不再运行，则工作流结束。
下面我们来看下，工作流是如何运行的，以及每个节点何时被触发执行。
如上图所示节点会“被连接”也会“连接其他节点”，我们称“被连接”的那根线为前置线，“连接其他节点的线”为后置线。上图例子中【知识库搜索】模块左侧有一根前置线，右侧有一根后置线。而【AI对话】节点只有左侧一根前置线。
FastGPT工作流中的线有以下几种状态：
waiting：被连接的节点等待执行。 active：被连接的节点可以执行。 skip：被连接的节点不需要执行跳过。 节点执行的原则：
判断前置线中有没有状态为 waiting 的，如果有则等待。 判断前置线中状态有没有状态为 active 如果有则执行。 如果前置线中状态即没有 waiting 也没有 active 则认为此节点需要跳过。 节点执行完毕后，需要根据实际情况更改后置线的状态为active或skip并且更改前置线状态为waiting等待下一轮执行。 让我们看一下上面例子的执行过程：
【流程开始】节点执行完毕，更改后置线为active。 【知识库搜索】节点判断前置线状态为active开始执行，执行完毕后更改后置线状态为active 前置线状态为waiting。 【AI对话】节点判断前置线状态为active开始执行，流程执行结束。 如何连接节点 link 为了方便连接，FastGPT 每个节点的上下左右都有连接点，左和上是前置线连接点，右和下是后置线连接点。 可以点击连接线中间的 x 来删除连接线。 可以左键点击选中连接线 如何阅读？ link 建议从左往右阅读。 从 用户问题 节点开始。用户问题节点，代表的是用户发送了一段文本，触发任务开始。 关注【AI 对话】和【指定回复】节点，这两个节点是输出答案的地方。 FAQ link想合并多个输出结果怎么实现？ link 文本加工，可以对字符串进行合并。 知识库搜索合并，可以合并多个知识库搜索结果 其他结果，无法直接合并，可以考虑传入到HTTP节点中进行合并，使用[Laf](https://laf.</description></item><item><title>AI 对话</title><link>https://doc.tryfastgpt.ai/docs/guide/workbench/workflow/ai_chat/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/guide/workbench/workflow/ai_chat/</guid><description>特点 link 可重复添加 触发执行 核心模块 参数说明 linkAI模型 link可以通过 config.json 配置可选的对话模型，通过 one-api 来实现多模型接入。
点击AI模型后，可以配置模型的相关参数。
🍅
具体配置参数介绍可以参考: AI参数配置说明</description></item><item><title>知识库搜索</title><link>https://doc.tryfastgpt.ai/docs/guide/workbench/workflow/dataset_search/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/guide/workbench/workflow/dataset_search/</guid><description>知识库搜索具体参数说明，以及内部逻辑请移步：FastGPT知识库搜索方案
特点 link 可重复添加（复杂编排时防止线太乱，可以更美观） 有外部输入 有静态配置 触发执行 核心模块 参数说明 link输入 - 关联的知识库 link可以选择一个或多个相同向量模型的知识库，用于向量搜索。
输入 - 搜索参数 link点击查看参数介绍
输出 - 引用内容 link以数组格式输出引用，长度可以为 0。意味着，即使没有搜索到内容，这个输出链路也会走通。</description></item><item><title>工具调用&amp;终止</title><link>https://doc.tryfastgpt.ai/docs/guide/workbench/workflow/tool/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/guide/workbench/workflow/tool/</guid><description> 什么是工具 link工具可以是一个系统模块，例如：AI对话、知识库搜索、HTTP模块等。也可以是一个插件。
工具调用可以让 LLM 更动态的决策流程，而不都是固定的流程。（当然，缺点就是费tokens）
工具的组成 link 工具介绍。通常是模块的介绍或插件的介绍，这个介绍会告诉LLM，这个工具的作用是什么。 工具参数。对于系统模块来说，工具参数已经是固定的，无需额外配置。对于插件来说，工具参数是一个可配置项。 工具是如何运行的 link要了解工具如何运行的，首先需要知道它的运行条件。
需要工具的介绍（或者叫描述）。这个介绍会告诉LLM，这个工具的作用是什么，LLM会根据上下文语义，决定是否需要调用这个工具。 工具的参数。有些工具调用时，可能需要一些特殊的参数。参数中有2个关键的值：参数介绍和是否必须。 结合工具的介绍、参数介绍和参数是否必须，LLM会决定是否调用这个工具。有以下几种情况：
无参数的工具：直接根据工具介绍，决定是否需要执行。例如：获取当前时间。 有参数的工具： 无必须的参数：尽管上下文中，没有适合的参数，也可以调用该工具。但有时候，LLM会自己伪造一个参数。 有必须的参数：如果没有适合的参数，LLM可能不会调用该工具。可以通过提示词，引导用户提供参数。 工具调用逻辑 link在支持函数调用的模型中，可以一次性调用多个工具，调用逻辑如下：
怎么用 link 高级编排中，拖动工具调用的连接点，可用的工具头部会出现一个菱形，可以将它与工具调用模块底部的菱形相连接。
被连接的工具，会自动分离工具输入与普通的输入，并且可以编辑介绍，可以通过调整介绍，使得该工具调用时机更加精确。
关于工具调用，如何调试仍然是一个玄学，所以建议，不要一次性增加太多工具，选择少量工具调优后再进一步尝试。
用途 link默认情况下，工具调用节点，在决定调用工具后，会将工具运行的结果，返回给AI，让 AI 对工具运行的结果进行总结输出。有时候，如果你不需要 AI 进行进一步的总结输出，可以使用该节点，将其接入对于工具流程的末尾。
如下图，在执行知识库搜索后，发送给了 HTTP 请求，搜索将不会返回搜索的结果给工具调用进行 AI 总结。
附加节点 link当您使用了工具调用节点，同时就会出现工具调用终止节点和自定义变量节点，能够进一步提升工具调用的使用体验。
工具调用终止 link工具调用终止可用于结束本次调用，即可以接在某个工具后面，当工作流执行到这个节点时，便会强制结束本次工具调用，不再调用其他工具，也不会再调用 AI 针对工具调用结果回答问题。
自定义工具变量 link自定义变量可以扩展工具的变量输入，即对于一些未被视作工具参数或无法工具调用的节点，可以自定义工具变量，填上对应的参数描述，那么工具调用便会相对应的调用这个节点，进而调用其之后的工作流。
相关示例 link 谷歌搜索 发送飞书webhook</description></item><item><title>问题分类</title><link>https://doc.tryfastgpt.ai/docs/guide/workbench/workflow/question_classify/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/guide/workbench/workflow/question_classify/</guid><description>特点 link 可重复添加 有外部输入 需要手动配置 触发执行 function_call 模块 功能 link可以将用户的问题进行分类，分类后执行不同操作。在一些较模糊的场景中，分类效果不是很明显。
参数说明 link系统提示词 link被放置在对话最前面，可用于补充说明分类内容的定义。例如问题会被分为：
打招呼 Laf 常见问题 其他问题 由于 Laf 不是一个明确的东西，需要给它一个定义，此时提示词里可以填入 Laf 的定义：
Laf 是云开发平台，可以快速的开发应用 Laf 是一个开源的 BaaS 开发平台（Backend as a Service) Laf 是一个开箱即用的 serverless 开发平台 Laf 是一个集「函数计算」、「数据库」、「对象存储」等于一身的一站式开发平台 Laf 可以是开源版的腾讯云开发、开源版的 Google Firebase、开源版的 UniCloud 聊天记录 link适当增加一些聊天记录，可以联系上下文进行分类。
用户问题 link用户输入的内容。
分类内容 link依然以这 3 个分类为例，可以看到最终组成的 Function。其中返回值由系统随机生成，不需要关心。
打招呼 Laf 常见问题 其他问题 const agentFunction = { name: agentFunName, description: &amp;#39;判断用户问题的类型属于哪方面，返回对应的枚举字段&amp;#39;, parameters: { type: &amp;#39;object&amp;#39;, properties: { type: { type: &amp;#39;string&amp;#39;, description: `打招呼，返回: abc；Laf 常见问题，返回：vvv；其他问题，返回：aaa` enum: [&amp;#34;abc&amp;#34;,&amp;#34;vvv&amp;#34;,&amp;#34;aaa&amp;#34;] } }, required: [&amp;#39;type&amp;#39;] } }; 上面的 Function 必然会返回 type = abc，vvv，aaa 其中一个值，从而实现分类判断。</description></item><item><title>文本内容提取</title><link>https://doc.tryfastgpt.ai/docs/guide/workbench/workflow/content_extract/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/guide/workbench/workflow/content_extract/</guid><description>特点 link 可重复添加 需要手动配置 触发执行 function_call 模块 核心模块 功能 link从文本中提取结构化数据，通常是配合 HTTP 模块实现扩展。也可以做一些直接提取操作，例如：翻译。
参数说明 link提取要求描述 link顾名思义，给模型设置一个目标，需要提取哪些内容。
示例 1
你是实验室预约助手，从对话中提取出姓名，预约时间，实验室号。当前时间 {{cTime}}
示例 2
你是谷歌搜索助手，从对话中提取出搜索关键词
示例 3
将我的问题直接翻译成英文，不要回答问题
历史记录 link通常需要一些历史记录，才能更完整的提取用户问题。例如上图中需要提供姓名、时间和实验室名，用户可能一开始只给了时间和实验室名，没有提供自己的姓名。再经过一轮缺失提示后，用户输入了姓名，此时需要结合上一次的记录才能完整的提取出 3 个内容。
目标字段 link目标字段与提取的结果相对应，从上图可以看到，每增加一个字段，输出会增加一个对应的出口。
key: 字段的唯一标识，不可重复！ 字段描述：描述该字段是关于什么的，例如：姓名、时间、搜索词等等。 必须：是否强制模型提取该字段，可能提取出来是空字符串。 输出介绍 link 完整提取结果: 一个 JSON 字符串，包含所有字段的提取结果。 目标字段提取结果：类型均为字符串。</description></item><item><title>用户选择</title><link>https://doc.tryfastgpt.ai/docs/guide/workbench/workflow/user-selection/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/guide/workbench/workflow/user-selection/</guid><description>特点 link 用户交互 可重复添加 触发执行 功能 link「用户选择」节点属于用户交互节点，当触发这个节点时，对话会进入“交互”状态，会记录工作流的状态，等用户完成交互后，继续向下执行工作流
比如上图中的例子，当触发用户选择节点时，对话框隐藏，对话进入“交互状态”
当用户做出选择时，节点会判断用户的选择，执行“是”的分支
作用 link基础的用法为提出需要用户做抉择的问题，然后根据用户的反馈设计不同的工作流流程</description></item><item><title>表单输入</title><link>https://doc.tryfastgpt.ai/docs/guide/workbench/workflow/form_input/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/guide/workbench/workflow/form_input/</guid><description>特点 link 用户交互 可重复添加 触发执行 功能 link「表单输入」节点属于用户交互节点，当触发这个节点时，对话会进入“交互”状态，会记录工作流的状态，等用户完成交互后，继续向下执行工作流
比如上图中的例子，当触发表单输入节点时，对话框隐藏，对话进入“交互状态”
当用户填完必填的信息并点击提交后，节点能够收集用户填写的表单信息，传递到后续的节点中使用
作用 link能够精准收集需要的用户信息，再根据用户信息进行后续操作</description></item><item><title>文本拼接</title><link>https://doc.tryfastgpt.ai/docs/guide/workbench/workflow/text_editor/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/guide/workbench/workflow/text_editor/</guid><description>特点 link 可重复添加 有外部输入 触发执行 手动配置 功能 link对输入文本进行固定加工处理，入参仅支持字符串和数字格式，入参以变量形式使用在文本编辑区域。
根据上方示例图的处理方式，对任何输入都会在前面拼接“用户的问题是:”。
作用 link给任意模块输入自定格式文本，或处理 AI 模块系统提示词。
示例 link 接入谷歌搜索</description></item><item><title>指定回复</title><link>https://doc.tryfastgpt.ai/docs/guide/workbench/workflow/reply/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/guide/workbench/workflow/reply/</guid><description>特点 link 可重复添加（防止复杂编排时线太乱，重复添加可以更美观） 可手动输入 可外部输入 会输出结果给客户端 指定回复模块通常用户特殊状态回复，回复内容有两种：
一种是手动输入固定内容。 一种是通过变量引用。 图 1</description></item><item><title>文档解析</title><link>https://doc.tryfastgpt.ai/docs/guide/workbench/workflow/document_parsing/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/guide/workbench/workflow/document_parsing/</guid><description> 开启文件上传后，可使用文档解析组件。
功能 link作用 link</description></item><item><title>HTTP 请求</title><link>https://doc.tryfastgpt.ai/docs/guide/workbench/workflow/http/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/guide/workbench/workflow/http/</guid><description>特点 link 可重复添加 手动配置 触发执行 核中核模块 介绍 linkHTTP 模块会向对应的地址发送一个 HTTP 请求，实际操作与 Postman 和 ApiFox 这类直流工具使用差不多。
Params 为路径请求参数，GET请求中用的居多。 Body 为请求体，POST/PUT请求中用的居多。 Headers 为请求头，用于传递一些特殊的信息。 自定义变量中可以接收前方节点的输出作为变量 3 种数据中均可以通过 {{}} 来引用变量。 url 也可以通过 {{}} 来引用变量。 变量来自于全局变量、系统变量、前方节点输出 参数结构 link系统变量说明 link你可以将鼠标放置在请求参数旁边的问号中，里面会提示你可用的变量。
appId: 应用的ID chatId: 当前对话的ID，测试模式下不存在。 responseChatItemId: 当前对话中，响应的消息ID，测试模式下不存在。 variables: 当前对话的全局变量。 cTime: 当前时间。 histories: 历史记录（默认最多取10条，无法修改长度） Params, Headers link不多描述，使用方法和Postman, ApiFox 基本一致。
可通过 {{key}} 来引入变量。例如：
key value appId {{appId}} Authorization Bearer {{token}} Body link只有特定请求类型下会生效。
可以写一个自定义的 Json，并通过 {{key}} 来引入变量。例如：
假设有一组变量 Http 模块中的Body声明 最终得到的解析 { &amp;#34;string&amp;#34;: &amp;#34;字符串&amp;#34;, &amp;#34;number&amp;#34;: 123, &amp;#34;boolean&amp;#34;: true, &amp;#34;array&amp;#34;: [1, 2, 3], &amp;#34;obj&amp;#34;: { &amp;#34;name&amp;#34;: &amp;#34;FastGPT&amp;#34;, &amp;#34;url&amp;#34;: &amp;#34;https://tryfastgpt.</description></item><item><title>判断器</title><link>https://doc.tryfastgpt.ai/docs/guide/workbench/workflow/tfswitch/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/guide/workbench/workflow/tfswitch/</guid><description>特点 link 可重复添加 有外部输入 触发执行 功能 link对任意变量进行IF判断，若满足条件则执行IF分支，不满足条件执行ELSE分支。
上述例子中若「知识库引用」变量的长度等于0则执行IF分支，否则执行ELSE分支。
支持增加更多的判断条件和分支，同编程语言中的IF语句逻辑相同。
作用 link适用场景有：让大模型做判断后输出固定内容，根据大模型回复内容判断是否触发后续模块。</description></item><item><title>变量更新</title><link>https://doc.tryfastgpt.ai/docs/guide/workbench/workflow/variable_update/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/guide/workbench/workflow/variable_update/</guid><description>特点 link 可重复添加 有外部输入 触发执行 手动配置 功能 link 更新指定节点的输出值 更新全局变量 作用 link最基础的使用场景为
给一个「自定义变量」类型的全局变量赋值，从而实现全局变量无需用户输入 更新「变量更新」节点前的工作流节点输出，在后续使用中，使用的节点输出值为新的输出</description></item><item><title>代码运行</title><link>https://doc.tryfastgpt.ai/docs/guide/workbench/workflow/sandbox/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/guide/workbench/workflow/sandbox/</guid><description>功能 link可用于执行一段简单的 js 代码，用于进行一些复杂的数据处理。代码运行在沙盒中，无法进行网络请求、dom和异步操作。如需复杂操作，需外挂 HTTP 实现。
注意事项
私有化用户需要部署fastgpt-sandbox 镜像，并配置SANDBOX_URL环境变量。 沙盒最大运行 10s， 32M 内存限制。 变量输入 link可在自定义输入中添加代码运行需要的变量，在代码的 main 函数中，可解构出相同名字的变量。
如上图，自定义输入中有 data1 和 data2 两个变量，main 函数中可以解构出相同名字的变量。
结果输出 link务必返回一个 object 对象
自定义输出中，可以添加变量名来获取 object 对应 key 下的值。例如上图中，返回了一个对象：
{ result: data1, data2 } 他有 2 个 key：result和 data2(js 缩写，key=data2，value=data2)。这时候自定义输出中就可以添加 2 个变量来获取对应 key 下的 value。
内置 JS 全局变量 linkdelay 延迟 link延迟 1 秒后返回
async function main({data1, data2}){ await delay(1000) return { result: &amp;#34;111&amp;#34; } } countToken 统计 token link function main({input}){ return { result: countToken(input) } } strToBase64 字符串转 base64(4.</description></item><item><title>批量运行</title><link>https://doc.tryfastgpt.ai/docs/guide/workbench/workflow/loop/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/guide/workbench/workflow/loop/</guid><description>节点概述 link【批量运行】节点是 FastGPT V4.8.11 版本新增的一个重要功能模块。它允许工作流对数组类型的输入数据进行迭代处理，每次处理数组中的一个元素，并自动执行后续节点，直到完成整个数组的处理。
这个节点的设计灵感来自编程语言中的循环结构，但以可视化的方式呈现。
在程序中，节点可以理解为一个个 Function 或者接口。可以理解为它就是一个步骤。将多个节点一个个拼接起来，即可一步步的去实现最终的 AI 输出。
【批量运行】节点本质上也是一个 Function，它的主要职责是自动化地重复执行特定的工作流程。
核心特性 link 数组批量处理
支持输入数组类型数据 自动遍历数组元素 保持处理顺序 支持并行处理 (性能优化) 自动迭代执行
自动触发后续节点 支持条件终止 支持循环计数 维护执行上下文 与其他节点协同
支持与 AI 对话节点配合 支持与 HTTP 节点配合 支持与内容提取节点配合 支持与判断器节点配合 应用场景 link【批量运行】节点的主要作用是通过自动化的方式扩展工作流的处理能力，使 FastGPT 能够更好地处理批量任务和复杂的数据处理流程。特别是在处理大规模数据或需要多轮迭代的场景下，批量运行节点能显著提升工作流的效率和自动化程度。
【批量运行】节点特别适合以下场景：
批量数据处理
批量翻译文本 批量总结文档 批量生成内容 数据流水线处理
对搜索结果逐条分析 对知识库检索结果逐条处理 对 HTTP 请求返回的数组数据逐项处理 递归或迭代任务
长文本分段处理 多轮优化内容 链式数据处理 使用方法 link输入参数设置 link【批量运行】节点需要配置两个核心输入参数：
数组 (必填)：接收一个数组类型的输入，可以是：
字符串数组 (Array&amp;lt;string&amp;gt;) 数字数组 (Array&amp;lt;number&amp;gt;) 布尔数组 (Array&amp;lt;boolean&amp;gt;) 对象数组 (Array&amp;lt;object&amp;gt;) 循环体 (必填)：定义每次循环需要执行的节点流程，包含：
循环体开始：标记循环开始的位置。 循环体结束：标记循环结束的位置，并可选择输出结果变量。 循环体配置 link 在循环体内部，可以添加任意类型的节点，如：</description></item><item><title>知识库搜索引用合并</title><link>https://doc.tryfastgpt.ai/docs/guide/workbench/workflow/knowledge_base_search_merge/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/guide/workbench/workflow/knowledge_base_search_merge/</guid><description> 作用 link将多个知识库搜索结果合并成一个结果进行输出，并会通过 RRF 进行重新排序（根据排名情况），并且支持最大 tokens 过滤。
使用方法 linkAI对话只能接收一个知识库引用内容。因此，如果调用了多个知识库，无法直接引用所有知识库（如下图）
使用知识库搜索引用合并，可以把多个知识库的搜索结果合在一起。
可用例子： link 经过问题分类后对不同知识库进行检索，然后统一给一个 AI 进行回答，此时可以用到合并，不需要每个分支都添加一个 AI 对话。</description></item><item><title>问题优化</title><link>https://doc.tryfastgpt.ai/docs/guide/workbench/workflow/coreferenceresolution/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/guide/workbench/workflow/coreferenceresolution/</guid><description>特点 link 可重复添加 有外部输入 触发执行 背景 link在 RAG 中，我们需要根据输入的问题去数据库里执行 embedding 搜索，查找相关的内容，从而查找到相似的内容（简称知识库搜索）。
在搜索的过程中，尤其是连续对话的搜索，我们通常会发现后续的问题难以搜索到合适的内容，其中一个原因是知识库搜索只会使用“当前”的问题去执行。看下面的例子：
用户在提问“第二点是什么”的时候，只会去知识库里查找“第二点是什么”，压根查不到内容。实际上需要查询的是“QA结构是什么”。因此我们需要引入一个【问题优化】模块，来对用户当前的问题进行补全，从而使得知识库搜索能够搜索到合适的内容。使用补全后效果如下：
功能 link调用 AI 去对用户当前的问题进行补全。目前主要是补全“指代”词，使得检索词更加的完善可靠，从而增强上下文连续对话的知识库搜索能力。
遇到最大的难题在于：模型对于【补全】的概念可能不清晰，且对于长上下文往往无法准确的知道应该如何补全。
示例 link 接入谷歌搜索</description></item><item><title>Laf 函数调用</title><link>https://doc.tryfastgpt.ai/docs/guide/workbench/workflow/laf/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/guide/workbench/workflow/laf/</guid><description>介绍 linkLaf 函数调用模块可以调用 Laf 账号下的云函数，其工作原理与 HTTP 模块相同，有以下特殊特征：
只能使用 POST 请求 请求自带系统参数 systemParams，无需通过变量传递。 绑定 Laf 账号 link要调用 Laf 云函数，首先需要绑定 Laf 账号和应用，并且在应用中创建云函数。
Laf 提供了 PAT(访问凭证) 来实现 Laf 平台外的快捷登录，可以访问 Laf 文档查看详细如何获取 PAT。
在获取到 PAT 后，我们可以进入 FastGPT 的账号页或是在高级编排中的 Laf模块 对 Laf 账号进行绑定。Laf 账号是团队共享的，仅团队管理员可配置。
填入 PAT 验证后，选择需要绑定的应用（应用需要是 Running 状态），即可调用该应用下的云函数。
编写云函数 linkLaf 云函数拥有根据 interface 自动生成 OpenAPI 的能力，可以参照下面的代码编写云函数，以便自动生成 OpenAPI 文档。
Laf模块可以根据 OpenAPI 文档，自动识别出入参，无需手动添加数据类型。如果不会写 TS，可忽略，手动在 FastGPT 中添加参数即可。
import cloud from &amp;#39;@lafjs/cloud&amp;#39; interface IRequestBody { // 自定义入参，FastGPT 传入的均为POST请求。 data1: string // 必填参数 data2?</description></item><item><title>自定义反馈</title><link>https://doc.tryfastgpt.ai/docs/guide/workbench/workflow/custom_feedback/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/guide/workbench/workflow/custom_feedback/</guid><description>该模块为临时模块，后续会针对该模块进行更全面的设计。
特点 link 可重复添加 无外部输入 自动执行 介绍 link自定义反馈模块，可以为你的对话增加一个反馈标记，从而方便在后台更好的分析对话的数据。
在调试模式下，不会记录反馈内容，而是直接提示: 自动反馈测试: 反馈内容。
在对话模式（对话、分享窗口、带 chatId 的 API 调用）时，会将反馈内容记录到对话日志中。（会延迟60s记录）
作用 link自定义反馈模块的功能类似于程序开发的埋点，便于你观测的对话中的数据。</description></item><item><title>使用 Gapier 快速导入Agent工具</title><link>https://doc.tryfastgpt.ai/docs/guide/workbench/gapier/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/guide/workbench/gapier/</guid><description>FastGPT V4.7版本加入了工具调用，可以兼容 GPTs 的 Actions。这意味着，你可以直接导入兼容 GPTs 的 Agent 工具。
Gapier 是一个在线 GPTs Actions工具，提供了50多种现成工具，并且每天有免费额度进行测试，方便用户试用，官方地址为：https://gapier.com/。
现在，我们开始把 Gapier 的工具导入到 FastGPT 中。
1. 创建插件 link Step1 Step2 Step3 登录Gapier 复制相关参数 Step4 Step5 Step6 自定义请求头: Authorization
请求值: Bearer 复制的key 创建完后，如果需要变更，无需重新创建，只需要修改对应参数即可，会自动做差值比较更新。
2. 应用绑定工具 link简易模式 link Step1 Step2 Step3 Step4 高级编排 link Step1 Step2 Step3 Step4 3. 工具调用说明 link不同模型的区别 link不同模型调用工具采用不同的方法，有些模型支持 toolChoice 和 functionCall 效果会更好。不支持这两种方式的模型通过提示词调用，但是效果不是很好，并且为了保证顺利调用，FastGPT内置的提示词，仅支持每次调用一个工具。
具体哪些模型支持 functionCall 可以官网查看（当然，也需要OneAPI支持），同时需要调整模型配置文件中的对应字段（详细看配置字段说明）。
线上版用户，可以在模型选择时，看到是否支持函数调用的标识。</description></item><item><title>如何提交系统插件</title><link>https://doc.tryfastgpt.ai/docs/guide/plugins/how_to_submit_system_plugin/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/guide/plugins/how_to_submit_system_plugin/</guid><description>如何向 FastGPT 社区提交系统插件
系统插件原则 link 尽可能的轻量简洁，以解决实际问题的工具为主 不允许有密集 cpu 计算，不会占用大量内存占用或网络消耗 不允许操作数据库 不允许往固定的私人地址发送请求（不包含请求某些在线服务，例如 gapier, firecrawl等) 不允许使用私人包，可使用主流的开源包 什么插件可以合并 link由于目前未采用按需安装的模式，合并进仓库的插件会全部展示给用户使用。
为了控制插件的质量以及避免数量过多带来的繁琐，并不是所有的插件都会被合并到开源仓库中，你可以提前 PR 与我们沟通插件的内容。
后续实现插件按需安装后，我们会允许更多的社区插件合入。
如何写一个系统插件 - 初步 linkFastGPT 系统插件和用户工作台的插件效果是一致的，所以你需要提前了解“插件”的定义和功能。
在 FastGPT 中，插件是一种特殊的工作流，它允许你将一个工作流封装起来，并自定义入口参数和出口参数，类似于代码里的 “子函数”。
跑通 FastGPT dev 环境 link 需要在 dev 环境下执行下面的操作。
在 FastGPT 工作台中，创建一个插件 link 选择基础模板即可。
创建系统插件配置 link 系统插件配置以及自定义代码，都会在 packages/plugins 目录下。
在 packages/plugins/src 下，复制一份 template 目录，并修改名字。 打开目录里面的 template.json 文件，配置如下： 目录还有一个 index.ts 文件，下文再提。 { &amp;#34;author&amp;#34;: &amp;#34;填写你的名字&amp;#34;, &amp;#34;version&amp;#34;: &amp;#34;当前系统版本号&amp;#34;, &amp;#34;name&amp;#34;: &amp;#34;插件名&amp;#34;, &amp;#34;avatar&amp;#34;: &amp;#34;插件头像，需要配成 icon 格式。直接把 logo 图在 pr 评论区提交即可，我们会帮你加入。&amp;#34;, &amp;#34;intro&amp;#34;: &amp;#34; 插件的描述，这个描述会影响工具调用&amp;#34;, &amp;#34;showStatus&amp;#34;: false, // 是否在对话过程展示状态 &amp;#34;weight&amp;#34;: 10, // 排序权重，均默认 10 &amp;#34;isTool&amp;#34;: true, // 是否作为工具调用节点 &amp;#34;templateType&amp;#34;: &amp;#34;tools&amp;#34;, // 都填写 tools 即可，由官方来分类 &amp;#34;workflow&amp;#34;: { // 这个对象先不管，待会直接粘贴导出的工作流即可 &amp;#34;nodes&amp;#34;: [], &amp;#34;edges&amp;#34;: [] } } 打开 packages/plugins/register 文件，注册你的插件。在 list 数组中，加入一个你插件目录的名字，如下图的例子。如需构建插件组（带目录），可参考 DuckDuckGo 插件。 无需额外写代码的插件，直接放在 staticPluginList 内，需要在项目内额外写代码的，写在 packagePluginList 中。</description></item><item><title>SearXNG 搜索插件配置与使用说明</title><link>https://doc.tryfastgpt.ai/docs/guide/plugins/searxng_plugin_guide/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/guide/plugins/searxng_plugin_guide/</guid><description>SearXNG是一款免费的互联网元搜索引擎，它汇总了来自各种搜索服务和数据库的结果。它不会跟踪或分析用户。用户可以自行部署它进行使用。本文介绍 Searxng 的部署以及接入 FastGPT 插件。
1. 部署应用 link这里介绍在 Sealos 中部署 SearXNG 的方法。Docker 部署，可以直接参考 SearXNG 官方教程。
点击打开 Sealos 北京区，点击应用部署，并新建一个应用：
打开应用部署 点击新建应用 2. 部署配置 link把下面参数，填入配置中：
镜像名: searxng/searxng:latest CPU: 0.2 内存: 512M 容器暴露端口: 8080 开启公网访问 点击高级配置，填写环境变量和配置文件 环境变量
填下面两个内容，主要是为了减小并发，不然内存占用非常大。
UWSGI_WORKERS=4 UWSGI_THREADS=4 配置文件
新增一个配置文件，文件名：/etc/searx/settings.yml 文件内容：
general: debug: false instance_name: &amp;#34;searxng&amp;#34; privacypolicy_url: false donation_url: false contact_url: false enable_metrics: true open_metrics: &amp;#39;&amp;#39; brand: new_issue_url: https://github.com/searxng/searxng/issues/new docs_url: https://docs.searxng.org/ public_instances: https://searx.space wiki_url: https://github.com/searxng/searxng/wiki issue_url: https://github.com/searxng/searxng/issues search: safe_search: 0 autocomplete: &amp;#34;&amp;#34; autocomplete_min: 4 default_lang: &amp;#34;auto&amp;#34; ban_time_on_fail: 5 max_ban_time_on_fail: 120 formats: - html server: port: 8080 bind_address: &amp;#34;0.</description></item><item><title>Google 搜索插件填写说明</title><link>https://doc.tryfastgpt.ai/docs/guide/plugins/google_search_plugin_guide/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/guide/plugins/google_search_plugin_guide/</guid><description>创建Google Custom Search Engine link https://programmablesearchengine.google.com/
我们连到Custom Search Engine control panel 建立Search Engine
取得搜索引擎的ID，即cx
获取api key link https://developers.google.com/custom-search/v1/overview?hl=zh-cn
填入插件输入参数 link 将搜索引擎ID填入cx字段，api key填入key字段</description></item><item><title>Bing 搜索插件填写说明</title><link>https://doc.tryfastgpt.ai/docs/guide/plugins/bing_search_plugin/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/guide/plugins/bing_search_plugin/</guid><description> 打开微软Azure官网，登陆账号 link https://portal.azure.com/
创建bing web搜索资源 link 搜索Bing Search v7，点击创建
https://portal.azure.com/#create/Microsoft.BingSearch
进入资源详情点击管理密钥 link 4. 复制任意一个密钥填入插件输入 link</description></item><item><title>Doc2x 插件填写说明</title><link>https://doc.tryfastgpt.ai/docs/guide/plugins/doc2x_plugin_guide/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/guide/plugins/doc2x_plugin_guide/</guid><description>打开docx官网，创建账号，并复制 apikey link https://doc2x.noedgeai.com/
填写apikey到fastgpt中 link 工作流****中：
简易模式使用：</description></item><item><title>知识库基础原理介绍</title><link>https://doc.tryfastgpt.ai/docs/guide/knowledge_base/rag/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/guide/knowledge_base/rag/</guid><description>RAG文档
1. 引言 link随着自然语言处理（NLP）技术的迅猛发展，生成式语言模型（如GPT、BART等）在多种文本生成任务中表现卓越，尤其在语言生成和上下文理解方面。然而，纯生成模型在处理事实类任务时存在一些固有的局限性。例如，由于这些模型依赖于固定的预训练数据，它们在回答需要最新或实时信息的问题时，可能会出现“编造”信息的现象，导致生成结果不准确或缺乏事实依据。此外，生成模型在面对长尾问题和复杂推理任务时，常因缺乏特定领域的外部知识支持而表现不佳，难以提供足够的深度和准确性。
与此同时，检索模型（Retriever）能够通过在海量文档中快速找到相关信息，解决事实查询的问题。然而，传统检索模型（如BM25）在面对模糊查询或跨域问题时，往往只能返回孤立的结果，无法生成连贯的自然语言回答。由于缺乏上下文推理能力，检索模型生成的答案通常不够连贯和完整。
为了解决这两类模型的不足，检索增强生成模型（Retrieval-Augmented Generation，RAG）应运而生。RAG通过结合生成模型和检索模型的优势，实时从外部知识库中获取相关信息，并将其融入生成任务中，确保生成的文本既具备上下文连贯性，又包含准确的知识。这种混合架构在智能问答、信息检索与推理、以及领域特定的内容生成等场景中表现尤为出色。
1.1 RAG的定义 linkRAG是一种将信息检索与生成模型相结合的混合架构。首先，检索器从外部知识库或文档集中获取与用户查询相关的内容片段；然后，生成器基于这些检索到的内容生成自然语言输出，确保生成的内容既信息丰富，又具备高度的相关性和准确性。
2. RAG模型的核心机制 linkRAG 模型由两个主要模块构成：检索器（Retriever）与生成器（Generator）。这两个模块相互配合，确保生成的文本既包含外部的相关知识，又具备自然流畅的语言表达。
2.1 检索器（Retriever） link检索器的主要任务是从一个外部知识库或文档集中获取与输入查询最相关的内容。在RAG中，常用的技术包括：
向量检索：如BERT向量等，它通过将文档和查询转化为向量空间中的表示，并使用相似度计算来进行匹配。向量检索的优势在于能够更好地捕捉语义相似性，而不仅仅是依赖于词汇匹配。 传统检索算法：如BM25，主要基于词频和逆文档频率（TF-IDF）的加权搜索模型来对文档进行排序和检索。BM25适用于处理较为简单的匹配任务，尤其是当查询和文档中的关键词有直接匹配时。 RAG中检索器的作用是为生成器提供一个上下文背景，使生成器能够基于这些检索到的文档片段生成更为相关的答案。
2.2 生成器（Generator） link生成器负责生成最终的自然语言输出。在RAG系统中，常用的生成器包括：
BART：BART是一种序列到序列的生成模型，专注于文本生成任务，可以通过不同层次的噪声处理来提升生成的质量 。 GPT系列：GPT是一个典型的预训练语言模型，擅长生成流畅自然的文本。它通过大规模数据训练，能够生成相对准确的回答，尤其在任务-生成任务中表现尤为突出 。 生成器在接收来自检索器的文档片段后，会利用这些片段作为上下文，并结合输入的查询，生成相关且自然的文本回答。这确保了模型的生成结果不仅仅基于已有的知识，还能够结合外部最新的信息。
2.3 RAG的工作流程 linkRAG模型的工作流程可以总结为以下几个步骤：
输入查询：用户输入问题，系统将其转化为向量表示。 文档检索：检索器从知识库中提取与查询最相关的文档片段，通常使用向量检索技术或BM25等传统技术进行。 生成答案：生成器接收检索器提供的片段，并基于这些片段生成自然语言答案。生成器不仅基于原始的用户查询，还会利用检索到的片段提供更加丰富、上下文相关的答案。 输出结果：生成的答案反馈给用户，这个过程确保了用户能够获得基于最新和相关信息的准确回答。 3. RAG模型的工作原理 link3.1 检索阶段 link在RAG模型中，用户的查询首先被转化为向量表示，然后在知识库中执行向量检索。通常，检索器采用诸如BERT等预训练模型生成查询和文档片段的向量表示，并通过相似度计算（如余弦相似度）匹配最相关的文档片段。RAG的检索器不仅仅依赖简单的关键词匹配，而是采用语义级别的向量表示，从而在面对复杂问题或模糊查询时，能够更加准确地找到相关知识。这一步骤对于最终生成的回答至关重要，因为检索的效率和质量直接决定了生成器可利用的上下文信息 。
3.2 生成阶段 link生成阶段是RAG模型的核心部分，生成器负责基于检索到的内容生成连贯且自然的文本回答。RAG中的生成器，如BART或GPT等模型，结合用户输入的查询和检索到的文档片段，生成更加精准且丰富的答案。与传统生成模型相比，RAG的生成器不仅能够生成语言流畅的回答，还可以根据外部知识库中的实际信息提供更具事实依据的内容，从而提高了生成的准确性 。
3.3 多轮交互与反馈机制 linkRAG模型在对话系统中能够有效支持多轮交互。每一轮的查询和生成结果会作为下一轮的输入，系统通过分析和学习用户的反馈，逐步优化后续查询的上下文。通过这种循环反馈机制，RAG能够更好地调整其检索和生成策略，使得在多轮对话中生成的答案越来越符合用户的期望。此外，多轮交互还增强了RAG在复杂对话场景中的适应性，使其能够处理跨多轮的知识整合和复杂推理 。
4. RAG的优势与局限 link4.1 优势 link 信息完整性：RAG 模型结合了检索与生成技术，使得生成的文本不仅语言自然流畅，还能够准确利用外部知识库提供的实时信息。这种方法能够显著提升生成任务的准确性，特别是在知识密集型场景下，如医疗问答或法律意见生成。通过从知识库中检索相关文档，RAG 模型避免了生成模型“编造”信息的风险，确保输出更具真实性 。 知识推理能力：RAG 能够利用大规模的外部知识库进行高效检索，并结合这些真实数据进行推理，生成基于事实的答案。相比传统生成模型，RAG 能处理更为复杂的任务，特别是涉及跨领域或跨文档的推理任务。例如，法律领域的复杂判例推理或金融领域的分析报告生成都可以通过RAG的推理能力得到优化 。 领域适应性强：RAG 具有良好的跨领域适应性，能够根据不同领域的知识库进行特定领域内的高效检索和生成。例如，在医疗、法律、金融等需要实时更新和高度准确性的领域，RAG 模型的表现优于仅依赖预训练的生成模型 。 4.2 局限 linkRAG（检索增强生成）模型通过结合检索器和生成器，实现了在多种任务中知识密集型内容生成的突破性进展。然而，尽管其具有较强的应用潜力和跨领域适应能力，但在实际应用中仍然面临着一些关键局限，限制了其在大规模系统中的部署和优化。以下是RAG模型的几个主要局限性：
4.2.1 检索器的依赖性与质量问题 linkRAG模型的性能很大程度上取决于检索器返回的文档质量。由于生成器主要依赖检索器提供的上下文信息，如果检索到的文档片段不相关、不准确，生成的文本可能出现偏差，甚至产生误导性的结果。尤其在多模糊查询或跨领域检索的情况下，检索器可能无法找到合适的片段，这将直接影响生成内容的连贯性和准确性。</description></item><item><title>知识库搜索方案和参数</title><link>https://doc.tryfastgpt.ai/docs/guide/knowledge_base/dataset_engine/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/guide/knowledge_base/dataset_engine/</guid><description>理解向量 linkFastGPT 采用了 RAG 中的 Embedding 方案构建知识库，要使用好 FastGPT 需要简单的理解Embedding向量是如何工作的及其特点。
人类的文字、图片、视频等媒介是无法直接被计算机理解的，要想让计算机理解两段文字是否有相似性、相关性，通常需要将它们转成计算机可以理解的语言，向量是其中的一种方式。
向量可以简单理解为一个数字数组，两个向量之间可以通过数学公式得出一个距离，距离越小代表两个向量的相似度越大。从而映射到文字、图片、视频等媒介上，可以用来判断两个媒介之间的相似度。向量搜索便是利用了这个原理。
而由于文字是有多种类型，并且拥有成千上万种组合方式，因此在转成向量进行相似度匹配时，很难保障其精确性。在向量方案构建的知识库中，通常使用topk召回的方式，也就是查找前k个最相似的内容，丢给大模型去做更进一步的语义判断、逻辑推理和归纳总结，从而实现知识库问答。因此，在知识库问答中，向量搜索的环节是最为重要的。
影响向量搜索精度的因素非常多，主要包括：向量模型的质量、数据的质量（长度，完整性，多样性）、检索器的精度（速度与精度之间的取舍）。与数据质量对应的就是检索词的质量。
检索器的精度比较容易解决，向量模型的训练略复杂，因此数据和检索词质量优化成了一个重要的环节。
提高向量搜索精度的方法 link 更好分词分段：当一段话的结构和语义是完整的，并且是单一的，精度也会提高。因此，许多系统都会优化分词器，尽可能的保障每组数据的完整性。 精简index的内容，减少向量内容的长度：当index的内容更少，更准确时，检索精度自然会提高。但与此同时，会牺牲一定的检索范围，适合答案较为严格的场景。 丰富index的数量，可以为同一个chunk内容增加多组index。 优化检索词：在实际使用过程中，用户的问题通常是模糊的或是缺失的，并不一定是完整清晰的问题。因此优化用户的问题（检索词）很大程度上也可以提高精度。 微调向量模型：由于市面上直接使用的向量模型都是通用型模型，在特定领域的检索精度并不高，因此微调向量模型可以很大程度上提高专业领域的检索效果。 FastGPT 构建知识库方案 link数据存储结构 link在 FastGPT 中，整个知识库由库、集合和数据 3 部分组成。集合可以简单理解为一个文件。一个库中可以包含多个集合，一个集合中可以包含多组数据。最小的搜索单位是库，也就是说，知识库搜索时，是对整个库进行搜索，而集合仅是为了对数据进行分类管理，与搜索效果无关。（起码目前还是）
向量存储结构 linkFastGPT 采用了PostgresSQL的PG Vector插件作为向量检索器，索引为HNSW。且PostgresSQL仅用于向量检索（该引擎可以替换成其它数据库），MongoDB用于其他数据的存取。
在MongoDB的dataset.datas表中，会存储向量原数据的信息，同时有一个indexes字段，会记录其对应的向量ID，这是一个数组，也就是说，一组数据可以对应多个向量。
在PostgresSQL的表中，设置一个vector字段用于存储向量。在检索时，会先召回向量，再根据向量的ID，去MongoDB中寻找原数据内容，如果对应了同一组原数据，则进行合并，向量得分取最高得分。
多向量的目的和使用方式 link在一组向量中，内容的长度和语义的丰富度通常是矛盾的，无法兼得。因此，FastGPT 采用了多向量映射的方式，将一组数据映射到多组向量中，从而保障数据的完整性和语义的丰富度。
你可以为一组较长的文本，添加多组向量，从而在检索时，只要其中一组向量被检索到，该数据也将被召回。
意味着，你可以通过标注数据块的方式，不断提高数据块的精度。
检索方案 link 通过问题优化实现指代消除和问题扩展，从而增加连续对话的检索能力以及语义丰富度。 通过Concat query来增加Rerank连续对话的时，排序的准确性。 通过RRF合并方式，综合多个渠道的检索效果。 通过Rerank来二次排序，提高精度。 搜索参数 link 搜索模式 link语义检索 link语义检索是通过向量距离，计算用户问题与知识库内容的距离，从而得出“相似度”，当然这并不是语文上的相似度，而是数学上的。
优点：
相近语义理解 跨多语言理解（例如输入中文问题匹配英文知识点） 多模态理解（文本，图片，音视频等） 缺点：
依赖模型训练效果 精度不稳定 受关键词和句子完整度影响 全文检索 link采用传统的全文检索方式。适合查找关键的主谓语等。
混合检索 link同时使用向量检索和全文检索，并通过 RRF 公式进行两个搜索结果合并，一般情况下搜索结果会更加丰富准确。
由于混合检索后的查找范围很大，并且无法直接进行相似度过滤，通常需要进行利用重排模型进行一次结果重新排序，并利用重排的得分进行过滤。
结果重排 link利用ReRank模型对搜索结果进行重排，绝大多数情况下，可以有效提高搜索结果的准确率。不过，重排模型与问题的完整度（主谓语齐全）有一些关系，通常会先走问题优化后再进行搜索-重排。重排后可以得到一个0-1的得分，代表着搜索内容与问题的相关度，该分数通常比向量的得分更加精确，可以根据得分进行过滤。
FastGPT 会使用 RRF 对重排结果、向量搜索结果、全文检索结果进行合并，得到最终的搜索结果。</description></item><item><title>API 文件库</title><link>https://doc.tryfastgpt.ai/docs/guide/knowledge_base/api_dataset/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/guide/knowledge_base/api_dataset/</guid><description>背景 link目前 FastGPT 支持本地文件导入，但是很多时候，用户自身已经有了一套文档库，如果把文件重复导入一遍，会造成二次存储，并且不方便管理。因为 FastGPT 提供了一个 API 文件库的概念，可以通过简单的 API 接口，去拉取已有的文档库，并且可以灵活配置是否导入。
API 文件库能够让用户轻松对接已有的文档库，只需要按照 FastGPT 的 API 文件库规范，提供相应文件接口，然后将服务接口的 baseURL 和 token 填入知识库创建参数中，就能直接在页面上拿到文件库的内容，并选择性导入
如何使用 API 文件库 link创建知识库时，选择 API 文件库类型，然后需要配置两个关键参数:文件服务接口的 baseURL 和用于身份验证的请求头信息。只要提供的接口规范符合 FastGPT 的要求，系统就能自动获取并展示完整的文件列表，可以根据需要选择性地将文件导入到知识库中。
你需要提供两个参数：
baseURL: 文件服务接口的 baseURL authorization: 用于身份验证的请求头信息，实际请求格式为 Authorization: Bearer &amp;lt;token&amp;gt; 接口规范 link接口响应格式：
type ResponseType = { success: boolean; message: string; data: any; } 数据类型：
// 文件列表中，单项的文件类型 type FileListItem = { id: string; parentId: string | null; name: string; type: &amp;#39;file&amp;#39; | &amp;#39;folder&amp;#39;; updateTime: Date; createTime: Date; } 1.</description></item><item><title>飞书知识库</title><link>https://doc.tryfastgpt.ai/docs/guide/knowledge_base/lark_dataset/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/guide/knowledge_base/lark_dataset/</guid><description>FastGPT v4.8.16 版本开始，商业版用户支持飞书知识库导入，用户可以通过配置飞书应用的 appId 和 appSecret，并选中一个文档空间的顶层文件夹来导入飞书知识库。目前处于测试阶段，部分交互有待优化。
由于飞书限制，无法直接获取所有文档内容，目前仅可以获取共享空间下文件目录的内容，无法获取个人空间和知识库里的内容。
1. 创建飞书应用 link打开 飞书开放平台，点击创建应用，选择自建应用，然后填写应用名称。
2. 配置应用权限 link创建应用后，进入应用可以配置相关权限，这里需要增加3个权限：
获取云空间文件夹下的云文档清单 查看新版文档 查看、评论、编辑和管理云空间中所有文件 3. 获取 appId 和 appSecret link 4. 给 Folder 增加权限 link可参考飞书教程： https://open.feishu.cn/document/server-docs/docs/drive-v1/faq#b02e5bfb
大致总结为：
把刚刚创建的应用拉入一个群里 给这个群增加目录权限 如果你的目录已经给全员组增加权限了，则可以跳过上面步骤，直接获取 Folder Token。
5. 获取 Folder Token link可以页面路径上获取 Folder Token，注意不要把问号复制进来。
6. 创建知识库 link根据 3 和 5 获取到的 3 个参数，创建知识库，选择飞书文件库类型，然后填入对应的参数，点击创建。</description></item><item><title>语雀文件库</title><link>https://doc.tryfastgpt.ai/docs/guide/knowledge_base/yuque_dataset/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/guide/knowledge_base/yuque_dataset/</guid><description>FastGPT v4.8.16 版本开始，商业版用户支持语雀文件库导入，用户可以通过配置语雀的 token 和 uid 来导入语雀文档库。目前处于测试阶段，部分交互有待优化。
1. 获取语雀的 token 和 uid link在语雀首页 - 个人头像 - 设置，可找到对应参数。
参考下图获取 Token 和 User ID，注意给 Token 赋值权限：
获取 Token 增加权限 获取 User ID 2. 创建知识库 link使用上一步获取的 token 和 uid，创建知识库，选择语雀文件库类型，然后填入对应的参数，点击创建。
3. 导入文档 link创建完知识库后，点击添加文件即可导入语雀的文档库，跟随引导即可。
语雀知识库支持定时同步功能，每天会不定时的扫描一次，如果文档有更新，则会进行同步，也可以进行手动同步。</description></item><item><title>Web 站点同步</title><link>https://doc.tryfastgpt.ai/docs/guide/knowledge_base/websync/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/guide/knowledge_base/websync/</guid><description>该功能目前仅向商业版用户开放。
什么是 Web 站点同步 linkWeb 站点同步利用爬虫的技术，可以通过一个入口网站，自动捕获同域名下的所有网站，目前最多支持200个子页面。出于合规与安全角度，FastGPT 仅支持静态站点的爬取，主要用于各个文档站点快速构建知识库。
Tips: 国内的媒体站点基本不可用，公众号、csdn、知乎等。可以通过终端发送curl请求检测是否为静态站点，例如：
curl https://doc.tryfastgpt.ai/docs/intro/ 如何使用 link1. 新建知识库，选择 Web 站点同步 link 2. 点击配置站点信息 link 3. 填写网址和选择器 link 好了， 现在点击开始同步，静等系统自动抓取网站信息即可。
创建应用，绑定知识库 link 选择器如何使用 link选择器是 HTML CSS JS 的产物，你可以通过选择器来定位到你需要抓取的具体内容，而不是整个站点。使用方式为：
首先打开浏览器调试面板（通常是 F12，或者【右键 - 检查】） link 输入对应元素的选择器 link菜鸟教程 css 选择器，具体选择器的使用方式可以参考菜鸟教程。
上图中，我们选中了一个区域，对应的是div标签，它有 data-prismjs-copy, data-prismjs-copy-success, data-prismjs-copy-error 三个属性，这里我们用到一个就够。所以选择器是： div[data-prismjs-copy]
除了属性选择器，常见的还有类和ID选择器。例如：
上图 class 里的是类名（可能包含多个类名，都是空格隔开的，选择一个即可），选择器可以为：.docs-content
多选择器使用 link在开头的演示中，我们对 FastGPT 文档是使用了多选择器的方式来选择，通过逗号隔开了两个选择器。
我们希望选中上图两个标签中的内容，此时就需要两组选择器。一组是：.docs-content .mb-0.d-flex，含义是 docs-content 类下同时包含 mb-0和d-flex 两个类的子元素；
另一组是.docs-content div[data-prismjs-copy]，含义是docs-content 类下包含data-prismjs-copy属性的div元素。
把两组选择器用逗号隔开即可：.docs-content .mb-0.d-flex, .docs-content div[data-prismjs-copy]</description></item><item><title>外部文件知识库</title><link>https://doc.tryfastgpt.ai/docs/guide/knowledge_base/externalfile/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/guide/knowledge_base/externalfile/</guid><description>外部文件库是 FastGPT 商业版特有功能。它允许接入你现在的文件系统，无需将文件再导入一份到 FastGPT 中。
并且，阅读权限可以通过你的文件系统进行控制。
导入参数说明 link 外部预览地址：用于跳转你的文件阅读地址，会携带“文件阅读ID”进行访问。 文件访问URL：文件可访问的地址。 文件阅读ID：通常情况下，文件访问URL是临时的。如果希望永久可以访问，你需要使用该文件阅读ID，并配合上“外部预览地址”，跳转至新的阅读地址进行原文件访问。 文件名：默认会自动解析文件访问URL上的文件名。如果你手动填写，将会以手动填写的值为准。 点击查看API导入文档
API 文件库替代方案 link4.8.15 提供了新的知识库类型 - API 文件库，对外部文件知识库做了进一步的拓展
通过对接口进行简单的调整，就能使用 API 文件库代替外部文件知识库的功能
你可以直接将外部文件知识库中的外部预览地址，作为 API 文件库接口规范中获取文件阅读链接的接口返回
然后再以相同的 baseURL 实现获取文件列表和获取单个文件内容这两个接口
这样就能轻松地使用 API 文件库替代原有的外部文件知识库，更多详细的内容见 API 文件库的文档</description></item><item><title>团队&amp;成员组&amp;权限</title><link>https://doc.tryfastgpt.ai/docs/guide/team_permissions/team_roles_permissions/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/guide/team_permissions/team_roles_permissions/</guid><description/></item><item><title>邀请链接说明文档</title><link>https://doc.tryfastgpt.ai/docs/guide/team_permissions/invitation_link/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/guide/team_permissions/invitation_link/</guid><description>v4.9.1 团队邀请成员将开始使用「邀请链接」的模式，弃用之前输入用户名进行添加的形式。
在版本升级后，原收到邀请还未加入团队的成员，将自动清除邀请。请使用邀请链接重新邀请成员。
如何使用 link 在团队管理页面，管理员可点击「邀请成员」按钮打开邀请成员弹窗 在邀请成员弹窗中，点击「创建邀请链接」按钮，创建邀请链接。 输入对应内容 链接描述：建议将链接描述为使用场景或用途。链接创建后不支持修改噢。
有效期：30分钟，7天，1年
有效人数：1人，无限制
点击复制链接，并将其发送给想要邀请的人。 用户访问链接后，如果未登录/未注册，则先跳转到登录页面进行登录。在登录后将进入团队页面，处理邀请。 邀请链接形如：fastgpt.cn/account/team?invitelinkid=xxxx
点击接受，则用户将加入团队
点击忽略，则关闭弹窗，用户下次访问该邀请链接则还可以选择加入。
链接失效和自动清理 link链接失效原因 link手动停用链接
邀请链接到达有效期，自动停用
有效人数为1人的链接，已有1人通过邀请链接加入团队。
停用的链接无法访问，也无法再次启用。
链接上限 link一个用户最多可以同时存在 10 个有效的邀请链接。
链接自动清理 link失效的链接将在 30 天后自动清理。</description></item><item><title>对话框与HTML渲染</title><link>https://doc.tryfastgpt.ai/docs/guide/dialogboxes/htmlrendering/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/guide/dialogboxes/htmlrendering/</guid><description> 源码模式 预览模式 全屏模式 1. 设计背景 link尽管Markdown本身支持嵌入HTML标签，但由于安全问题，许多平台和环境对HTML的渲染进行了限制，特别是在渲染动态内容、交互式元素以及外部资源时。这些限制大大降低了用户在撰写和展示复杂文档时的灵活性，尤其是当需要嵌入外部HTML内容时。为了应对这一问题，我们通过使用 iframe 来嵌入和渲染HTML内容，并结合 sandbox 属性，保障了外部HTML的安全渲染。
2. 功能简介 link该功能模块的主要目的是扩展FastGPT在Markdown渲染中的能力，支持嵌入和渲染HTML内容。由于是利用 Iframe 渲染，所以无法确认内容的高度，FastGPT 中会给 Iframe 设置一个固定高度来进行渲染。并且不支持 HTML 中执行 js 脚本。
3. 技术实现 link本模块通过以下方式实现了HTML渲染和互动功能：
组件设计：该模块通过渲染 iframe 类型的代码块展示HTML内容。使用自定义的 IframeBlock 组件，结合 sandbox 属性来保障嵌入内容的安全性。sandbox 限制了外部HTML中的行为，如禁用脚本执行、限制表单提交等，确保HTML内容的安全性。通过辅助函数与渲染Markdown内容的部分结合，处理 iframe 嵌入的HTML内容。 安全机制：通过 iframe 的 sandbox 属性和 referrerPolicy 来防止潜在的安全风险。sandbox 属性提供了细粒度的控制，允许特定的功能（如脚本、表单、弹出窗口等）在受限的环境中执行，以确保渲染的HTML内容不会对系统造成威胁。 展示与互动功能：用户可以通过不同的展示模式（如全屏、预览、源代码模式）自由切换，以便更灵活地查看和控制嵌入的HTML内容。嵌入的 iframe 自适应父容器的宽度，同时保证 iframe嵌入的内容能够适当显示。 4. 如何使用 link你只需要通过 Markdown 代码块格式，并标记语言为 html 即可。例如：
```html &amp;lt;!DOCTYPE html&amp;gt; &amp;lt;html lang=&amp;#34;zh-CN&amp;#34;&amp;gt; &amp;lt;head&amp;gt; &amp;lt;meta charset=&amp;#34;UTF-8&amp;#34;&amp;gt; &amp;lt;meta name=&amp;#34;viewport&amp;#34; content=&amp;#34;width=device-width, initial-scale=1.0&amp;#34;&amp;gt; &amp;lt;meta http-equiv=&amp;#34;X-UA-Compatible&amp;#34; content=&amp;#34;ie=edge&amp;#34;&amp;gt; &amp;lt;title&amp;gt;欢迎使用FastGPT&amp;lt;/title&amp;gt; &amp;lt;/head&amp;gt; &amp;lt;body&amp;gt; &amp;lt;nav&amp;gt; &amp;lt;ul&amp;gt; &amp;lt;li&amp;gt;&amp;lt;a href=&amp;#34;#home&amp;#34;&amp;gt;首页&amp;lt;/a&amp;gt;&amp;lt;/li&amp;gt; &amp;lt;li&amp;gt;&amp;lt;a href=&amp;#34;#about&amp;#34;&amp;gt;关于我们&amp;lt;/a&amp;gt;&amp;lt;/li&amp;gt; &amp;lt;li&amp;gt;&amp;lt;a href=&amp;#34;#contact&amp;#34;&amp;gt;联系我们&amp;lt;/a&amp;gt;&amp;lt;/li&amp;gt; &amp;lt;li&amp;gt;&amp;lt;a href=&amp;#34;#gallery&amp;#34;&amp;gt;图库&amp;lt;/a&amp;gt;&amp;lt;/li&amp;gt; &amp;lt;/ul&amp;gt; &amp;lt;/nav&amp;gt; &amp;lt;/body&amp;gt; &amp;lt;/html&amp;gt;</description></item><item><title>知识库引用分块阅读器</title><link>https://doc.tryfastgpt.ai/docs/guide/dialogboxes/quotelist/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/guide/dialogboxes/quotelist/</guid><description>在企业 AI 应用落地过程中，文档知识引用的精确性和透明度一直是用户关注的焦点。FastGPT 4.9.1 版本带来的知识库分块阅读器，巧妙解决了这一痛点，让 AI 引用不再是&amp;quot;黑盒&amp;quot;。
为什么需要分块阅读器？ link传统的 AI 对话中，当模型引用企业知识库内容时，用户往往只能看到被引用的片段，无法获取完整语境，这给内容验证和深入理解带来了挑战。分块阅读器的出现，让用户可以在对话中直接查看引用内容的完整文档，并精确定位到引用位置，实现了引用的&amp;quot;可解释性&amp;quot;。
传统引用体验的局限 link以往在知识库中上传文稿后，当我们在工作流中输入问题时，传统的引用方式只会展示引用到的分块，无法确认分块在文章中的上下文：
问题 引用 FastGPT 分块阅读器：精准定位，无缝阅读 link而在 FastGPT 全新的分块式阅读器中，同样的知识库内容和问题，呈现方式发生了质的飞跃
当 AI 引用知识库内容时，用户只需点击引用链接，即可打开一个浮窗，呈现完整的原文内容，并通过醒目的高亮标记精确显示引用的文本片段。这既保证了回答的可溯源性，又提供了便捷的原文查阅体验。
核心功能 link全文展示与定位 link&amp;ldquo;分块阅读器&amp;rdquo; 让用户能直观查看AI回答引用的知识来源。
在对话界面中，当 AI 引用了知识库内容，系统会在回复下方展示出处信息。用户只需点击这些引用链接，即可打开一个优雅的浮窗，呈现完整的原文内容，并通过醒目的高亮标记精确显示 AI 引用的文本片段。
这一设计既保证了回答的可溯源性，又提供了便捷的原文查阅体验，让用户能轻松验证AI回答的准确性和相关上下文。
便捷引用导航 link分块阅读器右上角设计了简洁实用的导航控制，用户可以通过这对按钮轻松在多个引用间切换浏览。导航区还直观显示当前查看的引用序号及总引用数量（如 &amp;ldquo;7/10&amp;rdquo;），帮助用户随时了解浏览进度和引用内容的整体规模。
引用质量评分 link每条引用内容旁边都配有智能评分标签，直观展示该引用在所有知识片段中的相关性排名。用户只需将鼠标悬停在评分标签上，即可查看完整的评分详情，了解这段引用内容为何被AI选中以及其相关性的具体构成。
文档内容一键导出 link分块阅读器贴心配备了内容导出功能，让有效信息不再流失。只要用户拥有相应知识库的阅读权限，便可通过简单点击将引用涉及的全文直接保存到本地设备。
进阶特性 link灵活的可见度控制 linkFastGPT提供灵活的引用可见度设置，让知识共享既开放又安全。以免登录链接为例，管理员可精确控制外部访问者能看到的信息范围。
当设置为&amp;quot;仅引用内容可见&amp;quot;时，外部用户点击引用链接将只能查看 AI 引用的特定文本片段，而非完整原文档。如图所示，分块阅读器此时智能调整显示模式，仅呈现相关引用内容。
即时标注优化 link在浏览过程中，授权用户可以直接对引用内容进行即时标注和修正，系统会智能处理这些更新而不打断当前的对话体验。所有修改过的内容会通过醒目的&amp;quot;已更新&amp;quot;标签清晰标识，既保证了引用的准确性，又维持了对话历史的完整性。
这一无缝的知识优化流程特别适合团队协作场景，让知识库能在实际使用过程中持续进化，确保AI回答始终基于最新、最准确的信息源。
智能文档性能优化 link面对现实业务中可能包含成千上万分块的超长文档，FastGPT采用了先进的性能优化策略，确保分块阅读器始终保持流畅响应。
系统根据引用相关性排序和数据库索引进行智能加载管理，实现了&amp;quot;按需渲染&amp;quot;机制——根据索引排序和数据库 id，只有当用户实际需要查看的内容才会被加载到内存中。这意味着无论是快速跳转到特定引用，还是自然滚动浏览文档，都能获得丝滑的用户体验，不会因为文档体积庞大而出现卡顿或延迟。
这一技术优化使FastGPT能够轻松应对企业级的大规模知识库场景，让即使是包含海量信息的专业文档也能高效展示和查阅。</description></item><item><title>通过 API 访问应用</title><link>https://doc.tryfastgpt.ai/docs/use-cases/external-integration/openapi/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/use-cases/external-integration/openapi/</guid><description>在 FastGPT 中，你可以为每一个应用创建多个 API 密钥，用于访问应用的 API 接口。每个密钥仅能访问一个应用。完整的接口可以查看应用对话接口。
获取 API 密钥 link依次选择应用 -&amp;gt; 「API访问」，然后点击「API 密钥」来创建密钥。
warning 密钥需要自己保管好，一旦关闭就无法再复制密钥，只能创建新密钥再复制。
🍅
Tips: 安全起见，你可以设置一个额度或者过期时间，防止 key 被滥用。
替换三方应用的变量 link OPENAI_API_BASE_URL: https://api.fastgpt.in/api (改成自己部署的域名) OPENAI_API_KEY = 上一步获取到的密钥 ChatGPT Next Web 示例：
ChatGPT Web 示例：</description></item><item><title>接入飞书机器人教程</title><link>https://doc.tryfastgpt.ai/docs/use-cases/external-integration/feishu/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/use-cases/external-integration/feishu/</guid><description>从 4.8.10 版本起，FastGPT 商业版支持直接接入飞书机器人，无需额外的 API。
1. 申请飞书应用 link开一个免费的测试企业更方便进行调试。
在飞书开放平台的开发者后台申请企业自建应用。 添加一个机器人应用。
2. 在 FastGPT 新建发布渠道 link在fastgpt中选择想要接入的应用，在 发布渠道 页面，新建一个接入飞书机器人的发布渠道，填写好基础信息。
3. 获取应用的 App ID, App Secret 两个凭证 link在飞书开放平台开发者后台，刚刚创建的企业自建应用中，找到 App ID 和 App Secret，填入 FastGPT 新建发布渠道的对话框里面。
填入两个参数到 FastGPT 配置弹窗中。
（可选）在飞书开放平台开发者后台，点击事件与回调 -&amp;gt; 加密策略 获取 Encrypt Key，并填入飞书机器人接入的对话框里面
Encrypt Key 用于加密飞书服务器与 FastGPT 之间通信。 建议如果使用 Https 协议，则不需要 Encrypt Key。如果使用 Http 协议通信，则建议使用 Encrypt Key Verification Token 默认生成的这个 Token 用于校验来源。但我们使用飞书官方推荐的另一种更为安全的校验方式，因此可以忽略这个配置项。
4. 配置回调地址 link新建好发布渠道后，点击请求地址，复制对应的请求地址。
在飞书控制台，点击左侧的 事件与回调 ，点击配置订阅方式旁边的编辑 icon，粘贴刚刚复制的请求地址到输入框中。
5. 配置机器人回调事件和权限 link 添加 接收消息 事件 在事件与回调页面，点击添加事件。</description></item><item><title>接入钉钉机器人教程</title><link>https://doc.tryfastgpt.ai/docs/use-cases/external-integration/dingtalk/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/use-cases/external-integration/dingtalk/</guid><description>从 4.8.16 版本起，FastGPT 商业版支持直接接入钉钉机器人，无需额外的 API。
1. 创建钉钉企业内部应用 link 在钉钉开发者后台创建企业内部应用。 获取Client ID和Client Secret。 2. 为 FastGPT 添加发布渠道 link在 FastGPT 中选择要接入的应用，在发布渠道页面，新建一个接入钉钉机器人的发布渠道。
将前面拿到的 Client ID 和 Client Secret 填入配置弹窗中。
创建完成后，点击请求地址按钮，然后复制回调地址。
3. 为应用添加机器人应用能力。 link在钉钉开发者后台，点击左侧添加应用能力，为刚刚创建的企业内部应用添加 机器人 应用能力。
4. 配置机器人回调地址 link点击左侧机器人 应用能力，然后将底部消息接受模式设置为HTTP模式，消息接收地址填入前面复制的 FastGPT 的回调地址。
调试完成后，点击发布。
5. 发布应用 link机器人发布后，还需要在版本管理与发布页面发布应用版本。
点击创建新版本后，设置版本号和版本描述后点击保存发布即可。
应用发布后，即可在钉钉企业中使用机器人功能，可对机器人私聊。或者在群组添加机器人后@机器人，触发对话。</description></item><item><title>接入微信公众号教程</title><link>https://doc.tryfastgpt.ai/docs/use-cases/external-integration/official_account/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/use-cases/external-integration/official_account/</guid><description>从 4.8.10 版本起，FastGPT 商业版支持直接接入微信公众号，无需额外的 API。
注意⚠️: 目前只支持通过验证的公众号（服务号和订阅号都可以）
1. 在 FastGPT 新建发布渠道 link在 FastGPT 中选择想要接入的应用，在 发布渠道 页面，新建一个接入微信公众号的发布渠道，填写好基础信息。
2. 获取 AppID 、 Secret和Token link1. 登录微信公众平台，选择您的公众号。 link打开微信公众号官网：https://mp.weixin.qq.com
只支持通过验证的公众号，未通过验证的公众号暂不支持。
开发者可以从这个链接申请微信公众号的测试号进行测试，测试号可以正常使用，但不能配置 AES Key
2. 把3个参数填入 FastGPT 配置弹窗中。 link 3. 在 IP 白名单中加入 FastGPT 的 IP link 私有部署的用户可自行查阅自己的 IP 地址。
海外版用户（cloud.tryfastgpt.ai）可以填写下面的 IP 白名单：
35.240.227.100 34.124.237.188 34.143.240.160 34.87.51.146 34.87.79.202 35.247.163.68 34.87.102.86 35.198.192.104 34.126.163.205 34.124.189.116 34.143.149.171 34.87.173.252 34.142.157.52 34.87.180.104 34.87.20.189 34.87.110.152 34.87.44.74 34.87.152.33 35.197.149.75 35.247.161.35 国内版用户（fastgpt.cn)可以填写下面的 IP 白名单：</description></item><item><title>对接 chatgpt-on-wechat</title><link>https://doc.tryfastgpt.ai/docs/use-cases/external-integration/onwechat/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/use-cases/external-integration/onwechat/</guid><description>1 分钟对接 chatgpt-on-wechat linkchatgpt-on-wechat GitHub 地址
由于 FastGPT 的 API 接口和 OpenAI 的规范一致，可以无需变更原来的应用即可使用 FastGPT 上编排好的应用。API 使用可参考 这篇文章。编排示例，可参考 高级编排介绍
1. 获取 OpenAPI 密钥 link依次选择应用 -&amp;gt; 「API访问」，然后点击「API 密钥」来创建密钥。
warning 密钥需要自己保管好，一旦关闭就无法再复制密钥，只能创建新密钥再复制。
3. 创建 docker-compose.yml 文件 link只需要修改 OPEN_AI_API_KEY 和 OPEN_AI_API_BASE 两个环境变量即可。其中 OPEN_AI_API_KEY 为第一步获取的密钥，OPEN_AI_API_BASE 为 FastGPT 的 OpenAPI 地址，例如：https://api.fastgpt.in/api/v1。
随便找一个目录，创建一个 docker-compose.yml 文件，将下面的代码复制进去。
version: &amp;#39;2.0&amp;#39; services: chatgpt-on-wechat: image: zhayujie/chatgpt-on-wechat container_name: chatgpt-on-wechat security_opt: - seccomp:unconfined environment: OPEN_AI_API_KEY: &amp;#39;fastgpt-z51pkjqm9nrk03a1rx2funoy&amp;#39; OPEN_AI_API_BASE: &amp;#39;https://api.fastgpt.in/api/v1&amp;#39; MODEL: &amp;#39;gpt-3.5-turbo&amp;#39; CHANNEL_TYPE: &amp;#39;wx&amp;#39; PROXY: &amp;#39;&amp;#39; HOT_RELOAD: &amp;#39;False&amp;#39; SINGLE_CHAT_PREFIX: &amp;#39;[&amp;#34;bot&amp;#34;, &amp;#34;@bot&amp;#34;]&amp;#39; SINGLE_CHAT_REPLY_PREFIX: &amp;#39;&amp;#34;[bot] &amp;#34;&amp;#39; GROUP_CHAT_PREFIX: &amp;#39;[&amp;#34;@bot&amp;#34;]&amp;#39; GROUP_NAME_WHITE_LIST: &amp;#39;[&amp;#34;ChatGPT测试群&amp;#34;, &amp;#34;ChatGPT测试群2&amp;#34;]&amp;#39; IMAGE_CREATE_PREFIX: &amp;#39;[&amp;#34;画&amp;#34;, &amp;#34;看&amp;#34;, &amp;#34;找&amp;#34;]&amp;#39; CONVERSATION_MAX_TOKENS: 1000 SPEECH_RECOGNITION: &amp;#39;False&amp;#39; CHARACTER_DESC: &amp;#39;你是ChatGPT, 一个由OpenAI训练的大型语言模型, 你旨在回答并解决人们的任何问题，并且可以使用多种语言与人交流。&amp;#39; SUBSCRIBE_MSG: &amp;#39;感谢您的关注！\n这里是ChatGPT，可以自由对话。\n支持语音对话。\n支持图片输入。\n支持图片输出，画字开头的消息将按要求创作图片。\n支持tool、角色扮演和文字冒险等丰富的插件。\n输入{trigger_prefix}#help 查看详细指令。&amp;#39; EXPIRES_IN_SECONDS: 3600 USE_GLOBAL_PLUGIN_CONFIG: &amp;#39;True&amp;#39; USE_LINKAI: &amp;#39;False&amp;#39; LINKAI_API_KEY: &amp;#39;&amp;#39; LINKAI_APP_CODE: &amp;#39;&amp;#39; 4.</description></item><item><title>接入微信和企业微信</title><link>https://doc.tryfastgpt.ai/docs/use-cases/external-integration/wechat/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/use-cases/external-integration/wechat/</guid><description>FastGPT 三分钟接入微信/企业微信 link私人微信和企业微信接入的方式基本一样，不同的地方会刻意指出。
查看视频教程
创建APIKey link首先找到我们需要接入的应用，然后点击「外部使用」-&amp;gt;「API访问」创建一个APIKey并保存。
配置微秘书 link打开微秘书 注册登录后找到菜单栏「基础配置」-&amp;gt;「智能配置」，按照下图配置。
继续往下看到 apikey 和服务器根地址，这里apikey填写我们在 FastGPT 应用外部访问中创建的 APIkey，服务器根地址填写官方地址或者私有化部署的地址，这里用官方地址示例，注意要添加/v1后缀,填写完毕后保存。
sealos部署服务 link访问sealos 登录进来之后打开「应用管理」-&amp;gt; 「新建应用」。
应用名：称随便填写 镜像名：私人微信填写 aibotk/wechat-assistant 企业微信填写 aibotk/worker-assistant cpu和内存建议 1c1g 往下翻页找到「高级配置」-&amp;gt; 「编辑环境变量」
这里需要填写三个环境变量：
AIBOTK_KEY=微秘书 APIKEY AIBOTK_SECRET=微秘书 APISECRET WORK_PRO_TOKEN=你申请的企微 token （企业微信需要填写，私人微信不需要） 这里最后的企业微信 Token 在微秘书的-&amp;gt;会员开通栏目中自行购买。
这里环境变量我们介绍下如何填写：
AIBOTK_KEY 和 AIBOTK_SECRET 我们需要回到微秘书找到「个人中心」,这里的 APIKEY 对应 AIBOTK_KEY ，APISECRET 对应 AIBOTK_SECRET。
WORK_PRO_TOKEN 微秘书的会员中心中自行购买即可。
填写完毕后点右上角「部署」，等待应用状态变为运行中。
返回微秘书 找到「首页」，扫码登录需要接入的微信号。
测试 link只需要发送信息，或者拉入群聊@登录的微信就会回复信息啦。</description></item><item><title>iframe 接入</title><link>https://doc.tryfastgpt.ai/docs/use-cases/external-integration/iframe_integration/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/use-cases/external-integration/iframe_integration/</guid><description/></item><item><title>如何提交应用模板</title><link>https://doc.tryfastgpt.ai/docs/use-cases/app-cases/submit_application_template/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/use-cases/app-cases/submit_application_template/</guid><description>什么模板可以合并 link目前合并进仓库的应用模板，会在「模板市场」中全部展示给用户。
为了控制模板的质量以及避免数量过多带来的繁琐，并不是所有的模板都会被合并到开源仓库中，你可以提前 PR 与我们沟通模板的内容。
预估最后总体的数量不会很多，控制在 50 个左右，一半来自 FastGPT Team，一半来自社区用户。
如何写一个应用模板 link 跑通 FastGPT dev 环境 link 需要在 dev 环境下执行下面的操作。
可参照 FastGPT｜快速开始本地开发
在 FastGPT 工作台中，创建一个应用 link 创建空白工作流即可。
创建应用模板 link 应用模板配置以及相关资源，都会在 packages/templates/src 目录下。
在packages/templates/src 目录下，创建一个文件夹，名称为模板对应的 id。 在刚刚创建的文件夹中，再创建一个 template.json 文件，复制粘贴并填写如下配置： { &amp;#34;name&amp;#34;: &amp;#34;模板名&amp;#34;, &amp;#34;intro&amp;#34;: &amp;#34;模板描述，会展示在模板市场的展示页&amp;#34;, &amp;#34;author&amp;#34;: &amp;#34;填写你的名字&amp;#34;, &amp;#34;avatar&amp;#34;: &amp;#34;模板头像，可以将图片文件放在同一个文件夹中，然后填写相应路径&amp;#34;, &amp;#34;tags&amp;#34;: [&amp;#34;模板标签&amp;#34;], // writing(文本创作)，image-generation(图片生成)，web-search(联网搜索), // roleplay(角色扮演), office-services(办公服务) 暂时分为 5 类，从中选择相应的标签 &amp;#34;type&amp;#34;: &amp;#34;模板类别&amp;#34;, // simple(简易应用), advanced(工作流), plugin(插件) &amp;#34;workflow&amp;#34;: { // 这个对象先不管，待会直接粘贴导出的工作流即可 &amp;#34;nodes&amp;#34;: [], &amp;#34;edges&amp;#34;: [], &amp;#34;chatConfig&amp;#34;: {} } } 完成应用编排并测试 link 完成应用编排后，可以点击右上角的发布。</description></item><item><title>长字幕翻译</title><link>https://doc.tryfastgpt.ai/docs/use-cases/app-cases/translate-subtitle-using-gpt/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/use-cases/app-cases/translate-subtitle-using-gpt/</guid><description>直接使用 LLM 来翻译长字幕会遇到很多难点，这些难点也正是直接使用 AI 无法有效处理的问题：
Tokens 限制：这是最明显的障碍。大语言模型 (LLM) 通常有输出 tokens 的限制，这意味着对于长文本，如果不使用特殊的工作流，可能需要手动将文本分段，逐段输入 AI 进行翻译，然后再手动拼接结果。这个过程不仅繁琐，还容易出错。
字幕格式的保持：对于字幕来说，时间轴信息至关重要。然而，AI 模型有时会产生 “幻觉”，即无中生有地修改或生成不存在的信息。在字幕翻译中，这可能导致 AI 错误地修改时间轴，使字幕与音频不同步。
翻译质量：简单的机器翻译往往无法满足观众的需求。即使是大语言模型，单轮翻译的质量也常常不尽如人意。对于字幕来说，翻译质量直接影响观看体验，糟糕的翻译会严重影响观众的沉浸感。
本案例将展示如何利用 FastGPT 工作流代码结合 LLM 来有效解决这些问题。我们的方法不仅能克服技术限制，还能显著提升翻译质量。
提取字幕信息 link工作流的一大优势在于可以结合额外的操作，使 AI 能更精准地处理信息。在字幕翻译中，我们可以先分离 SRT 字幕文件的各个组成部分，然后只让 LLM 翻译文本部分。这种方法既节约了 token 使用，又确保了时间轴信息不被误改。
具体实现如下：
使用代码执行模块，对输入的原始字幕文本进行解析。 将字幕信息分类为三部分：时间信息、序号信息和文本信息。 只保留文本信息用于后续的 AI 翻译。 这种预处理步骤大大提高了整个翻译过程的效率和准确性。
切分文本 link为了进一步优化翻译过程，我们需要将提取出的文本信息重新组织。这一步的目的是将文本分割成适合 LLM 处理的大小，同时保持上下文的连贯性。
在本例中，我们采用以下策略：
将文本按照每 40 句为一组进行切分。这个数字是经过多次测试后得出的平衡点，既能保证翻译质量，又不会超出 LLM 的处理能力。 使用 标签分割每句文本。这种标记方法便于后续的重新组装，同时也为 AI 模型提供了清晰的句子边界。 这种切分方法既考虑了 AI 模型的能力限制，又保证了翻译的连贯性。通过保持适当的上下文，我们可以得到更加准确和自然的翻译结果。
格式化原文本 link在这一步，我们构建了最终输入给 LLM 的原文本。这个步骤的关键在于如何在控制 tokens 数量的同时，为 AI 提供足够的上下文信息。我们采用了以下策略：
传入所有文本作为背景上下文。这确保 AI 能理解整段对话的语境。 使用&amp;lt;TRANSLATE_THIS&amp;gt;标签明确指出当前需要翻译的片段。这种方法既能控制 AI 的输出范围，又不会丢失整体语境。 这种格式化方法使得 AI 能在理解全局的基础上，专注于翻译特定部分，从而提高翻译的准确性和连贯性。</description></item><item><title>多轮翻译机器人</title><link>https://doc.tryfastgpt.ai/docs/use-cases/app-cases/multi_turn_translation_bot/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/use-cases/app-cases/multi_turn_translation_bot/</guid><description>吴恩达老师提出了一种反思翻译的大语言模型(LLM)翻译工作流程——GitHub - andrewyng/translation-agent，具体工作流程如下：
提示一个 LLM 将文本从 source_language 翻译到 target_language； 让 LLM 反思翻译结果并提出建设性的改进建议； 使用这些建议来改进翻译。 这个翻译流程应该是目前比较新的一种翻译方式，利用 LLM 对自己的翻译结果进行改进来获得较好的翻译效果
项目中展示了可以利用对长文本进行分片，然后分别进行反思翻译处理，以突破 LLM 对 tokens 数量的限制，真正实现长文本一键高效率高质量翻译。
项目还通过给大模型限定国家地区，已实现更精确的翻译，如美式英语、英式英语之分；同时提出一些可能能带来更好效果的优化，如对于一些 LLM 未曾训练到的术语（或有多种翻译方式的术语）建立术语表，进一步提升翻译的精确度等等
而这一切都能通过 Fastgpt 工作流轻松实现，本文将手把手教你如何复刻吴恩达老师的 translation-agent
单文本块反思翻译 link先从简单的开始，即不超出 LLM tokens 数量限制的单文本块翻译
初始翻译 link第一步先让 LLM 对源文本块进行初始翻译（翻译的提示词在源项目中都有）
通过文本拼接模块引用 源语言、目标语言、源文本这三个参数，生成提示词，传给 LLM，让它给出第一版的翻译
反思 link然后让 LLM 对第一步生成的初始翻译给出修改建议，称之为 反思
这时的提示词接收 5 个参数，源文本、初始翻译、源语言、目标语言 以及限定词地区国家，这样 LLM 会对前面生成的翻译提出相当多的修改建议，为后续的提升翻译作准备
提升翻译 link 在前文生成了初始翻译以及相应的反思后，将这二者输入给第三次 LLM 翻译，这样我们就能获得一个比较高质量的翻译结果
完整的工作流如下
运行效果 link由于考虑之后对这个反思翻译的复用，所以创建了一个插件，那么在下面我直接调用这个插件就能使用反思翻译，效果如下
随机挑选了一段哈利波特的文段
可以看到反思翻译后的效果还是好上不少的，其中反思的输出如下
长文反思翻译 link在掌握了对短文本块的反思翻译后，我们能轻松的通过分片和循环，实现对长文本也即多文本块的反思翻译
整体的逻辑是，首先对传入文本的 tokens数量做判断，如果不超过设置的 tokens 限制，那么直接调用单文本块反思翻译，如果超过设置的 tokens限制，那么切割为合理的大小，再分别进行对应的反思翻译处理
计算 tokens link 首先，我使用了 Laf函数 模块来实现对输入文本的 tokens 的计算</description></item><item><title>英语作文纠错机器人</title><link>https://doc.tryfastgpt.ai/docs/use-cases/app-cases/english_essay_correction_bot/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/use-cases/app-cases/english_essay_correction_bot/</guid><description>FastGPT 提供了一种基于 LLM Model 搭建应用的简便方式。
本文通过搭建一个英语作文纠错机器人，介绍一下如何使用 工作流
搭建过程 link1. 创建工作流 link 可以从 多轮翻译机器人 开始创建。
多轮翻译机器人是 @米开朗基杨 同学创建的，同样也是一个值得学习的工作流。
2. 获取输入，使用大模型进行分析 link我们期望让大模型处理文字，返回一个结构化的数据，由我们自己处理。
提示词 是最重要的一个参数，这里提供的提示词仅供参考：
## 角色 资深英语写作专家 ## 任务 对输入的原文进行分析。 找出其中的各种错误， 包括但不限于单词拼写错误、 语法错误等。 注意： 忽略标点符号前后空格的问题。 注意： 对于存在错误的句子， 提出修改建议是指指出这个句子中的具体部分， 然后提出将这一个部分修改替换为什么。 ## 输出格式 不要使用 Markdown 语法， 输入 JSON 格式的内容。 输出的&amp;#34;reason&amp;#34;的内容使用中文。 直接输出一个列表， 其成员为一个相同类型的对象， 定义如下 您正在找回 FastGPT 账号 ``` { “raw”: string; // 表示原文 “reason”: string; // 表示原因 “suggestion”: string; // 修改建议 } ``` 可以在模型选择的窗口中设置禁用 AI 回复。</description></item><item><title>固定开头和结尾内容</title><link>https://doc.tryfastgpt.ai/docs/use-cases/app-cases/fixingevidence/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/use-cases/app-cases/fixingevidence/</guid><description>如上图，可以通过指定回复编排一个固定的开头和结尾内容。
模块编排 link复制下面配置，点击「高级编排」右上角的导入按键，导入该配置。
编排配置 { &amp;#34;nodes&amp;#34;: [ { &amp;#34;nodeId&amp;#34;: &amp;#34;7z5g5h&amp;#34;, &amp;#34;name&amp;#34;: &amp;#34;流程开始&amp;#34;, &amp;#34;intro&amp;#34;: &amp;#34;&amp;#34;, &amp;#34;avatar&amp;#34;: &amp;#34;/imgs/workflow/userChatInput.svg&amp;#34;, &amp;#34;flowNodeType&amp;#34;: &amp;#34;workflowStart&amp;#34;, &amp;#34;position&amp;#34;: { &amp;#34;x&amp;#34;: -269.50851681351924, &amp;#34;y&amp;#34;: 1657.6123698022448 }, &amp;#34;inputs&amp;#34;: [ { &amp;#34;key&amp;#34;: &amp;#34;userChatInput&amp;#34;, &amp;#34;renderTypeList&amp;#34;: [ &amp;#34;reference&amp;#34;, &amp;#34;textarea&amp;#34; ], &amp;#34;valueType&amp;#34;: &amp;#34;string&amp;#34;, &amp;#34;label&amp;#34;: &amp;#34;问题输入&amp;#34;, &amp;#34;required&amp;#34;: true, &amp;#34;toolDescription&amp;#34;: &amp;#34;用户问题&amp;#34;, &amp;#34;type&amp;#34;: &amp;#34;systemInput&amp;#34;, &amp;#34;showTargetInApp&amp;#34;: false, &amp;#34;showTargetInPlugin&amp;#34;: false, &amp;#34;connected&amp;#34;: false, &amp;#34;selectedTypeIndex&amp;#34;: 0, &amp;#34;value&amp;#34;: [ &amp;#34;7z5g5h&amp;#34;, &amp;#34;userChatInput&amp;#34; ] } ], &amp;#34;outputs&amp;#34;: [ { &amp;#34;id&amp;#34;: &amp;#34;userChatInput&amp;#34;, &amp;#34;type&amp;#34;: &amp;#34;static&amp;#34;, &amp;#34;key&amp;#34;: &amp;#34;userChatInput&amp;#34;, &amp;#34;valueType&amp;#34;: &amp;#34;string&amp;#34;, &amp;#34;label&amp;#34;: &amp;#34;core.</description></item><item><title>实验室预约</title><link>https://doc.tryfastgpt.ai/docs/use-cases/app-cases/lab_appointment/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/use-cases/app-cases/lab_appointment/</guid><description>本示例演示了利用工具调用，自动选择调用知识库搜索实验室相关内容，或调用 HTTP 模块实现数据库的 CRUD 操作。
以一个实验室预约为例，用户可以通过对话系统预约、取消、修改预约和查询预约记录。
1. 全局变量使用 link通过设计一个全局变量，让用户输入姓名，模拟用户身份信息。实际使用过程中，通常是直接通过嵌入 Token 来标记用户身份。
2. 工具调用 link 背景知识中，引导模型调用工具去执行不通的操作。
🤗
Tips: 这里需要增加适当的上下文，方便模型结合历史纪录进行判断和决策~
3. HTTP 模块 link HTTP模块中，需要设置 3 个工具参数：
预约行为：可取 get, put, post, delete 四个值，分别对应查询、修改、新增、删除操作。当然，你也可以写4个HTTP模块，来分别处理。 labname: 实验室名。非必填，因为查询和删除时候，不需要。 time: 预约时间。 总结 link 工具调用模块是非常强大的功能，可以在一定程度上替代问题分类和内容提取。 通过工具模块，动态的调用不同的工具，可以将复杂业务解耦。 附件 link编排配置 link可直接复制，导入到 FastGPT 中。
编排配置 { &amp;#34;nodes&amp;#34;: [ { &amp;#34;nodeId&amp;#34;: &amp;#34;userChatInput&amp;#34;, &amp;#34;name&amp;#34;: &amp;#34;流程开始&amp;#34;, &amp;#34;intro&amp;#34;: &amp;#34;当用户发送一个内容后，流程将会从这个模块开始执行。&amp;#34;, &amp;#34;avatar&amp;#34;: &amp;#34;/imgs/workflow/userChatInput.svg&amp;#34;, &amp;#34;flowNodeType&amp;#34;: &amp;#34;workflowStart&amp;#34;, &amp;#34;position&amp;#34;: { &amp;#34;x&amp;#34;: 309.7143912167367, &amp;#34;y&amp;#34;: 1501.2761754220846 }, &amp;#34;inputs&amp;#34;: [ { &amp;#34;key&amp;#34;: &amp;#34;userChatInput&amp;#34;, &amp;#34;renderTypeList&amp;#34;: [ &amp;#34;reference&amp;#34;, &amp;#34;textarea&amp;#34; ], &amp;#34;valueType&amp;#34;: &amp;#34;string&amp;#34;, &amp;#34;label&amp;#34;: &amp;#34;问题输入&amp;#34;, &amp;#34;required&amp;#34;: true, &amp;#34;toolDescription&amp;#34;: &amp;#34;用户问题&amp;#34;, &amp;#34;type&amp;#34;: &amp;#34;systemInput&amp;#34;, &amp;#34;showTargetInApp&amp;#34;: false, &amp;#34;showTargetInPlugin&amp;#34;: false, &amp;#34;connected&amp;#34;: false, &amp;#34;selectedTypeIndex&amp;#34;: 0, &amp;#34;value&amp;#34;: [ &amp;#34;userChatInput&amp;#34;, &amp;#34;userChatInput&amp;#34; ] } ], &amp;#34;outputs&amp;#34;: [ { &amp;#34;id&amp;#34;: &amp;#34;userChatInput&amp;#34;, &amp;#34;type&amp;#34;: &amp;#34;static&amp;#34;, &amp;#34;key&amp;#34;: &amp;#34;userChatInput&amp;#34;, &amp;#34;valueType&amp;#34;: &amp;#34;string&amp;#34;, &amp;#34;label&amp;#34;: &amp;#34;core.</description></item><item><title>Dalle3 绘图</title><link>https://doc.tryfastgpt.ai/docs/use-cases/app-cases/dalle3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/use-cases/app-cases/dalle3/</guid><description>OpenAI Dalle3 接口 link先来看下官方接口的参数和响应值：
Body
{ &amp;#34;model&amp;#34;: &amp;#34;dall-e-3&amp;#34;, &amp;#34;prompt&amp;#34;: &amp;#34;A cute baby sea otter&amp;#34;, &amp;#34;n&amp;#34;: 1, &amp;#34;size&amp;#34;: &amp;#34;1024x1024&amp;#34; } Response
{ &amp;#34;created&amp;#34;: 1589478378, &amp;#34;data&amp;#34;: [ { &amp;#34;url&amp;#34;: &amp;#34;https://...&amp;#34; }, { &amp;#34;url&amp;#34;: &amp;#34;https://...&amp;#34; } ] } 编排思路 link 通过 AI 来优化图片绘制的提示词（这步省略了，自己找提示词即可） 通过 【HTTP 请求】模块 调用 Dalle3 接口，获取图片的 URL。 通过 【文本加工】模块 来构建 Markdown 的图片格式。 通过 【指定回复】模块 来直接输出图片链接。 1. 构建 HTTP 模块 link请求参数直接复制 Dalle3 接口的即可，并求改 prompt 为变量。需要增加一个 Headers.Authorization 。
Body:
{ &amp;#34;model&amp;#34;: &amp;#34;dall-e-3&amp;#34;, &amp;#34;prompt&amp;#34;: &amp;#34;{{prompt}}&amp;#34;, &amp;#34;n&amp;#34;: 1, &amp;#34;size&amp;#34;: &amp;#34;1024x1024&amp;#34; } Headers:</description></item><item><title>接入谷歌搜索</title><link>https://doc.tryfastgpt.ai/docs/use-cases/app-cases/google_search/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/use-cases/app-cases/google_search/</guid><description>工具调用模式 工具调用模式 非工具调用模式 非工具调用模式 如上图，利用「HTTP请求」模块，你可以外接一个搜索引擎作为 AI 回复的参考资料。这里以调用 Google Search API 为例。注意：本文主要是为了介绍 「HTTP请求」模块，具体的搜索效果需要依赖提示词和搜索引擎，尤其是【搜索引擎】，简单的搜索引擎无法获取更详细的内容，这部分可能需要更多的调试。
注册 Google Search API link参考这篇文章，每天可以免费使用 100 次。
写一个 Google Search 接口 link这里用 Laf 快速实现一个接口，即写即发布，无需部署。务必打开 POST 请求方式。
Laf 谷歌搜索Demo import cloud from &amp;#39;@lafjs/cloud&amp;#39; const googleSearchKey = &amp;#34;xxx&amp;#34; const googleCxId = &amp;#34;3740cxxx&amp;#34; const baseurl = &amp;#34;https://www.googleapis.com/customsearch/v1&amp;#34; type RequestType = { searchKey: string } export default async function (ctx: FunctionContext) { const { searchKey } = ctx.body as RequestType console.log(ctx.body) if (!</description></item><item><title>发送飞书webhook通知</title><link>https://doc.tryfastgpt.ai/docs/use-cases/app-cases/feishu_webhook/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/use-cases/app-cases/feishu_webhook/</guid><description>该文章展示如何发送一个简单的飞书webhook通知，以此类推，发送其他类型的通知也可以这么操作。
1. 准备飞书机器人 link 2. 导入编排代码 link复制下面配置，点击「高级编排」右上角的导入按键，导入该配置，导入后将飞书提供的接口地址复制到「HTTP 模块」。
编排配置 { &amp;#34;nodes&amp;#34;: [ { &amp;#34;nodeId&amp;#34;: &amp;#34;userGuide&amp;#34;, &amp;#34;name&amp;#34;: &amp;#34;系统配置&amp;#34;, &amp;#34;intro&amp;#34;: &amp;#34;可以配置应用的系统参数&amp;#34;, &amp;#34;avatar&amp;#34;: &amp;#34;/imgs/workflow/userGuide.png&amp;#34;, &amp;#34;flowNodeType&amp;#34;: &amp;#34;userGuide&amp;#34;, &amp;#34;position&amp;#34;: { &amp;#34;x&amp;#34;: 303.41163758039283, &amp;#34;y&amp;#34;: -552.297639861266 }, &amp;#34;version&amp;#34;: &amp;#34;481&amp;#34;, &amp;#34;inputs&amp;#34;: [], &amp;#34;outputs&amp;#34;: [] }, { &amp;#34;nodeId&amp;#34;: &amp;#34;workflowStartNodeId&amp;#34;, &amp;#34;name&amp;#34;: &amp;#34;流程开始&amp;#34;, &amp;#34;intro&amp;#34;: &amp;#34;&amp;#34;, &amp;#34;avatar&amp;#34;: &amp;#34;/imgs/workflow/userChatInput.svg&amp;#34;, &amp;#34;flowNodeType&amp;#34;: &amp;#34;workflowStart&amp;#34;, &amp;#34;position&amp;#34;: { &amp;#34;x&amp;#34;: 529.3935295017156, &amp;#34;y&amp;#34;: 197.114018410347 }, &amp;#34;version&amp;#34;: &amp;#34;481&amp;#34;, &amp;#34;inputs&amp;#34;: [ { &amp;#34;key&amp;#34;: &amp;#34;userChatInput&amp;#34;, &amp;#34;renderTypeList&amp;#34;: [ &amp;#34;reference&amp;#34;, &amp;#34;textarea&amp;#34; ], &amp;#34;valueType&amp;#34;: &amp;#34;string&amp;#34;, &amp;#34;label&amp;#34;: &amp;#34;用户问题&amp;#34;, &amp;#34;required&amp;#34;: true, &amp;#34;toolDescription&amp;#34;: &amp;#34;用户问题&amp;#34; } ], &amp;#34;outputs&amp;#34;: [ { &amp;#34;id&amp;#34;: &amp;#34;userChatInput&amp;#34;, &amp;#34;key&amp;#34;: &amp;#34;userChatInput&amp;#34;, &amp;#34;label&amp;#34;: &amp;#34;core.</description></item><item><title>快速开始本地开发</title><link>https://doc.tryfastgpt.ai/docs/development/intro/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/intro/</guid><description>本文档介绍了如何设置开发环境以构建和测试 FastGPT，。
前置依赖项 link您需要在计算机上安装和配置以下依赖项才能构建 FastGPT：
Git Docker（构建镜像） Node.js v20.14.0（版本尽量一样，可以使用nvm管理node版本） pnpm 推荐版本 9.4.0 (目前官方的开发环境) make命令: 根据不同平台，百度安装 (官方是GNU Make 4.3) 开始本地开发 link check_circle 用户默认的时区为 Asia/Shanghai,非 linux 环境时候，获取系统时间会异常，本地开发时候，可以将用户的时区调整成 UTC（+0）。 建议先服务器装好数据库，再进行本地开发。 1. Fork 存储库 link您需要 Fork 存储库。
2. 克隆存储库 link克隆您在 GitHub 上 Fork 的存储库：
git clone git@github.com:&amp;lt;github_username&amp;gt;/FastGPT.git 目录简要说明
projects 目录下为 FastGPT 应用代码。其中 app 为 FastGPT 核心应用。（后续可能会引入其他应用） NextJS 框架前后端放在一起，API 服务位于 src/pages/api 目录内。 packages 目录为共用代码，通过 workspace 被注入到 projects 中，已配置 monorepo 自动注入，无需额外打包。 3. 安装数据库 link第一次开发，需要先部署数据库，建议本地开发可以随便找一台 2C2G 的轻量小数据库实践，或者新建文件夹并配置相关文件用以运行docker。数据库部署教程：Docker 快速部署。部署完了，可以本地访问其数据库。</description></item><item><title>Sealos 一键部署</title><link>https://doc.tryfastgpt.ai/docs/development/sealos/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/sealos/</guid><description>部署架构图 link 多模型支持 linkFastGPT 使用了 one-api 项目来管理模型池，其可以兼容 OpenAI 、Azure 、国内主流模型和本地模型等。
可参考：Sealos 快速部署 OneAPI
一键部署 link使用 Sealos 服务，无需采购服务器、无需域名，支持高并发 &amp;amp; 动态伸缩，并且数据库应用采用 kubeblocks 的数据库，在 IO 性能方面，远超于简单的 Docker 容器部署。可以根据需求，再下面两个区域选择部署。
新加坡区 link新加披区的服务器在国外，可以直接访问 OpenAI，但国内用户需要梯子才可以正常访问新加坡区。国际区价格稍贵，点击下面按键即可部署👇
北京区 link北京区服务提供商为火山云，国内用户可以稳定访问，但无法访问 OpenAI 等境外服务，价格约为新加坡区的 1/4。点击下面按键即可部署👇
1. 开始部署 link由于需要部署数据库，部署完后需要等待 2~4 分钟才能正常访问。默认用了最低配置，首次访问时会有些慢。
根据提示，输入root_password，和 openai/oneapi 的地址和密钥。
点击部署后，会跳转到应用管理页面。可以点击fastgpt主应用右侧的详情按键（名字为 fastgpt-xxxx）， 如下图所示。
点击详情后，会跳转到 fastgpt 的部署管理页面，点击外网访问地址中的链接，即可打开 fastgpt 服务。
如需绑定自定义域名、修改部署参数，可以点击右上角变更，根据 sealos 的指引完成。
2. 登录 link用户名：root
密码是刚刚一键部署时设置的root_password
3. 配置模型 link4. 配置模型 link务必先配置至少一组模型，否则系统无法正常使用。
点击查看模型配置教程
收费 linkSealos 采用按量计费的方式，也就是申请了多少 cpu、内存、磁盘，就按该申请量进行计费。具体的计费标准，可以打开sealos控制面板中的费用中心进行查看。
Sealos 使用 link简介 linkFastGPT 商业版共包含了2个应用（fastgpt, fastgpt-plus）和2个数据库，使用多 Api Key 时候需要安装 OneAPI（一个应用和一个数据库），总计3个应用和3个数据库。</description></item><item><title>Docker Compose 快速部署</title><link>https://doc.tryfastgpt.ai/docs/development/docker/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/docker/</guid><description>前置知识 link 基础的网络知识：端口，防火墙…… Docker 和 Docker Compose 基础知识 大模型相关接口和参数 RAG 相关知识：向量模型，向量数据库，向量检索 部署架构图 link 🤖
MongoDB：用于存储除了向量外的各类数据
PostgreSQL/Milvus：存储向量数据
OneAPI: 聚合各类 AI API，支持多模型调用 （任何模型问题，先自行通过 OneAPI 测试校验）
推荐配置 linkPgVector版本 link非常轻量，适合知识库索引量在 5000 万以下。
环境 最低配置（单节点） 推荐配置 测试（可以把计算进程设置少一些） 2c4g 2c8g 100w 组向量 4c8g 50GB 4c16g 50GB 500w 组向量 8c32g 200GB 16c64g 200GB Milvus版本 link对于亿级以上向量性能更优秀。
点击查看 Milvus 官方推荐配置
环境 最低配置（单节点） 推荐配置 测试 2c8g 4c16g 100w 组向量 未测试 500w 组向量 zilliz cloud版本 linkZilliz Cloud 由 Milvus 原厂打造，是全托管的 SaaS 向量数据库服务，性能优于 Milvus 并提供 SLA，点击使用 Zilliz Cloud。</description></item><item><title>SSO &amp; 外部成员同步</title><link>https://doc.tryfastgpt.ai/docs/guide/admin/sso/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/guide/admin/sso/</guid><description>如果你不需要用到 SSO/成员同步功能，或者是只需要用 Github、google、microsoft、公众号的快速登录，可以跳过本章节。本章适合需要接入自己的成员系统或主流 办公IM 的用户。
介绍 link为了方便地接入外部成员系统，FastGPT 提供一套接入外部系统的标准接口，以及一个 FastGPT-SSO-Service 镜像作为适配器。
通过这套标注接口，你可以可以实现：
SSO 登录。从外部系统回调后，在 FastGPT 中创建一个用户。 成员和组织架构同步（下面都简称成员同步）。 原理
FastGPT-pro 中，有一套标准的SSO 和成员同步接口，系统会根据这套接口进行 SSO 和成员同步操作。
FastGPT-SSO-Service 是为了聚合不同来源的 SSO 和成员同步接口，将他们转成 fastgpt-pro 可识别的接口。
系统配置教程 link1. 部署 SSO-service 镜像 link使用 docker-compose 部署：
fastgpt-sso: image: registry.cn-hangzhou.aliyuncs.com/fastgpt/fastgpt-sso-service:v4.9.0 container_name: fastgpt-sso restart: always networks: - fastgpt environment: - SSO_PROVIDER=example - AUTH_TOKEN=xxxxx # 鉴权信息，fastgpt-pro 会用到。 # 具体对接提供商的环境变量。 根据不同的提供商，你需要配置不同的环境变量，下面是内置的通用协议/IM：
协议/功能 SSO 成员同步支持 飞书 是 是 企业微信 是 是 钉钉 是 否 Saml2.0 是 否 Oauth2.</description></item><item><title>配置文件介绍</title><link>https://doc.tryfastgpt.ai/docs/development/configuration/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/configuration/</guid><description>由于环境变量不利于配置复杂的内容，新版 FastGPT 采用了 ConfigMap 的形式挂载配置文件，你可以在 projects/app/data/config.json 看到默认的配置文件。可以参考 docker-compose 快速部署 来挂载配置文件。
开发环境下，你需要将示例配置文件 config.json 复制成 config.local.json 文件才会生效。
下面配置文件示例中包含了系统参数和各个模型配置：
4.8.20+ 版本新配置文件示例 link 从4.8.20版本开始，模型在页面中进行配置。
{ &amp;#34;feConfigs&amp;#34;: { &amp;#34;lafEnv&amp;#34;: &amp;#34;https://laf.dev&amp;#34; // laf环境。 https://laf.run （杭州阿里云） ,或者私有化的laf环境。如果使用 Laf openapi 功能，需要最新版的 laf 。 }, &amp;#34;systemEnv&amp;#34;: { &amp;#34;vectorMaxProcess&amp;#34;: 15, // 向量处理线程数量 &amp;#34;qaMaxProcess&amp;#34;: 15, // 问答拆分线程数量 &amp;#34;vlmMaxProcess&amp;#34;: 15, // 图片理解模型最大处理进程 &amp;#34;tokenWorkers&amp;#34;: 50, // Token 计算线程保持数，会持续占用内存，不能设置太大。 &amp;#34;hnswEfSearch&amp;#34;: 100, // 向量搜索参数，仅对 PG 和 OB 生效。越大，搜索越精确，但是速度越慢。设置为100，有99%&amp;#43;精度。 &amp;#34;customPdfParse&amp;#34;: { // 4.9.0 新增配置 &amp;#34;url&amp;#34;: &amp;#34;&amp;#34;, // 自定义 PDF 解析服务地址 &amp;#34;key&amp;#34;: &amp;#34;&amp;#34;, // 自定义 PDF 解析服务密钥 &amp;#34;doc2xKey&amp;#34;: &amp;#34;&amp;#34;, // doc2x 服务密钥 &amp;#34;price&amp;#34;: 0 // PDF 解析服务价格 } } } 自定义 PDF 解析配置 link自定义 PDF 服务解析的优先级高于 Doc2x 服务，所以如果使用 Doc2x 服务，请勿配置自定义 PDF 服务。</description></item><item><title>团队模式说明文档</title><link>https://doc.tryfastgpt.ai/docs/guide/admin/teammode/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/guide/admin/teammode/</guid><description>介绍 link目前支持的团队模式：
多团队模式（默认模式） 单团队模式（全局只有一个团队） 成员同步模式（所有成员自外部同步） 团队模式 短信/邮箱 注册 管理员直接添加 SSO 注册 是否创建默认团队 是否加入 Root 团队 是否创建默认团队 是否加入 Root 团队 是否创建默认团队 是否加入 Root 团队 单团队模式 ❌ ✅ ❌ ✅ ❌ ✅ 多团队模式 ✅ ❌ ✅ ❌ ✅ ❌ 同步模式 ❌ ❌ ❌ ✅ ❌ ✅ 多团队模式（默认模式） link多团队模式下，每个用户创建时默认创建以自己为所有者的默认团队。
单团队模式 link单团队模式是 v4.9 推出的新功能。为了简化企业进行人员和资源的管理，开启单团队模式后，所有新增的用户都不再创建自己的默认团队，而是加入 root 用户所在的团队。
同步模式 link在完成系统配置，开启同步模式的情况下，外部成员系统的成员会自动同步到 FastGPT 中。
具体的同步方式和规则请参考 SSO &amp;amp; 外部成员同步。
配置 link在 fastgpt-pro 的系统配置-成员配置中，可以配置团队模式。</description></item><item><title>私有部署常见问题</title><link>https://doc.tryfastgpt.ai/docs/development/faq/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/faq/</guid><description>一、错误排查方式 link可以先找找Issue，或新提 Issue，私有部署错误，务必提供详细的操作步骤、日志、截图，否则很难排查。
获取后端错误 link docker ps -a 查看所有容器运行状态，检查是否全部 running，如有异常，尝试docker logs 容器名查看对应日志。 容器都运行正常的，docker logs 容器名 查看报错日志 前端错误 link前端报错时，页面会出现崩溃，并提示检查控制台日志。可以打开浏览器控制台，并查看console中的 log 日志。还可以点击对应 log 的超链接，会提示到具体错误文件，可以把这些详细错误信息提供，方便排查。
OneAPI 错误 link带有requestId的，都是 OneAPI 提示错误，大部分都是因为模型接口报错。可以参考 OneAPI 常见错误
二、通用问题 link前端页面崩溃 link 90% 情况是模型配置不正确：确保每类模型都至少有一个启用；检查模型中一些对象参数是否异常（数组和对象），如果为空，可以尝试给个空数组或空对象。 少部分是由于浏览器兼容问题，由于项目中包含一些高阶语法，可能低版本浏览器不兼容，可以将具体操作步骤和控制台中错误信息提供 issue。 关闭浏览器翻译功能，如果浏览器开启了翻译，可能会导致页面崩溃。 通过sealos部署的话，是否没有本地部署的一些限制？ link 这是索引模型的长度限制，通过任何方式部署都一样的，但不同索引模型的配置不一样，可以在后台修改参数。
怎么挂载小程序配置文件 link将验证文件，挂载到指定位置：/app/projects/app/public/xxxx.txt
然后重启。例如:
数据库3306端口被占用了，启动服务失败 link 把端口映射改成 3307 之类的，例如 3307:3306。
本地部署的限制 link具体内容参考https://fael3z0zfze.feishu.cn/wiki/OFpAw8XzAi36Guk8dfucrCKUnjg。
能否纯本地运行 link可以。需要准备好向量模型和LLM模型。
其他模型没法进行问题分类/内容提取 link 看日志。如果提示 JSON invalid，not support tool 之类的，说明该模型不支持工具调用或函数调用，需要设置toolChoice=false和functionCall=false，就会默认走提示词模式。目前内置提示词仅针对了商业模型API进行测试。问题分类基本可用，内容提取不太行。 如果已经配置正常，并且没有错误日志，则说明可能提示词不太适合该模型，可以通过修改customCQPrompt来自定义提示词。 页面崩溃 link 关闭翻译 检查配置文件是否正常加载，如果没有正常加载会导致缺失系统信息，在某些操作下会导致空指针。 95%情况是配置文件不对。会提示 xxx undefined 提示URI malformed，请 Issue 反馈具体操作和页面，这是由于特殊字符串编码解析报错。 某些api不兼容问题（较少） 开启内容补全后，响应速度变慢 link 问题补全需要经过一轮AI生成。 会进行3~5轮的查询，如果数据库性能不足，会有明显影响。 页面中可以正常回复，API 报错 link页面中是用 stream=true 模式，所以API也需要设置 stream=true 来进行测试。部分模型接口（国产居多）非 Stream 的兼容有点垃圾。 和上一个问题一样，curl 测试。</description></item><item><title>FastGPT 模型配置说明</title><link>https://doc.tryfastgpt.ai/docs/development/modelconfig/intro/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/modelconfig/intro/</guid><description>在 4.8.20 版本以前，FastGPT 模型配置在 config.json 文件中声明，你可以在 https://github.com/labring/FastGPT/blob/main/projects/app/data/model.json 中找到旧版的配置文件示例。
从 4.8.20 版本开始，你可以直接在 FastGPT 页面中进行模型配置，并且系统内置了大量模型，无需从 0 开始配置。下面介绍模型配置的基本流程：
配置模型 link1. 对接模型提供商 linkAI Proxy link从 4.8.23 版本开始， FastGPT 支持在页面上配置模型提供商，即使用 AI Proxy 接入教程 来进行模型聚合，从而可以对接更多模型提供商。
One API link也可以使用 OneAPI 接入教程。你需要先在各服务商申请好 API 接入 OneAPI 后，才能在 FastGPT 中使用这些模型。示例流程如下：
除了各模型官方的服务外，还有一些第三方服务商提供模型接入服务，当然你也可以用 Ollama 等来部署本地模型，最终都需要接入 OneAPI，下面是一些第三方服务商：
SiliconCloud(硅基流动): 提供开源模型调用的平台。
Sealos AIProxy: 提供国内各家模型代理，无需逐一申请 api。
在 OneAPI 配置好模型后，你就可以打开 FastGPT 页面，启用对应模型了。
2. 配置介绍 link 🤖
注意：
目前语音识别模型和重排模型仅会生效一个，所以配置时候，只需要配置一个即可。 系统至少需要一个语言模型和一个索引模型才能正常使用。 核心配置 link 模型 ID：接口请求时候，Body 中model字段的值，全局唯一。 自定义请求地址/Key：如果需要绕过OneAPI，可以设置自定义请求地址和 Token。一般情况下不需要，如果 OneAPI 不支持某些模型，可以使用该特性。 模型类型 link 语言模型 - 进行文本对话，多模态模型支持图片识别。 索引模型 - 对文本块进行索引，用于相关文本检索。 重排模型 - 对检索结果进行重排，用于优化检索排名。 语音合成 - 将文本转换为语音。 语音识别 - 将语音转换为文本。 启用模型 link系统内置了目前主流厂商的模型，如果你不熟悉配置，直接点击启用即可，需要注意的是，模型 ID需要和 OneAPI 中渠道的模型一致。</description></item><item><title>通过 AI Proxy 接入模型</title><link>https://doc.tryfastgpt.ai/docs/development/modelconfig/ai-proxy/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/modelconfig/ai-proxy/</guid><description>从 FastGPT 4.8.23 版本开始，引入 AI Proxy 来进一步方便模型的配置。
AI Proxy 与 One API 类似，也是作为一个 OpenAI 接口管理 &amp;amp; 分发系统，可以通过标准的 OpenAI API 格式访问所有的大模型，开箱即用。
部署 linkDocker 版本 linkdocker-compose.yml 文件已加入了 AI Proxy 配置，可直接使用。点击查看最新的 yml 配置
从旧版升级的用户，可以复制 yml 里，ai proxy 的配置，加入到旧的 yml 文件中。
运行原理 linkAI proxy 核心模块:
渠道管理：管理各家模型提供商的 API Key 和可用模型列表。 模型调用：根据请求的模型，选中对应的渠道；根据渠道的 API 格式，构造请求体，发送请求；格式化响应体成标准格式返回。 调用日志：详细记录模型调用的日志，并在错误时候可以记录其入参和报错信息，方便排查。 运行流程：
在 FastGPT 中使用 linkAI proxy 相关功能，可以在账号-模型提供商页面找到。
1. 创建渠道 link在模型提供商的配置页面，点击模型渠道，进入渠道配置页面
点击右上角的“新增渠道”，即可进入渠道配置页面
以阿里云的模型为例，进行如下配置
渠道名：展示在外部的渠道名称，仅作标识; 厂商：模型对应的厂商，不同厂商对应不同的默认地址和 API 密钥格式; 模型：当前渠道具体可以使用的模型，系统内置了主流的一些模型，如果下拉框中没有想要的选项，可以点击“新增模型”，增加自定义模型; 模型映射：将 FastGPT 请求的模型，映射到具体提供的模型上。例如： { &amp;#34;gpt-4o-test&amp;#34;: &amp;#34;gpt-4o&amp;#34;, } FatGPT 中的模型为 gpt-4o-test，向 AI Proxy 发起请求时也是 gpt-4o-test。AI proxy 在向上游发送请求时，实际的model为 gpt-4o。</description></item><item><title>通过 OneAPI 接入模型</title><link>https://doc.tryfastgpt.ai/docs/development/modelconfig/one-api/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/modelconfig/one-api/</guid><description>FastGPT 目前采用模型分离的部署方案，FastGPT 中只兼容 OpenAI 的模型规范（OpenAI 不存在的模型采用一个较为通用的规范），并通过 One API 来实现对不同模型接口的统一。
One API 是一个 OpenAI 接口管理 &amp;amp; 分发系统，可以通过标准的 OpenAI API 格式访问所有的大模型，开箱即用。
FastGPT 与 One API 关系 link可以把 One API 当做一个网关，FastGPT 与 One API 关系：
部署 linkSealos 版本 link 北京区: 点击部署 OneAPI 新加坡区(可用 GPT) 点击部署 OneAPI 部署完后，可以打开 OneAPI 访问链接，进行下一步操作。
OneAPI 基础教程 link概念 link 渠道： OneApi 中一个渠道对应一个 Api Key，这个 Api Key 可以是GPT、微软、ChatGLM、文心一言的。一个Api Key通常可以调用同一个厂商的多个模型。 One API 会根据请求传入的模型来决定使用哪一个渠道，如果一个模型对应了多个渠道，则会随机调用。 令牌：访问 One API 所需的凭证，只需要这1个凭证即可访问One API上配置的模型。因此FastGPT中，只需要配置One API的baseurl和令牌即可。令牌不要设置任何的模型范围权限，否则容易报错。 大致工作流程 link 客户端请求 One API 根据请求中的 model 参数，匹配对应的渠道（根据渠道里的模型进行匹配，必须完全一致）。如果匹配到多个渠道，则随机选择一个（同优先级）。 One API 向真正的地址发出请求。 One API 将结果返回给客户端。 1.</description></item><item><title>通过 SiliconCloud 体验开源模型</title><link>https://doc.tryfastgpt.ai/docs/development/modelconfig/siliconcloud/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/modelconfig/siliconcloud/</guid><description>SiliconCloud(硅基流动) 是一个以提供开源模型调用为主的平台，并拥有自己的加速引擎。帮助用户低成本、快速的进行开源模型的测试和使用。实际体验下来，他们家模型的速度和稳定性都非常不错，并且种类丰富，覆盖语言、向量、重排、TTS、STT、绘图、视频生成模型，可以满足 FastGPT 中所有模型需求。
如果你想部分模型使用 SiliconCloud 的模型，可额外参考OneAPI接入硅基流动。
本文会介绍完全使用 SiliconCloud 模型来部署 FastGPT 的方案。
1. 注册 SiliconCloud 账号 link 点击注册硅基流动账号 进入控制台，获取 API key: https://cloud.siliconflow.cn/account/ak 2. 修改 FastGPT 环境变量 link OPENAI_BASE_URL=https://api.siliconflow.cn/v1 # 填写 SiliconCloud 控制台提供的 Api Key CHAT_API_KEY=sk-xxxxxx 3. 修改 FastGPT 模型配置 link系统内置了几个硅基流动的模型进行体验，如果需要其他模型，可以手动添加。
这里启动了 Qwen2.5 72b 的纯语言和视觉模型；选择 bge-m3 作为向量模型；选择 bge-reranker-v2-m3 作为重排模型。选择 fish-speech-1.5 作为语音模型；选择 SenseVoiceSmall 作为语音输入模型。
4. 体验测试 link测试对话和图片识别 link随便新建一个简易应用，选择对应模型，并开启图片上传后进行测试：
可以看到，72B 的模型，性能还是非常快的，这要是本地没几个 4090，不说配置环境，输出怕都要 30s 了。
测试知识库导入和知识库问答 link新建一个知识库（由于只配置了一个向量模型，页面上不会展示向量模型选择）
导入本地文件，直接选择文件，然后一路下一步即可。79 个索引，大概花了 20s 的时间就完成了。现在我们去测试一下知识库问答。
首先回到我们刚创建的应用，选择知识库，调整一下参数后即可开始对话：
对话完成后，点击底部的引用，可以查看引用详情，同时可以看到具体的检索和重排得分：
测试语音播放 link继续在刚刚的应用中，左侧配置中找到语音播放，点击后可以从弹窗中选择语音模型，并进行试听：</description></item><item><title>通过 PPIO LLM API 接入模型</title><link>https://doc.tryfastgpt.ai/docs/development/modelconfig/ppio/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/modelconfig/ppio/</guid><description>FastGPT 还可以通过 PPIO LLM API 接入模型。
warning 以下内容搬运自 FastGPT 接入 PPIO LLM API，可能会有更新不及时的情况。
FastGPT 是一个将 AI 开发、部署和使用全流程简化为可视化操作的平台。它使开发者不需要深入研究算法， 用户也不需要掌握复杂技术，通过一站式服务将人工智能技术变成易于使用的工具。
PPIO 派欧云提供简单易用的 API 接口，让开发者能够轻松调用 DeepSeek 等模型。
对开发者：无需重构架构，3 个接口完成从文本生成到决策推理的全场景接入，像搭积木一样设计 AI 工作流； 对生态：自动适配从中小应用到企业级系统的资源需求，让智能随业务自然生长。 下方教程提供完整接入方案（含密钥配置），帮助您快速将 FastGPT 与 PPIO API 连接起来。
1. 配置前置条件 link(1) 获取 API 接口地址
固定为: https://api.ppinfra.com/v3/openai/chat/completions。
(2) 获取 【API 密钥】
登录派欧云控制台 API 秘钥管理 页面，点击创建按钮。 注册账号填写邀请码【VOJL20】得 50 代金券
(3) 生成并保存 【API 密钥】
warning 秘钥在服务端是加密存储，请在生成时保存好秘钥；若遗失可以在控制台上删除并创建一个新的秘钥。
(4) 获取需要使用的模型 ID
deepseek 系列：
DeepSeek R1：deepseek/deepseek-r1/community
DeepSeek V3：deepseek/deepseek-v3/community
其他模型 ID、最大上下文及价格可参考：模型列表</description></item><item><title>升级说明</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/intro/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/intro/</guid><description>FastGPT 升级包括两个步骤：
镜像升级 执行升级初始化脚本 镜像名 linkgit版
FastGPT 主镜像：ghcr.io/labring/fastgpt:latest 商业版镜像：ghcr.io/c121914yu/fastgpt-pro:latest Admin 镜像：ghcr.io/c121914yu/fastgpt-admin:latest 阿里云
FastGPT 主镜像: registry.cn-hangzhou.aliyuncs.com/fastgpt/fastgpt 商业版镜像：ghcr:registry.cn-hangzhou.aliyuncs.com/fastgpt/fastgpt-pro Admin 镜像: registry.cn-hangzhou.aliyuncs.com/fastgpt/fastgpt-admin 镜像由镜像名和Tag组成，例如: registry.cn-hangzhou.aliyuncs.com/fastgpt/fastgpt:v4.6.1 代表4.6.3版本镜像，具体可以看 docker hub, github 仓库。
Sealos 修改镜像 link 打开 Sealos Cloud， 找到桌面上的应用管理 选择对应的应用 - 点击右边三个点 - 变更 修改镜像 - 确认变更
如果要修改配置文件，可以拉到下面的配置文件进行修改。
Docker-Compose 修改镜像 link直接修改yml文件中的image: 即可。随后执行:
docker-compose pull docker-compose up -d 执行升级初始化脚本 link镜像更新完后，可以查看文档中的版本介绍，通常需要执行升级脚本的版本都会标明包含升级脚本，打开对应的文档，参考说明执行升级脚本即可，大部分时候都是需要发送一个POST请求。
QA link为什么需要执行升级脚本 link数据表出现大幅度变更，无法通过设置默认值，或复杂度较高时，会通过升级脚本来更新部分数据表字段。 严格按初始化步骤进行操作，不会造成旧数据丢失。但在初始化过程中，如果数据量大，需要初始化的时间较长，这段时间可能会造成服务无法正常使用。
{{host}} 是什么 link{{}} 代表变量， {{host}}代表一个名为 host 的变量。指的是你服务器的域名或 IP。
Sealos 中，你可以在下图中找到你的域名：
如何获取 rootkey link从docker-compose.yml中的environment中获取，对应的是ROOT_KEY的值。</description></item><item><title>Docker Mongo迁移(dump模式)</title><link>https://doc.tryfastgpt.ai/docs/development/migration/docker_mongo/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/migration/docker_mongo/</guid><description>作者 linkhttps://github.com/samqin123
相关PR。有问题可打开这里与作者交流
介绍 link如何使用Mongodump来完成从A环境到B环境的Fastgpt的mongodb迁移
前提说明：
A环境：我在阿里云上部署的fastgpt，现在需要迁移到B环境。 B环境：是新环境比如腾讯云新部署的fastgpt，更特殊一点的是，NAS（群晖或者QNAP）部署了fastgpt，mongo必须改成4.2或者4.4版本（其实云端更方便，支持fastgpt mongo默认版本） C环境：妥善考虑，用本地电脑作为C环境过渡，保存相关文件并分离操作 ‍
1. 环境准备：进入 docker mongo 【A环境】 link docker exec -it mongo sh mongo -u &amp;#39;username&amp;#39; -p &amp;#39;password&amp;#39; &amp;gt;&amp;gt; show dbs 看到fastgpt数据库，以及其它几个，确定下导出数据库名称 准备： 检查数据库，容器和宿主机都创建一下 backup 目录 【A环境 + C环境】
准备： link检查数据库，容器和宿主机都创建一下“数据导出导入”临时目录 ，比如data/backup 【A环境建目录 + C环境建目录用于同步到容器中】
先在【A环境】创建文件目录，用于dump导出操作 link容器：（先进入fastgpt docker容器）
docker exec -it fastgpt sh mkdir -p /data/backup 建好后，未来导出mongo的数据，会在A环境本地fastgpt的安装目录/Data/下看到自动同步好的目录，数据会在data\backup中，然后可以衔接后续的压缩和下载转移动作。如果没有同步到本地，也可以手动建一下，配合docker cp 把文件拷到本地用（基本不会发生）
然后，【C环境】宿主机目录类似操作，用于把上传的文件自动同步到C环境部署的fastgpt容器里。 link到fastgpt目录，进入mongo目录，有data目录，下面建backup
mkdir -p /fastgpt/data/backup 准备好后，后续上传
### 新fastgpt环境【B】中也需要建一个，比如/fastgpt/mongobackup目录，注意不要在fastgpt/data目录下建立目录 mkdir -p /fastgpt/mongobackup
###2. 正题开始，从fastgpt老环境【A】中导出数据 进入A环境，使用mongodump 导出mongo数据库。 #### 2.</description></item><item><title>Docker 数据库迁移(无脑操作)</title><link>https://doc.tryfastgpt.ai/docs/development/migration/docker_db/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/migration/docker_db/</guid><description>1. 停止服务 link docker-compose down 2. Copy文件夹 linkDocker 部署数据库都会通过 volume 挂载本地的目录进入容器，如果要迁移，直接复制这些目录即可。
PG 数据: pg/data Mongo 数据: mongo/data
直接把pg 和 mongo目录全部复制走即可。</description></item><item><title>V4.9.5（进行中）</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/495/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/495/</guid><description>🚀 新增内容 link 团队成员权限细分，可分别控制是否可创建在根目录应用/知识库以及 API Key ⚙️ 优化 link🐛 修复 link password 检测规则错误</description></item><item><title>V4.9.4</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/494/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/494/</guid><description>升级指南 link1. 做好数据备份 link2. 安装 Redis link docker 部署的用户，参考最新的 docker-compose.yml 文件增加 Redis 配置。增加一个 redis 容器，并配置fastgpt,fastgpt-pro的环境变量，增加 REDIS_URL 环境变量。 Sealos 部署的用户，在数据库里新建一个redis数据库，并复制内网地址的 connection 作为 redis 的链接串。然后配置fastgpt,fastgpt-pro的环境变量，增加 REDIS_URL 环境变量。 3. 更新镜像 tag link 更新 FastGPT 镜像 tag: v4.9.4 更新 FastGPT 商业版镜像 tag: v4.9.4 Sandbox 无需更新 AIProxy 无需更新 4. 执行升级脚本 link该脚本仅需商业版用户执行。
从任意终端，发起 1 个 HTTP 请求。其中 {{rootkey}} 替换成环境变量里的 rootkey；{{host}} 替换成FastGPT 域名。
curl --location --request POST &amp;#39;https://{{host}}/api/admin/initv494&amp;#39; \ --header &amp;#39;rootkey: {{rootkey}}&amp;#39; \ --header &amp;#39;Content-Type: application/json&amp;#39; 脚本功能</description></item><item><title>V4.9.3</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/493/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/493/</guid><description>更新指南 link1. 做好数据库备份 link2. 更新镜像 link 更新 FastGPT 镜像 tag: v4.9.3 更新 FastGPT 商业版镜像 tag: v4.9.3 Sandbox 镜像tag: v4.9.3 AIProxy 镜像tag: v0.1.5 🚀 新增内容 link 工作流 debug 模式支持交互节点。 代码运行支持 Python3 代码。 🐛 修复 link 工作流格式转化异常。</description></item><item><title>V4.9.2</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/492/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/492/</guid><description>更新指南 link可直接升级v4.9.3，v4.9.2存在一个工作流数据类型转化错误。
1. 做好数据库备份 link2. SSO 迁移 link使用了 SSO 或成员同步的商业版用户，并且是对接钉钉、企微的，需要迁移已有的 SSO 相关配置:
参考：SSO &amp;amp; 外部成员同步中的配置进行sso-service的部署和配置。
先将原商业版后台中的相关配置项复制备份出来（以企微为例，将 AppId, Secret 等复制出来）再进行镜像升级。 参考上述文档，部署 SSO 服务，配置相关的环境变量 如果原先使用企微组织架构同步的用户，升级完镜像后，需要在商业版后台切换团队模式为“同步模式” 3. 配置参数变更 link修改config.json文件中systemEnv.pgHNSWEfSearch参数名，改成hnswEfSearch。
商业版用户升级镜像后，直接在后台系统配置-基础配置中进行变更。
4. 更新镜像 link 更新 FastGPT 镜像 tag: v4.9.2 更新 FastGPT 商业版镜像 tag: v4.9.2 Sandbox 镜像，可以不更新 AIProxy 镜像修改为: registry.cn-hangzhou.aliyuncs.com/labring/aiproxy:v0.1.4 重要更新 link 知识库导入数据 API 变更，增加chunkSettingMode,chunkSplitMode,indexSize可选参数，具体可参考 知识库导入数据 API 文档。 🚀 新增内容 link 知识库分块优化：支持单独配置分块大小和索引大小，允许进行超大分块，以更大的输入 Tokens 换取完整分块。 知识库分块增加自定义分隔符预设值，同时支持自定义换行符分割。 外部变量改名：自定义变量。 并且支持在测试时调试，在分享链接中，该变量直接隐藏。 集合同步时，支持同步修改标题。 团队成员管理重构，抽离主流 IM SSO（企微、飞书、钉钉），并支持通过自定义 SSO 接入 FastGPT。同时完善与外部系统的成员同步。 支持 oceanbase 向量数据库。填写环境变量OCEANBASE_URL即可。 基于 mistral-ocr 的 PDF 解析示例。 基于 miner-u 的 PDF 解析示例。 ⚙️ 优化 link 导出对话日志时，支持导出成员名。 邀请链接交互。 无 SSL 证书时复制失败，会提示弹窗用于手动复制。 FastGPT 未内置 ai proxy 渠道时，也能正常展示其名称。 升级 nextjs 版本至 14.</description></item><item><title>V4.9.1</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/491/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/491/</guid><description>更新指南 link1. 做好数据库备份 link2. 更新镜像 link 更新 FastGPT 镜像 tag: v4.9.1-fix2 更新 FastGPT 商业版镜像 tag: v4.9.1-fix2 Sandbox 镜像，可以不更新 AIProxy 镜像修改为: registry.cn-hangzhou.aliyuncs.com/labring/aiproxy:v0.1.3 3. 执行升级脚本 link从任意终端，发起 1 个 HTTP 请求。其中 {{rootkey}} 替换成环境变量里的 rootkey；{{host}} 替换成FastGPT 域名。
curl --location --request POST &amp;#39;https://{{host}}/api/admin/initv491&amp;#39; \ --header &amp;#39;rootkey: {{rootkey}}&amp;#39; \ --header &amp;#39;Content-Type: application/json&amp;#39; 脚本功能
重新使用最新的 jieba 分词库进行分词处理。时间较长，可以从日志里查看进度。
🚀 新增内容 link 商业版支持单团队模式，更好的管理内部成员。 知识库分块阅读器。 API 知识库支持 PDF 增强解析。 邀请团队成员，改为邀请链接模式。 支持混合检索权重设置。 支持重排模型选择和权重设置，同时调整了知识库搜索权重计算方式，改成 搜索权重 + 重排权重，而不是向量检索权重+全文检索权重+重排权重。会对检索结果有一定影响，可以通过调整相关权重来进行数据适配。 ⚙️ 优化 link 知识库数据输入框交互 应用拉取绑定知识库数据交由后端处理。 增加依赖包安全版本检测，并升级部分依赖包。 模型测试代码。 优化思考过程解析逻辑：只要配置了模型支持思考，均会解析 标签，不会因为对话时，关闭思考而不解析。 载入最新 jieba 分词库，增强全文检索分词效果。 🐛 修复 link 最大响应 tokens 提示显示错误的问题。 HTTP Node 中，字符串包含换行符时，会解析失败。 知识库问题优化中，未传递历史记录。 错误提示翻译缺失。 内容提取节点，array 类型 schema 错误。 模型渠道测试时，实际未指定渠道测试。 新增自定义模型时，会把默认模型字段也保存，导致默认模型误判。 修复 promp 模式工具调用，未判空思考链，导致 UI 错误展示。 编辑应用信息导致头像丢失。 分享链接标题会被刷新掉。 计算 parentPath 时，存在鉴权失败清空。</description></item><item><title>V4.9.0(包含升级脚本)</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/490/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/490/</guid><description>更新指南 link1. 做好数据库备份 link2. 更新镜像和 PG 容器 link 更新 FastGPT 镜像 tag: v4.9.0 更新 FastGPT 商业版镜像 tag: v4.9.0 Sandbox 镜像，可以不更新 更新 PG 容器为 v0.8.0-pg15, 可以查看最新的 yml 3. 替换 OneAPI（可选） link如果需要使用 AI Proxy 替换 OneAPI 的用户可执行该步骤。
1. 修改 yml 文件 link参考最新的 yml 文件。里面已移除 OneAPI 并添加了 AIProxy配置。包含一个服务和一个 PgSQL 数据库。将 aiproxy 的配置追加到 OneAPI 的配置后面（先不要删除 OneAPI，有一个初始化会自动同步 OneAPI 的配置）
AI Proxy Yml 配置 # AI Proxy aiproxy: image: &amp;#39;ghcr.io/labring/aiproxy:latest&amp;#39; container_name: aiproxy restart: unless-stopped depends_on: aiproxy_pg: condition: service_healthy networks: - fastgpt environment: # 对应 fastgpt 里的AIPROXY_API_TOKEN - ADMIN_KEY=aiproxy # 错误日志详情保存时间（小时） - LOG_DETAIL_STORAGE_HOURS=1 # 数据库连接地址 - SQL_DSN=postgres://postgres:aiproxy@aiproxy_pg:5432/aiproxy # 最大重试次数 - RETRY_TIMES=3 # 不需要计费 - BILLING_ENABLED=false # 不需要严格检测模型 - DISABLE_MODEL_CONFIG=true healthcheck: test: [&amp;#39;CMD&amp;#39;, &amp;#39;curl&amp;#39;, &amp;#39;-f&amp;#39;, &amp;#39;http://localhost:3000/api/status&amp;#39;] interval: 5s timeout: 5s retries: 10 aiproxy_pg: image: pgvector/pgvector:0.</description></item><item><title>V4.8.23</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/4823/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/4823/</guid><description>更新指南 link1. 做好数据库备份 link2. 更新镜像： link 更新 fastgpt 镜像 tag: v4.8.23-fix 更新 fastgpt-pro 商业版镜像 tag: v4.8.23-fix Sandbox 镜像无需更新 3. 运行升级脚本 link从任意终端，发起 1 个 HTTP 请求。其中 {{rootkey}} 替换成环境变量里的 rootkey；{{host}} 替换成FastGPT 域名。
curl --location --request POST &amp;#39;https://{{host}}/api/admin/initv4823&amp;#39; \ --header &amp;#39;rootkey: {{rootkey}}&amp;#39; \ --header &amp;#39;Content-Type: application/json&amp;#39; 脚本会清理一些知识库脏数据，主要是多余的全文索引。
🚀 新增内容 link 增加默认“知识库文本理解模型”配置 AI proxy V1版，可替换 OneAPI使用，同时提供完整模型调用日志，便于排查问题。 增加工单入口支持。 ⚙️ 优化 link 模型配置表单，增加必填项校验。 集合列表数据统计方式，提高大数据量统计性能。 优化数学公式，转义 Latex 格式成 Markdown 格式。 解析文档图片，图片太大时，自动忽略。 时间选择器，当天开始时间自动设0，结束设置设 23:59:59，避免 UI 与实际逻辑偏差。 升级 mongoose 库版本依赖。 🐛 修复 link 标签过滤时，子文件夹未成功过滤。 暂时移除 md 阅读优化，避免链接分割错误。 离开团队时，未刷新成员列表。 PPTX 编码错误，导致解析失败。 删除知识库单条数据时，全文索引未跟随删除。 修复 Mongo Dataset text 索引在查询数据时未生效。</description></item><item><title>V4.8.22(包含升级脚本)</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/4822/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/4822/</guid><description>🌟更新指南 link1. 做好数据库备份 link2. 更新镜像： link 更新 fastgpt 镜像 tag: v4.8.22 更新 fastgpt-pro 商业版镜像 tag: v4.8.22 Sandbox 镜像无需更新 3. 运行升级脚本 link仅商业版，并提供 Saas 服务的用户需要运行该升级脚本。
从任意终端，发起 1 个 HTTP 请求。其中 {{rootkey}} 替换成环境变量里的 rootkey；{{host}} 替换成FastGPT 域名。
curl --location --request POST &amp;#39;https://{{host}}/api/admin/initv4822&amp;#39; \ --header &amp;#39;rootkey: {{rootkey}}&amp;#39; \ --header &amp;#39;Content-Type: application/json&amp;#39; 会迁移联系方式到对应用户表中。
🚀 新增内容 link AI 对话节点解析 &amp;lt;think&amp;gt;&amp;lt;/think&amp;gt; 标签内容作为思考链，便于各类模型进行思考链输出。需主动开启模型输出思考。 对话 API 优化，无论是否传递 chatId，都会保存对话日志。未传递 chatId，则随机生成一个 chatId 来进行存储。 ppio 模型提供商 ⚙️ 优化 link 模型未配置时提示，减少冲突提示。 使用记录代码。 内容提取节点，字段描述过长时换行。同时修改其输出名用 key，而不是 description。 团队管理交互。 对话接口，非流响应，增加报错字段。 🐛 修复 link 思考内容未进入到输出 Tokens.</description></item><item><title>V4.8.21</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/4821/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/4821/</guid><description>更新指南 link1. 做好数据库备份 link2. 更新镜像： link 更新 fastgpt 镜像 tag: v4.8.21-fix 更新 fastgpt-pro 商业版镜像 tag: v4.8.21-fix Sandbox 镜像无需更新 完整更新内容 link 新增 - 弃用/已删除的插件提示。 新增 - 对话日志按来源分类、标题检索、导出功能。 新增 - 全局变量支持拖拽排序。 新增 - LLM 模型支持 top_p, response_format, json_schema 参数。 新增 - Doubao1.5 模型预设。阿里 embedding3 预设。 新增 - 向量模型支持归一化配置，以便适配未归一化的向量模型，例如 Doubao 的 embedding 模型。 新增 - AI 对话节点，支持输出思考过程结果，可用于其他节点引用。 优化 - 网站嵌入式聊天窗口，增加窗口位置适配。 优化 - 模型未配置时错误提示。 优化 - 适配非 Stream 模式思考输出。 优化 - 增加 TTS voice 未配置时的空指针保护。 优化 - Markdown 链接解析分割规则，改成严格匹配模式，牺牲兼容多种情况，减少误解析。 优化 - 减少未登录用户的数据获取范围，提高系统隐私性。 修复 - 简易模式，切换到其他非视觉模型时候，会强制关闭图片识别。 修复 - o1,o3 模型，在测试时候字段映射未生效导致报错。 修复 - 公众号对话空指针异常。 修复 - 多个音频/视频文件展示异常。 修复 - 分享链接鉴权报错后无限循环。</description></item><item><title>V4.8.20(包含升级脚本)</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/4820/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/4820/</guid><description>更新指南 link1. 做好数据库备份 link2. 更新环境变量 link如果有很早版本用户，配置了ONEAPI_URL的，需要统一改成OPENAI_BASE_URL
3. 更新镜像： link 更新 fastgpt 镜像 tag: v4.8.20-fix2 更新 fastgpt-pro 商业版镜像 tag: v4.8.20-fix2 Sandbox 镜像无需更新 4. 运行升级脚本 link从任意终端，发起 1 个 HTTP 请求。其中 {{rootkey}} 替换成环境变量里的 rootkey；{{host}} 替换成FastGPT 域名。
curl --location --request POST &amp;#39;https://{{host}}/api/admin/initv4820&amp;#39; \ --header &amp;#39;rootkey: {{rootkey}}&amp;#39; \ --header &amp;#39;Content-Type: application/json&amp;#39; 脚本会自动把原配置文件的模型加载到新版模型配置中。
完整更新内容 link 新增 - 可视化模型参数配置，取代原配置文件配置模型。预设超过 100 个模型配置。同时支持所有类型模型的一键测试。（预计下个版本会完全支持在页面上配置渠道）。点击查看模型配置方案 新增 - DeepSeek resoner 模型支持输出思考过程。 新增 - 使用记录导出和仪表盘。 新增 - markdown 语法扩展，支持音视频（代码块 audio 和 video）。 新增 - 调整 max_tokens 计算逻辑。优先保证 max_tokens 为配置值，如超出最大上下文，则减少历史记录。例如：如果申请 8000 的 max_tokens，则上下文长度会减少 8000。 优化 - 问题优化增加上下文过滤，避免超出上下文。 优化 - 页面组件抽离，减少页面组件路由。 优化 - 全文检索，忽略大小写。 优化 - 问答生成和增强索引改成流输出，避免部分模型超时。 优化 - 自动给 assistant 空 content，补充 null，同时合并连续的 text assistant，避免部分模型抛错。 优化 - 调整图片 Host， 取消上传时补充 FE_DOMAIN，改成发送对话前补充，避免替换域名后原图片无法正常使用。 修复 - 部分场景成员列表无法触底加载。 修复 - 工作流递归执行，部分条件下无法正常运行。</description></item><item><title>V4.8.19(包含升级脚本)</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/4819/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/4819/</guid><description>更新指南 link1. 更新镜像： link 更新 fastgpt 镜像 tag: v4.8.19-beta 更新 fastgpt-pro 商业版镜像 tag: v4.8.19-beta Sandbox 镜像无需更新 2. 运行升级脚本 link从任意终端，发起 1 个 HTTP 请求。其中 {{rootkey}} 替换成环境变量里的 rootkey；{{host}} 替换成FastGPT 域名。
curl --location --request POST &amp;#39;https://{{host}}/api/admin/initv4819&amp;#39; \ --header &amp;#39;rootkey: {{rootkey}}&amp;#39; \ --header &amp;#39;Content-Type: application/json&amp;#39; 迁移用户表的头像到成员表中。
完整更新内容 link 新增 - 工作流知识库检索支持按知识库权限进行过滤。 新增 - 飞书/语雀知识库查看原文。 新增 - 流程等待插件，可以等待 n 毫秒后继续执行流程。 新增 - 飞书机器人接入，支持配置私有化飞书地址。 优化 - 成员列表分页加载。 优化 - 统一分页加载代码。 优化 - 对话页面加载时，可配置是否为独立页面。 优化 - 成员头像迁移，移动到成员表。 修复 - 语雀文件库导入时，嵌套文件内容无法展开的问题。 修复 - 工作流编排中，LLM 参数无法关闭问题。 修复 - 工作流编排中，代码运行节点还原模板问题。 修复 - HTTP 接口适配对象字符串解析。 修复 - 通过 API 上传文件（localFile）接口，图片过期标记未清除。 修复 - 工作流导入编排时，number input 类型无法覆盖。 修复 - 部分模型提供商 logo 无法正常显示。</description></item><item><title>V4.8.18(包含升级脚本)</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/4818/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/4818/</guid><description>更新指南 link1. 更新镜像： link 更新 fastgpt 镜像 tag: v4.8.18-fix 更新 fastgpt-pro 商业版镜像 tag: v4.8.18-fix Sandbox 镜像无需更新 2. 运行升级脚本 link从任意终端，发起 1 个 HTTP 请求。其中 {{rootkey}} 替换成环境变量里的 rootkey；{{host}} 替换成FastGPT 域名。
curl --location --request POST &amp;#39;https://{{host}}/api/admin/initv4818&amp;#39; \ --header &amp;#39;rootkey: {{rootkey}}&amp;#39; \ --header &amp;#39;Content-Type: application/json&amp;#39; 会迁移全文检索表，时间较长，迁移期间全文检索会失效，日志中会打印已经迁移的数据长度。
完整更新内容 link 新增 - 支持通过 JSON 配置直接创建应用。 新增 - 支持通过 CURL 脚本快速创建 HTTP 插件。 新增 - 商业版支持部门架构权限模式。 新增 - 支持配置自定跨域安全策略，默认全开。 新增 - 补充私有部署，模型问题排查文档。 优化 - HTTP Body 增加特殊处理，解决字符串变量带换行时无法解析问题。 优化 - 分享链接随机生成用户头像。 优化 - 图片上传安全校验。并增加头像图片唯一存储，确保不会累计存储。 优化 - Mongo 全文索引表分离。 优化 - 知识库检索查询语句合并，同时减少查库数量。 优化 - 文件编码检测，减少 CSV 文件乱码概率。 优化 - 异步读取文件内容，减少进程阻塞。 优化 - 文件阅读，HTML 直接下载，不允许在线阅读。 修复 - HTML 文件上传，base64 图片无法自动转图片链接。 修复 - 插件计费错误。</description></item><item><title>V4.8.17(包含升级脚本)</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/4817/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/4817/</guid><description>更新指南 link1. 更新镜像： link 更新 fastgpt 镜像 tag: v4.8.17-fix-title 更新 fastgpt-pro 商业版镜像 tag: v4.8.17 Sandbox 镜像无需更新 2. 运行升级脚本 link从任意终端，发起 1 个 HTTP 请求。其中 {{rootkey}} 替换成环境变量里的 rootkey；{{host}} 替换成FastGPT 域名。
curl --location --request POST &amp;#39;https://{{host}}/api/admin/initv4817&amp;#39; \ --header &amp;#39;rootkey: {{rootkey}}&amp;#39; \ --header &amp;#39;Content-Type: application/json&amp;#39; 会将用户绑定的 OpenAI 账号移动到团队中。
调整 completions 接口返回值 link/api/v1/chat/completions 接口返回值调整，对话节点、工具节点等使用到模型的节点，将不再返回 tokens 字段，改为返回 inputTokens 和 outputTokens 字段，分别表示输入和输出的 Token 数量。
完整更新内容 link 新增 - 简易模式工具调用支持数组类型插件。 新增 - 工作流增加异常离开自动保存，避免工作流丢失。 新增 - LLM 模型参数支持关闭 max_tokens 和 temperature。 新增 - 商业版支持后台配置模板市场。 新增 - 商业版支持后台配置自定义工作流变量，用于与业务系统鉴权打通。 新增 - 搜索测试接口支持问题优化。 新增 - 工作流中 Input Token 和 Output Token 分开记录展示。并修复部分请求未记录输出 Token 计费问题。 优化 - Markdown 大小测试，超出 20 万字符不使用 Markdown 组件，避免崩溃。 优化 - 知识库搜索参数，滑动条支持输入模式，可以更精准的控制。 优化 - 可用模型展示UI。 优化 - Mongo 查询语句，增加 virtual 字段。 修复 - 文件返回接口缺少 Content-Length 头，导致通过非同源文件上传时，阿里 vision 模型无法识别图片。 修复 - 去除判断器两端字符串隐藏换行符，避免判断器失效。 修复 - 变量更新节点，手动输入更新内容时候，非字符串类型数据类型无法自动转化。 修复 - 豆包模型无法工具调用。</description></item><item><title>V4.8.16(更新配置文件)</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/4816/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/4816/</guid><description>更新指南 link1. 更新镜像： link 更新 fastgpt 镜像 tag: v4.8.16 更新 fastgpt-pro 商业版镜像 tag: v4.8.16 Sandbox 镜像 tag: v4.8.16 2. 更新配置文件 link参考最新的配置文件，更新 config.json 或 admin 中模型文件配置。给 LLMModel 和 VectorModel 增加 provider 字段，以便进行模型分类。例如：
{ &amp;#34;provider&amp;#34;: &amp;#34;OpenAI&amp;#34;, // 这是新增的 &amp;#34;model&amp;#34;: &amp;#34;gpt-4o&amp;#34;, &amp;#34;name&amp;#34;: &amp;#34;gpt-4o&amp;#34;, &amp;#34;maxContext&amp;#34;: 125000, &amp;#34;maxResponse&amp;#34;: 4000, &amp;#34;quoteMaxToken&amp;#34;: 120000, &amp;#34;maxTemperature&amp;#34;: 1.2, &amp;#34;charsPointsPrice&amp;#34;: 0, &amp;#34;censor&amp;#34;: false, &amp;#34;vision&amp;#34;: true, &amp;#34;datasetProcess&amp;#34;: true, &amp;#34;usedInClassify&amp;#34;: true, &amp;#34;usedInExtractFields&amp;#34;: true, &amp;#34;usedInToolCall&amp;#34;: true, &amp;#34;usedInQueryExtension&amp;#34;: true, &amp;#34;toolChoice&amp;#34;: true, &amp;#34;functionCall&amp;#34;: false, &amp;#34;customCQPrompt&amp;#34;: &amp;#34;&amp;#34;, &amp;#34;customExtractPrompt&amp;#34;: &amp;#34;&amp;#34;, &amp;#34;defaultSystemChatPrompt&amp;#34;: &amp;#34;&amp;#34;, &amp;#34;defaultConfig&amp;#34;: {}, &amp;#34;fieldMap&amp;#34;: {} } 完整更新内容 link 新增 - SearXNG 搜索插件点击查看教程 新增 - 商业版支持 API 知识库和链接集合定时同步。 新增 - 猜你想问支持选择模型和自定义提示词。 新增 - 钉钉和企微机器人 webhook 插件。 新增 - 商业版支持钉钉 SSO 登录配置。点击查看教程 新增 - 商业版支持飞书和语雀知识库导入。点击查看教程 新增 - sandbox 新增 createHmac 加密全局方法。 新增 - 工作流右键支持全部折叠。 优化 - 模型选择器。 优化 - SSR 渲染，预判断是移动端还是 pc 端，减少页面抖动。 优化 - 工作流/简易模式变量初始化代码，去除监听初始化，避免因渲染顺序不一致导致的失败。 优化 - 工作流获取数据类型不一致数据时，增加类型转化，避免 undefined。 修复 - 无法自动切换默认语言。增加分享链接，强制执行一次切换默认语言。 修复 - 数组选择器自动兼容 4.</description></item><item><title>V4.8.15(包含升级脚本)</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/4815/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/4815/</guid><description>新功能预览 linkAPI 知识库 link HTML 渲染 link 源码模式 预览模式 全屏模式 升级指南 link 更新 fastgpt 镜像 tag: v4.8.15-fix3 更新 fastgpt-pro 商业版镜像 tag: v4.8.15 Sandbox 镜像，可以不更新 运行升级脚本 link从任意终端，发起 1 个 HTTP 请求。其中 {{rootkey}} 替换成环境变量里的 rootkey；{{host}} 替换成FastGPT 域名。
curl --location --request POST &amp;#39;https://{{host}}/api/admin/initv4815&amp;#39; \ --header &amp;#39;rootkey: {{rootkey}}&amp;#39; \ --header &amp;#39;Content-Type: application/json&amp;#39; 会重置应用定时执行的字段，把 null 去掉，减少索引大小。
从任意终端，发起 1 个 HTTP 请求。其中 {{rootkey}} 替换成环境变量里的 rootkey；{{host}} 替换成fastgpt-pro域名。
curl --location --request POST &amp;#39;https://{{host}}/api/admin/init/refreshFreeUser&amp;#39; \ --header &amp;#39;rootkey: {{rootkey}}&amp;#39; \ --header &amp;#39;Content-Type: application/json&amp;#39; 重新计算一次免费版用户的时长，之前有版本升级时没有重新计算时间，导致会误发通知。</description></item><item><title>V4.8.14</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/4814/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/4814/</guid><description>更新指南 link1. 做好数据备份 link2. 修改镜像 link 更新 FastGPT 镜像 tag: v4.8.14-fix 更新 FastGPT 商业版镜像 tag: v4.8.14 （fastgpt-pro镜像） Sandbox 镜像，可以不更新 milvus版本使用：v4.8.14-milvus-fix 镜像。
新功能预览 link自动触发工作流 link可以允许你配置用户加载对话时，自动触发一次工作流。可以用于一些 CRM 系统，可以快速的引导用户使用，无需等待用户主动触发。
完整更新内容 link 新增 - 工作流支持进入聊天框/点击开始对话后，自动触发一轮对话。 新增 - 重写 chatContext，对话测试也会有日志，并且刷新后不会丢失对话。 新增 - 分享链接支持配置是否允许查看原文。 新增 - 新的 doc2x 插件。 新增 - 繁体中文。 新增 - 分析链接和 chat api 支持传入自定义 uid。 商业版新增 - 微软 oauth 登录 优化 - 工作流 ui 细节。 优化 - 应用编辑记录采用 diff 存储，避免浏览器溢出。 优化 - 代码入口，增加 register 入口，无需等待首次访问才执行。 优化 - 工作流检查，增加更多缺失值检查。 优化 - 增加知识库训练最大重试次数限制。 优化 - 图片路径问题和示意图任务 优化 - Milvus description 修复 - 分块策略，四级标题会被丢失。 同时新增了五级标题的支持。 修复 - MongoDB 知识库集合唯一索引。 修复 - 反选知识库引用后可能会报错。 修复 - 简易模式转工作流，不是使用最新编辑记录进行转移。 修复 - 表单输入的说明文字不显示。 修复 - API 无法使用 base64 图片。</description></item><item><title>V4.8.13</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/4813/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/4813/</guid><description>更新指南 link1. 做好数据备份 link2. 修改镜像 link 更新 FastGPT 镜像 tag: v4.8.13-fix 更新 FastGPT 商业版镜像 tag: v4.8.13-fix （fastgpt-pro镜像） Sandbox 镜像，可以不更新 3. 添加环境变量 link 给 fastgpt 和 fastgpt-pro 镜像添加环境变量：FE_DOMAIN=http://xx.com，值为 fastgpt 前端访问地址，注意后面不要加/。可以自动补齐相对文件地址的前缀。 4. 调整文件上传编排 link虽然依然兼容旧版的文件上传编排，但是未来两个版本内将会去除兼容代码，请尽快调整编排，以适应最新的文件上传逻辑。尤其是嵌套应用的文件传递，未来将不会自动传递，必须手动指定传递的文件。具体内容可参考: 文件上传变更
更新说明 link 新增 - 数组变量选择支持多选，可以选多个数组或对应的单一数据类型，会自动按选择顺序进行合并。 新增 - 文件上传方案调整，AI对话和工具调用节点直接支持接收文件链接，并且会强制加入提示词，无需由模型决策调用。插件自定义变量支持文件上传类型，取代全局文件。 新增 - 对话记录增加时间显示。 新增 - 工作流校验错误时，跳转至错误节点。 新增 - 循环节点增加下标值。 新增 - 部分对话错误提醒增加翻译。 新增 - 对话输入框支持拖拽文件上传，可直接拖文件到输入框中。 新增 - 对话日志，来源可显示分享链接/API具体名称 新增 - 分享链接支持配置是否展示实时运行状态。 优化 - 合并多个 system 提示词成 1 个，避免部分模型不支持多个 system 提示词。 优化 - 知识库上传文件，优化报错提示。 优化 - 全文检索语句，减少一轮子查询。 优化 - 修改 findLast 为 [&amp;hellip;array].</description></item><item><title>V4.8.12(包含升级脚本)</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/4812/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/4812/</guid><description>更新指南 link1. 做好数据备份 link2. 修改镜像 link 更新 FastGPT 镜像 tag: v4.8.12-fix 更新 FastGPT 管理端镜像 tag: v4.8.12 （fastgpt-pro镜像） Sandbox 镜像，可以不更新 3. 商业版执行初始化 link从任意终端，发起 1 个 HTTP 请求。其中 {{rootkey}} 替换成环境变量里的 rootkey；{{host}} 替换成FastGPT 管理端域名。
curl --location --request POST &amp;#39;https://{{host}}/api/admin/init/4812&amp;#39; \ --header &amp;#39;rootkey: {{rootkey}}&amp;#39; \ --header &amp;#39;Content-Type: application/json&amp;#39; 会初始化应用和知识库的成员组数据。
4. 重构 Milvus 数据 link由于 js int64 精度丢失问题，之前私有化使用 milvus 或者 zilliz 的用户，如果存在数据精度丢失的问题，需要重构 Milvus 数据。（可以查看 dataset_datas 表中，indexes 中的 dataId 是否末尾精度丢失）。使用 PG 的用户不需要操作。
从任意终端，发起 1 个 HTTP 请求。其中 {{rootkey}} 替换成环境变量里的 rootkey；{{host}} 替换成FastGPT 主域名。</description></item><item><title>V4.8.11（商业版初始化）</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/4811/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/4811/</guid><description>更新指南 link1. 做好数据备份 link2. 修改配置文件 link如需增加 openai o1 模型，可添加如下配置：
{ &amp;#34;model&amp;#34;: &amp;#34;o1-mini&amp;#34;, &amp;#34;name&amp;#34;: &amp;#34;o1-mini&amp;#34;, &amp;#34;avatar&amp;#34;: &amp;#34;/imgs/model/openai.svg&amp;#34;, &amp;#34;maxContext&amp;#34;: 125000, &amp;#34;maxResponse&amp;#34;: 65000, &amp;#34;quoteMaxToken&amp;#34;: 120000, &amp;#34;maxTemperature&amp;#34;: 1.2, &amp;#34;charsPointsPrice&amp;#34;: 0, &amp;#34;censor&amp;#34;: false, &amp;#34;vision&amp;#34;: false, &amp;#34;datasetProcess&amp;#34;: true, &amp;#34;usedInClassify&amp;#34;: true, &amp;#34;usedInExtractFields&amp;#34;: true, &amp;#34;usedInToolCall&amp;#34;: true, &amp;#34;toolChoice&amp;#34;: false, &amp;#34;functionCall&amp;#34;: false, &amp;#34;customCQPrompt&amp;#34;: &amp;#34;&amp;#34;, &amp;#34;customExtractPrompt&amp;#34;: &amp;#34;&amp;#34;, &amp;#34;defaultSystemChatPrompt&amp;#34;: &amp;#34;&amp;#34;, &amp;#34;defaultConfig&amp;#34;: { &amp;#34;temperature&amp;#34;: 1 } }, { &amp;#34;model&amp;#34;: &amp;#34;o1-preview&amp;#34;, &amp;#34;name&amp;#34;: &amp;#34;o1-preview&amp;#34;, &amp;#34;avatar&amp;#34;: &amp;#34;/imgs/model/openai.svg&amp;#34;, &amp;#34;maxContext&amp;#34;: 125000, &amp;#34;maxResponse&amp;#34;: 32000, &amp;#34;quoteMaxToken&amp;#34;: 120000, &amp;#34;maxTemperature&amp;#34;: 1.2, &amp;#34;charsPointsPrice&amp;#34;: 0, &amp;#34;censor&amp;#34;: false, &amp;#34;vision&amp;#34;: false, &amp;#34;datasetProcess&amp;#34;: true, &amp;#34;usedInClassify&amp;#34;: true, &amp;#34;usedInExtractFields&amp;#34;: true, &amp;#34;usedInToolCall&amp;#34;: true, &amp;#34;toolChoice&amp;#34;: false, &amp;#34;functionCall&amp;#34;: false, &amp;#34;customCQPrompt&amp;#34;: &amp;#34;&amp;#34;, &amp;#34;customExtractPrompt&amp;#34;: &amp;#34;&amp;#34;, &amp;#34;defaultSystemChatPrompt&amp;#34;: &amp;#34;&amp;#34;, &amp;#34;defaultConfig&amp;#34;: { &amp;#34;temperature&amp;#34;: 1 } } 3.</description></item><item><title>V4.8.10(包含升级脚本)</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/4810/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/4810/</guid><description>更新指南 link1. 做好数据备份 link2. 商业版 —— 修改环境变量 link 需要给fastgpt-pro镜像，增加沙盒的环境变量：SANDBOX_URL=http://xxxxx:3000 给fastgpt-pro镜像和fastgpt镜像增加环境变量，以便更好的存储系统日志： LOG_LEVEL=debug STORE_LOG_LEVEL=warn 3. 修改镜像tag link 更新 FastGPT 镜像 tag: v4.8.10 更新 FastGPT 商业版镜像 tag: v4.8.10 Sandbox 镜像，可以不更新 4. 执行初始化 link从任意终端，发起 1 个 HTTP 请求。其中 {{rootkey}} 替换成环境变量里的 rootkey；{{host}} 替换成FastGPT 域名。
curl --location --request POST &amp;#39;https://{{host}}/api/admin/initv4810&amp;#39; \ --header &amp;#39;rootkey: {{rootkey}}&amp;#39; \ --header &amp;#39;Content-Type: application/json&amp;#39; 初始化发布记录版本标记 初始化开票记录 V4.8.10 更新说明 link完整内容请见：4.8.10 release
新增 - 模板市场。 新增 - 工作流节点拖动自动对齐吸附。 新增 - 用户选择节点（Debug 模式暂未支持）。 新增 - 工作流增加 uid 全局变量。 新增 - 工作流撤销和重做。 新增 - 工作流本次编辑记录，取代自动保存。 新增 - 工作流版本支持重命名。 新增 - 工作流的“应用调用”节点弃用，迁移成单独节点，与插件使用方式相同，同时可以传递全局变量和用户上传的文件。 新增 - 插件增加使用说明配置。 新增 - 插件自定义输入支持单选框。 新增 - HTTP 节点支持 text/plain 模式。 新增 - HTTP模块支持超时配置、支持更多的 Body 类型，params 和 headers 支持新的变量选择模式。 新增 - 工作流导出导入，支持直接导出和导入 JSON 文件，便于交流。 新增 - 发送验证码安全校验。 商业版新增 - 飞书机器人接入。 商业版新增 - 公众号接入接入。 商业版新增 - 自助开票申请。 商业版新增 - SSO 定制。 优化 - 工作流循环校验，避免 skip 循环空转。同时支持分支完全并发执行。 优化 - 工作流嵌套执行，参数可能存在的污染问题。 优化 - 部分全局变量，增加数据类型约束。 优化 - 节点选择，避免切换 tab 时候，path 加载报错。 优化 - 最新 React Markdown 组件，支持 Base64 图片。 优化 - 对话框性能问题。 优化 - 单选框打开后自动滚动到选中的位置。 优化 - 知识库集合禁用，目录禁用会递归修改其下所有 children 的禁用状态。 优化 - SSE 响应代码优化。 优化 - 无 SSL 证书情况下，优化复制。 优化 - 知识库列表 UI。 优化 - 知识库详情页 UI。 优化 - 支持无网络配置情况下运行。 优化 - 调整.</description></item><item><title>V4.8.9（需要初始化）</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/489/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/489/</guid><description>升级指南 link1. 做好数据库备份 link2. 修改镜像 link 更新 FastGPT 镜像 tag: v4.8.9 更新 FastGPT 商业版镜像 tag: v4.8.9 Sandbox 镜像，可以不更新 3. 商业版执行初始化 link从任意终端，发起 1 个 HTTP 请求。其中 {{rootkey}} 替换成环境变量里的 rootkey；{{host}} 替换成FastGPT 商业版域名。
curl --location --request POST &amp;#39;https://{{host}}/api/admin/init/489&amp;#39; \ --header &amp;#39;rootkey: {{rootkey}}&amp;#39; \ --header &amp;#39;Content-Type: application/json&amp;#39; 会初始化多租户的通知方式，仅内部使用的，无需执行。
V4.8.9 更新说明 link 新增 - 文件上传配置，不再依赖视觉模型决定是否可上传图片，而是通过系统配置决定。 新增 - AI 对话节点和工具调用支持选择“是否开启图片识别”，开启后会自动获取对话框上传的图片和“用户问题”中的图片链接。 新增 - 文档解析节点。 商业版新增 - 团队通知账号绑定，用于接收重要信息。 商业版新增 - 知识库集合标签功能，可以对知识库进行标签管理。 商业版新增 - 知识库搜索节点支持标签过滤和创建时间过滤。 商业版新增 - 转移 App owner 权限。 新增 - 删除所有对话引导内容。 新增 - QA 拆分支持自定义 chunk 大小，并优化 gpt4o-mini 拆分时，chunk 太大导致生成内容很少的问题。 优化 - 对话框信息懒加载，减少网络传输。 优化 - 清除选文件缓存，支持重复选择同一个文件。 修复 - 知识库上传文件，网络不稳定或文件较多情况下，进度无法到 100%。 修复 - 删除应用后回到聊天选择最后一次对话的应用为删除的应用时提示无该应用问题。 修复 - 插件动态变量配置默认值时，无法正常显示默认值。 修复 - 工具调用温度和最大回复值未生效。 修复 - 函数调用模式，assistant role 中，GPT 模型必须传入 content 参数。（不影响大部分模型，目前基本都改用用 ToolChoice 模式，FC 模式已弃用）。 修复 - 知识库文件上传进度更新可能异常。 修复 - 知识库 rebuilding 时候，页面总是刷新到第一页。 修复 - 知识库 list openapi 鉴权问题。 修复 - 分享链接，新对话无法反馈。</description></item><item><title>V4.8.8(包含升级脚本)</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/488/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/488/</guid><description>升级指南 link1. 做好数据库备份 link2. 修改镜像 link fastgpt 镜像 tag 修改成 v4.8.8-fix2 商业版镜像 tag 修改成 v4.8.8 3. 执行初始化 link从任意终端，发起 1 个 HTTP 请求。其中 {{rootkey}} 替换成环境变量里的 rootkey；{{host}} 替换成FastGPT 域名。
curl --location --request POST &amp;#39;https://{{host}}/api/admin/initv488&amp;#39; \ --header &amp;#39;rootkey: {{rootkey}}&amp;#39; \ --header &amp;#39;Content-Type: application/json&amp;#39; 会初始化知识库的继承权限
V4.8.8 更新说明 link点击查看完整更新
新增 - 重构系统插件的结构。允许向开源社区 PR 系统插件，具体可见: 如何向 FastGPT 社区提交系统插件。 新增 - DuckDuckGo 系统插件。 新增 - 飞书 webhook 系统插件。 新增 - 修改变量填写方式。提示词输入框以以及工作流中所有 Textarea 输入框，支持输入 / 唤起变量选择，可直接选择所有上游输出值，无需动态引入。 商业版新增 - 知识库权限继承。 优化 - 移动端快速切换应用交互。 优化 - 节点图标。 优化 - 对话框引用增加额外复制案件，便于复制。增加引用内容折叠。 优化 - OpenAI sdk 升级，并自定义了 whisper 模型接口（未仔细查看 sdk 实现，但 sdk 中 whisper 接口，似乎无法适配一般 fastapi 接口） 修复 - Permission 表声明问题。 修复 - 并行执行节点，运行时间未正确记录。 修复 - 运行详情未正确展示嵌套节点信息。 修复 - 简易模式，首次进入，无法正确获取知识库配置。 修复 - Log debug level 配置无效。 修复 - 插件独立运行时，会将插件输入的值进行变量替换，可能导致后续节点变量异常。</description></item><item><title>V4.8.7</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/487/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/487/</guid><description>升级指南 link1. 做好数据库备份 link2. 修改镜像 link fastgpt 镜像 tag 修改成 v4.8.7 商业版镜像 tag 修改成 v4.8.7 V4.8.7 更新说明 link 新增 - 插件支持独立运行，发布和日志查看 新增 - 应用搜索 优化 - 对话框代码 优化 - 升级 Dockerfile node 和 pnpm 版本 优化 - local 域名部署，也可以正常使用 vision 模式 修复 - 简易模式无法变更全局变量 修复 - gpt4o 无法同时使用工具和图片</description></item><item><title>V4.8.6(包含升级脚本)</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/486/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/486/</guid><description>升级指南 link1. 做好数据库备份 link2. 修改镜像 link fastgpt 镜像 tag 修改成 v4.8.6 fastgpt-sandbox 镜像 tag 修改成 v4.8.6 商业版镜像 tag 修改成 v4.8.6 3. 执行初始化 link从任意终端，发起 1 个 HTTP 请求。其中 {{rootkey}} 替换成环境变量里的 rootkey；{{host}} 替换成FastGPT 域名。
curl --location --request POST &amp;#39;https://{{host}}/api/admin/initv486&amp;#39; \ --header &amp;#39;rootkey: {{rootkey}}&amp;#39; \ --header &amp;#39;Content-Type: application/json&amp;#39; 会初始化应用的继承权限
V4.8.6 更新说明 link 新增 - 应用权限继承 新增 - 知识库支持单个集合禁用功能 新增 - 系统插件模式变更，新增链接读取和数学计算器插件，正式版会更新如何自定义系统插件 新增 - 代码沙盒运行参数 新增 - AI对话时隐藏头部的功能，主要是适配移动端 优化 - 文件读取，Mongo 默认使用从节点，减轻主节点压力 优化 - 提示词模板 优化 - Mongo model 重复加载 修复 - 创建链接集合未返回 id 修复 - 文档接口说明 修复 - api system 提示合并 修复 - 团队插件目录内的内容无法加载 修复 - 知识库集合目录面包屑无法加载 修复 - Markdown 导出对话异常 修复 - 提示模板结束标签错误 修复 - 文档描述</description></item><item><title>V4.8.5(包含升级脚本)</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/485/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/485/</guid><description>升级指南 link1. 做好数据库备份 link2. 修改镜像 link fastgpt 镜像 tag 修改成 v4.8.5 商业版镜像 tag 修改成 v4.8.5 3. 执行初始化 link从任意终端，发起 1 个 HTTP 请求。其中 {{rootkey}} 替换成环境变量里的 rootkey；{{host}} 替换成FastGPT 域名。
curl --location --request POST &amp;#39;https://{{host}}/api/admin/initv485&amp;#39; \ --header &amp;#39;rootkey: {{rootkey}}&amp;#39; \ --header &amp;#39;Content-Type: application/json&amp;#39; 会把插件的数据表合并到应用中，插件表不会删除。
商业版用户执行额外的初始化
从任意终端，发起 1 个 HTTP 请求。其中 {{rootkey}} 替换成环境变量里的 rootkey；{{host}} 替换成FastGPT 商业版的域名：
curl --location --request POST &amp;#39;https://{{host}}/api/admin/init/485&amp;#39; \ --header &amp;#39;rootkey: {{rootkey}}&amp;#39; \ --header &amp;#39;Content-Type: application/json&amp;#39; 会重置知识库权限系统。
V4.8.5 更新说明 link 新增 - 合并插件和应用，统一成工作台 新增 - 应用创建副本功能 新增 - 应用创建模板 新增 - 支持代码运行结果作为工具输出。 新增 - Markdown 图片输出，支持移动端放大缩放。 优化 - 原文件编码存取 优化 - 知识库删除后，简易模式会过滤掉删除的知识库，避免错误判断。 优化 - 文件夹读取，支持单个文件夹超出 100 个文件 优化 - 问答拆分/手动录入，当有a字段时，自动将q作为补充索引。 优化 - 对话框页面代码 优化 - 工作流新节点自动增加序号名 修复 - 定时任务无法实际关闭 修复 - 输入引导特殊字符导致正则报错 修复 - 文件包含特殊字符%，且为转义时会导致页面崩溃 修复 - 自定义输入选择知识库引用时页面崩溃</description></item><item><title>V4.8.4(包含升级脚本)</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/484/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/484/</guid><description>升级指南 link1. 修改镜像 link fastgpt 镜像 tag 修改成 v4.8.4 fastgpt-sandbox 镜像 tag 修改成 v4.8.4 (选择性，无变更) 商业版镜像 tag 修改成 v4.8.4 2. 商业版用户执行初始化 link从任意终端，发起 1 个 HTTP 请求。其中 {{rootkey}} 替换成环境变量里的 rootkey；{{host}} 替换成FastGPT 商业版的域名。
curl --location --request POST &amp;#39;https://{{host}}/api/admin/init/484&amp;#39; \ --header &amp;#39;rootkey: {{rootkey}}&amp;#39; \ --header &amp;#39;Content-Type: application/json&amp;#39; V4.8.4 更新说明 link 新增 - 应用使用新权限系统。 新增 - 应用支持文件夹。 优化 - 文本分割增加连续换行、制表符清除，避免大文本性能问题。 重要修复 - 修复系统插件运行池数据污染问题，由于从内存获取，会导致全局污染。 修复 - Debug 模式下，相同 source 和 target 内容，导致连线显示异常。 修复 - 定时执行初始化错误。 修复 - 应用调用传参异常。 修复 - ctrl + cv 复杂节点时，nodeId错误。 调整组件库全局theme。</description></item><item><title>V4.8.3</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/483/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/483/</guid><description>升级指南 link fastgpt 镜像 tag 修改成 v4.8.3 fastgpt-sandbox 镜像 tag 修改成 v4.8.3 商业版镜像 tag 修改成 v4.8.3 V4.8.3 更新说明 link 新增 - 支持 Milvus 数据库， 可参考最新的 docker-compose-milvus.yml. 新增 - 给 chat 接口 empty answer 增加 log，便于排查模型问题。 新增 - ifelse判断器，字符串支持正则。 新增 - 代码运行支持 console.log 输出调试。 修复 - 变量更新在 Debug 模式下出错。</description></item><item><title>V4.8.2</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/482/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/482/</guid><description>Sealos 升级说明 link 在应用管理中新建一个应用，镜像为：registry.cn-hangzhou.aliyuncs.com/fastgpt/fastgpt-sandbox:v4.8.1 无需外网访问地址，端口号为3000 部署完后，复制应用的内网地址 点击变更`FastGPT - 修改环境变量，增加下面的环境变量即可 SANDBOX_URL=内网地址 Docker 部署 link可以拉取最新 docker-compose.yml 文件参考
新增一个容器 sandbox fastgpt 和 fastgpt-pro(商业版) 容器新增环境变量: SANDBOX_URL sandbox 简易不要开启外网访问，未做凭证校验。 V4.8.2 更新说明 link 新增 - js代码运行节点（更完整的type提醒，后续继续完善） 新增 - 内容提取节点支持数据类型选择 修复 - 新增的站点同步无法使用 修复 - 定时任务无法输入内容</description></item><item><title>V4.8.1(包含升级脚本)</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/481/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/481/</guid><description>初始化脚本 link从任意终端，发起 1 个 HTTP 请求。其中 {{rootkey}} 替换成环境变量里的 rootkey；{{host}} 替换成FastGPT的域名。
curl --location --request POST &amp;#39;https://{{host}}/api/admin/initv481&amp;#39; \ --header &amp;#39;rootkey: {{rootkey}}&amp;#39; \ --header &amp;#39;Content-Type: application/json&amp;#39; 由于之前集合名不规范，该初始化会重置表名。请在初始化前，确保 dataset.trainings 表没有数据。 最好更新该版本时，暂停所有进行中业务，再进行初始化，避免数据冲突。
执行脏数据清理 link从任意终端，发起 1 个 HTTP 请求。其中 {{rootkey}} 替换成环境变量里的 rootkey；{{host}} 替换成FastGPT的域名。
curl --location --request POST &amp;#39;https://{{host}}/api/admin/clearInvalidData&amp;#39; \ --header &amp;#39;rootkey: {{rootkey}}&amp;#39; \ --header &amp;#39;Content-Type: application/json&amp;#39; 初始化完后，可以执行这个命令。之前定时清理的定时器有些问题，部分数据没被清理，可以手动执行清理。
V4.8.1 更新说明 link使用 Chat api 接口需要注意，增加了 event: updateVariables 事件，用于更新变量。
点击查看升级说明</description></item><item><title>V4.8</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/48/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/48/</guid><description>新工作流 linkFastGPT workflow V2上线，支持更加简洁的工作流模式。
🤖
由于工作流差异较大，不少地方需要手动重新构建。请依次重建插件和应用
简易尽快更新工作流，避免未来持续迭代后导致无法兼容。
给应用和插件增加了 version 的字段，用于标识是旧工作流还是新工作流。当你更新 4.8 后，保存和新建的工作流均为新版，旧版工作流会有一个重置的弹窗提示。并且，如果是通过 API 和 分享链接 调用的工作流，仍可以正常使用，直到你下次保存它们。
商业版配置更新 link商业版用户如果配置了邮件验证码，需要在管理端 -&amp;gt; 项目配置 -&amp;gt; 登录配置 -&amp;gt; 邮箱登录配置 -&amp;gt; 修改 邮箱服务SMTP地址，之前只能配置别名，现在可以配置自定义的地址。下面是一组别名和实际地址关系：
qq: smtp.qq.com gmail: smtp.gmail.com
V4.8 更新说明 link 重构 - 工作流 新增 - 判断器。支持 if elseIf else 判断。 @newfish-cmyk （preview版本的if else节点需要删除重建） 新增 - 变量更新节点。支持更新运行中工作流输出变量，或更新全局变量。@newfish-cmyk 新增 - 工作流自动保存和版本管理。 新增 - 工作流 Debug 模式，可以调试单个节点或者逐步调试工作流。 新增 - 定时执行应用。可轻松实现定时任务。 新增 - 插件自定义输入优化，可以渲染输入组件。 新增 - 分享链接发送对话前 hook https://github.com/labring/FastGPT/pull/1252 @gaord 优化 - 工作流连线，可以四向连接，方便构建循环工作流。 优化 - 工作流上下文传递，性能🚀。 优化 - ctrl和alt+enter换行，换行符位置不正确。 优化 - chat中存储变量配置。避免修改变量后，影响旧的对话。 优化 - 简易模式，更新配置后自动更新调试框内容，无需保存。 优化 - worker进程管理，并将计算 Token 任务分配给 worker 进程。 优化 - 工具调用支持指定字段数据类型（string, boolean, number） https://github.</description></item><item><title>V4.7.1(包含升级脚本)</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/471/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/471/</guid><description>初始化脚本 link从任意终端，发起 1 个 HTTP 请求。其中 {{rootkey}} 替换成环境变量里的 rootkey；{{host}} 替换成FastGPT的域名。
curl --location --request POST &amp;#39;https://{{host}}/api/admin/clearInvalidData&amp;#39; \ --header &amp;#39;rootkey: {{rootkey}}&amp;#39; \ --header &amp;#39;Content-Type: application/json&amp;#39; 该请求会执行脏数据清理（清理无效的文件、清理无效的图片、清理无效的知识库集合、清理无效的向量）
修改配置文件 link增加了Laf环境配置：点击查看最新的配置文件
V4.7.1 更新说明 link 新增 - 语音输入完整配置。支持选择是否打开语音输入（包括分享页面），支持语音输入后自动发送，支持语音输入后自动语音播放（流式）。 新增 - pptx 和 xlsx 文件读取。但所有文件读取都放服务端，会消耗更多的服务器资源，以及无法在上传时预览更多内容。 新增 - 集成 Laf 云函数，可以读取 Laf 账号中的云函数作为 HTTP 模块。 新增 - 定时器，清理垃圾数据。（采用小范围清理，会清理最近n个小时的，所以请保证服务持续运行，长时间不允许，可以继续执行 clearInvalidData 的接口进行全量清理。） 商业版新增 - 后台配置系统通知。 优化 - 支持ip模式导出知识库。 修改 - csv导入模板，取消 header 校验，自动获取前两列。 修复 - 工具调用模块连线数据类型校验错误。 修复 - 自定义索引输入时，解构数据失败。 修复 - rerank 模型数据格式。 修复 - 问题补全历史记录BUG 修复 - 分享页面特殊情况下加载缓慢问题（由于ssr时候数据库不会触发连接）</description></item><item><title>V4.7（需要初始化）</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/47/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/47/</guid><description>1. 修改配置文件 link增加一些 Boolean 值，用于决定不同功能块可以使用哪些模型，同时增加了模型的 logo：点击查看最新的配置文件
2. 初始化脚本 link升级完镜像后。从任意终端，发起 1 个 HTTP 请求。其中 {{rootkey}} 替换成环境变量里的 rootkey；{{host}} 替换成自己域名
curl --location --request POST &amp;#39;https://{{host}}/api/admin/initv47&amp;#39; \ --header &amp;#39;rootkey: {{rootkey}}&amp;#39; \ --header &amp;#39;Content-Type: application/json&amp;#39; 脚本功能：
初始化插件的 parentId 3. 升级 ReRank 模型 link4.7对ReRank模型进行了格式变动，兼容 cohere 的格式，可以直接使用 cohere 提供的 API。如果是本地的 ReRank 模型，需要修改镜像为：registry.cn-hangzhou.aliyuncs.com/fastgpt/bge-rerank-base:v0.1 。
cohere的重排模型对中文不是很好，感觉不如 bge 的好用，接入教程如下：
申请 Cohere 官方 Key: https://dashboard.cohere.com/api-keys 修改 FastGPT 配置文件 { &amp;#34;reRankModels&amp;#34;: [ { &amp;#34;model&amp;#34;: &amp;#34;rerank-multilingual-v2.0&amp;#34;, // 这里的 model 需要对应 cohere 的模型名 &amp;#34;name&amp;#34;: &amp;#34;检索重排&amp;#34;, // 随意 &amp;#34;requestUrl&amp;#34;: &amp;#34;https://api.</description></item><item><title>V4.6.9(包含升级脚本)</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/469/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/469/</guid><description>修改商业版环境变量 link增加 oneapi 地址和令牌。
OPENAI_BASE_URL=http://oneapi:3000/v1 CHAT_API_KEY=sk-fastgpt 初始化脚本 link从任意终端，发起 1 个 HTTP 请求。其中 {{rootkey}} 替换成环境变量里的 rootkey；{{host}} 替换成自己域名
curl --location --request POST &amp;#39;https://{{host}}/api/admin/initv469&amp;#39; \ --header &amp;#39;rootkey: {{rootkey}}&amp;#39; \ --header &amp;#39;Content-Type: application/json&amp;#39; 重置计量表。 执行脏数据清理（清理无效的文件、清理无效的图片、清理无效的知识库集合、清理无效的向量） 外部接口更新 link 由于计费系统变更，分享链接对话上报接口需要做一些调整，price字段被totalPoints字段取代。inputToken和outputToken不再提供，只提供token字段（总token数量）。 V4.6.9 更新说明 link 商业版新增 - 知识库新增“增强处理”训练模式，可生成更多类型索引。 新增 - 完善了HTTP模块的变量提示。 新增 - HTTP模块支持OpenAI单接口导入。 新增 - 全局变量支持增加外部变量。可通过分享链接的Query或 API 的 variables 参数传入。 新增 - 内容提取模块增加默认值。 优化 - 问题补全。增加英文类型。同时可以设置为单独模块，方便复用。 优化 - 重写了计量模式 优化 - Token 过滤历史记录，保持偶数条，防止部分模型报错。 优化 - 分享链接SEO，可直接展示应用名和头像。 修复 - 标注功能。 修复 - qa生成线程计数错误。 修复 - 问题分类连线类型错误</description></item><item><title>V4.6.8（需要初始化）</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/468/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/468/</guid><description>docker 部署 - 手动更新 Mongo link 修改 docker-compose.yml 的mongo部分，补上command和entrypoint mongo: image: mongo:5.0.18 # image: registry.cn-hangzhou.aliyuncs.com/fastgpt/mongo:5.0.18 # 阿里云 container_name: mongo ports: - 27017:27017 networks: - fastgpt command: mongod --keyFile /data/mongodb.key --replSet rs0 environment: # 这里密码注意要和以前的一致 - MONGO_INITDB_ROOT_USERNAME=username - MONGO_INITDB_ROOT_PASSWORD=password volumes: - ./mongo/data:/data/db entrypoint: - bash - -c - | openssl rand -base64 128 &amp;gt; /data/mongodb.key chmod 400 /data/mongodb.key chown 999:999 /data/mongodb.key echo &amp;#39;const isInited = rs.status().ok === 1 if(!isInited){ rs.initiate({ _id: &amp;#34;rs0&amp;#34;, members: [ { _id: 0, host: &amp;#34;mongo:27017&amp;#34; } ] }) }&amp;#39; &amp;gt; /data/initReplicaSet.</description></item><item><title>V4.6.7（需要初始化）</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/467/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/467/</guid><description>1。执行初始化 API link发起 1 个 HTTP 请求 ({{rootkey}} 替换成环境变量里的 rootkey，{{host}} 替换成自己域名)
https://xxxxx/api/admin/initv467 curl --location --request POST &amp;#39;https://{{host}}/api/admin/initv467&amp;#39; \ --header &amp;#39;rootkey: {{rootkey}}&amp;#39; \ --header &amp;#39;Content-Type: application/json&amp;#39; 初始化说明：
将 images 重新关联到数据集 设置 pg 表的 null 值。 V4.6.7 更新说明 link 修改了知识库UI及新的导入交互方式。 优化知识库和对话的数据索引。 知识库 openAPI，支持通过 API 操作知识库。 新增 - 输入框变量提示。输入 { 号后将会获得可用变量提示。根据社区针对高级编排的反馈，我们计划于 2 月份的版本中，优化变量内容，支持模块的局部变量以及更多全局变量写入。 优化 - 切换团队后会保存记录，下次登录时优先登录该团队。 修复 - API 对话时，chatId 冲突问题。 修复 - Iframe 嵌入网页可能导致的 window.onLoad 冲突。</description></item><item><title>V4.6.6（需要改配置文件）</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/466/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/466/</guid><description>配置文件变更 link为了减少代码重复度，我们对配置文件做了一些修改：点击查看最新的配置文件
商业版变更 link 更新商业版镜像到 4.6.6 版本。
将旧版配置文件中的 SystemParams.pluginBaseUrl 放置到环境变量中:
PRO_URL=商业版镜像地址（此处不再需要以 /api 结尾），例如:
PRO_URL=http://fastgpt-plugin.ns-hsss5d.svc.cluster.local:3000
原本在配置文件中的 FeConfig 已被移除，可以直接打开新的商业版镜像外网地址进行配置。包括 FastGPT 的各个参数和模型都可以直接在商业版镜像中配置，无需再变更 config.json 文件。
V4.6.6 更新说明 link 查看 FastGPT 2024 RoadMap 新增 - Http 模块请求头支持 Json 编辑器。 新增 - ReRank模型部署 新增 - 搜索方式：分离向量语义检索，全文检索和重排，通过 RRF 进行排序合并。 优化 - 问题分类提示词，id引导。测试国产商用 api 模型（百度阿里智谱讯飞）使用 Prompt 模式均可分类。 UI 优化，未来将逐步替换新的UI设计。 优化代码：Icon 抽离和自动化获取。 修复 - 链接读取的数据集，未保存选择器，导致同步时不使用选择器。</description></item><item><title>V4.6.5（需要改配置文件）</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/465/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/465/</guid><description>配置文件变更 link由于 openai 已开始弃用 function call，改为 toolChoice。FastGPT 同步的修改了对于的配置和调用方式，需要对配置文件做一些修改：
点击查看最新的配置文件
主要是修改模型的functionCall字段，改成toolChoice即可。设置为true的模型，会默认走 openai 的 tools 模式；未设置或设置为false的，会走提示词生成模式。 问题优化模型与内容提取模型使用同一组配置。
增加 &amp;quot;ReRankModels&amp;quot;: [] V4.6.5 功能介绍 link 新增 - 问题优化模块 新增 - 文本编辑模块 新增 - 判断器模块 新增 - 自定义反馈模块 新增 - 【内容提取】模块支持选择模型，以及字段枚举 优化 - docx读取，兼容表格（表格转markdown） 优化 - 高级编排连接线交互 优化 - 由于 html2md 导致的 cpu密集计算，阻断线程问题 修复 - 高级编排提示词提取描述</description></item><item><title>V4.6.4(包含升级脚本)</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/464/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/464/</guid><description>1。执行初始化 API link发起 1 个 HTTP 请求 ({{rootkey}} 替换成环境变量里的 rootkey，{{host}} 替换成自己域名)
https://xxxxx/api/admin/initv464 curl --location --request POST &amp;#39;https://{{host}}/api/admin/initv464&amp;#39; \ --header &amp;#39;rootkey: {{rootkey}}&amp;#39; \ --header &amp;#39;Content-Type: application/json&amp;#39; 初始化说明：
初始化 PG 的createTime字段 初始化 Mongo 中 chat 的 feedback 字段 V4.6.4 功能介绍 link 重写 - 分享链接身份逻辑，采用 localID 记录用户的ID。 商业版新增 - 分享链接 SSO 方案，通过身份鉴权地址，仅需3个接口即可完全接入已有用户系统。具体参考分享链接身份鉴权 新增 - 分享链接更多嵌入方式提示，更多DIY方式。 优化 - 历史记录模块。弃用旧的历史记录模块，直接在对应地方填写数值即可。 调整 - 知识库搜索模块 topk 逻辑，采用 MaxToken 计算，兼容不同长度的文本块 调整鉴权顺序，提高 apikey 的优先级，避免cookie抢占 apikey 的鉴权。 链接读取支持多选择器。参考Web 站点同步用法 修复 - 分享链接图片上传鉴权问题 修复 - Mongo 连接池未释放问题。 修复 - Dataset Intro 无法更新 修复 - md 代码块问题 修复 - root 权限问题 优化 docker file</description></item><item><title>V4.6.3(包含升级脚本)</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/463/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/463/</guid><description>1。执行初始化 API link发起 1 个 HTTP 请求 ({{rootkey}} 替换成环境变量里的 rootkey，{{host}} 替换成自己域名)
https://xxxxx/api/admin/initv463 curl --location --request POST &amp;#39;https://{{host}}/api/admin/initv463&amp;#39; \ --header &amp;#39;rootkey: {{rootkey}}&amp;#39; \ --header &amp;#39;Content-Type: application/json&amp;#39; 初始化说明：
初始化Mongo 中 dataset，collection 和 data 的部分字段 V4.6.3 功能介绍 link 商业版新增 - web站点同步 新增 - 集合元数据记录 优化 - url 读取内容 优化 - 流读取文件，防止内存溢出 优化 - 4v模型自动将 url 转 base64，本地也可调试 优化 - 图片压缩等级 修复 - 图片压缩失败报错，防止文件读取过程卡死。</description></item><item><title>V4.6.2(包含升级脚本)</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/462/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/462/</guid><description>1。执行初始化 API link发起 1 个 HTTP 请求 ({{rootkey}} 替换成环境变量里的 rootkey，{{host}} 替换成自己域名)
https://xxxxx/api/admin/initv462 curl --location --request POST &amp;#39;https://{{host}}/api/admin/initv462&amp;#39; \ --header &amp;#39;rootkey: {{rootkey}}&amp;#39; \ --header &amp;#39;Content-Type: application/json&amp;#39; 初始化说明：
初始化全文索引 V4.6.2 功能介绍 link 新增 - 全文索引（需配合 Rerank 模型，在看怎么放到开源版，模型接口比较特殊） 新增 - 插件来源（预计4.7/4.8版本会正式使用） 优化 - PDF读取 优化 - docx文件读取，转成 markdown 并保留其图片内容 修复和优化 TextSplitter 函数</description></item><item><title>V4.6.1</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/461/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/461/</guid><description>V4.6.1 功能介绍 link 新增 - GPT4-v 模型支持 新增 - whisper 语音输入 优化 - TTS 流传输 优化 - TTS 缓存</description></item><item><title>V4.6(包含升级脚本)</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/46/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/46/</guid><description>V4.6 版本加入了简单的团队功能，可以邀请其他用户进来管理资源。该版本升级后无法执行旧的升级脚本，且无法回退。
1。更新镜像并变更配置文件 link更新镜像至 latest 或者 v4.6 版本。商业版镜像更新至 V0.2.1
最新配置可参考：V46 版本最新 config.json，商业镜像配置文件也更新，参考最新的飞书文档。
2。执行初始化 API link发起 2 个 HTTP 请求 ({{rootkey}} 替换成环境变量里的 rootkey，{{host}} 替换成自己域名)
该初始化接口可能速度很慢，返回超时不用管，注意看日志即可，需要注意的是，需确保 initv46 成功后，在执行 initv46-2
https://xxxxx/api/admin/initv46 curl --location --request POST &amp;#39;https://{{host}}/api/admin/initv46&amp;#39; \ --header &amp;#39;rootkey: {{rootkey}}&amp;#39; \ --header &amp;#39;Content-Type: application/json&amp;#39; https://xxxxx/api/admin/initv46-2 curl --location --request POST &amp;#39;https://{{host}}/api/admin/initv46-2&amp;#39; \ --header &amp;#39;rootkey: {{rootkey}}&amp;#39; \ --header &amp;#39;Content-Type: application/json&amp;#39; 初始化内容： 1。创建默认团队 2。初始化 Mongo 所有资源的团队字段 3。初始化 Pg 的字段 4。初始化 Mongo Data
V4.6 功能介绍 link 新增 - 团队空间 新增 - 多路向量 (多个向量映射一组数据) 新增 - tts 语音 新增 - 支持知识库配置文本预处理模型 线上环境新增 - ReRank 向量召回，提高召回精度 优化 - 知识库导出，可直接触发流下载，无需等待转圈圈 4.</description></item><item><title>V4.5.2</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/452/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/452/</guid><description>功能介绍 linkFast GPT V4.5.2 link 新增 - 模块插件，允许自行组装插件进行模块复用。 优化 - 知识库引用提示。</description></item><item><title>V4.5.1(需进行初始化)</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/451/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/451/</guid><description>执行初始化 API link发起 1 个 HTTP 请求（{{rootkey}} 替换成环境变量里的rootkey，{{host}}替换成自己域名）
https://xxxxx/api/admin/initv451 curl --location --request POST &amp;#39;https://{{host}}/api/admin/initv451&amp;#39; \ --header &amp;#39;rootkey: {{rootkey}}&amp;#39; \ --header &amp;#39;Content-Type: application/json&amp;#39; 初始化内容：
rename 数据库字段 初始化 Mongo APP 表中知识库的相关字段 初始化 PG 和 Mongo 的内容，为每个文件创建一个集合（存储 Mongo 中），并反馈赋值给 PG。 该初始化接口可能速度很慢，返回超时不用管，注意看日志即可
功能介绍 linkFast GPT V4.5.1 link 新增知识库文件夹管理 修复了 openai4.x sdk 无法兼容 oneapi 的智谱和阿里的接口。 修复部分模块无法触发完成事件</description></item><item><title>V4.5(需进行较为复杂更新)</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/45/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/45/</guid><description>FastGPT V4.5 引入 PgVector0.5 版本的 HNSW 索引，极大的提高了知识库检索的速度，比起IVFFlat索引大致有3~10倍的性能提升，可轻松实现百万数据毫秒级搜索。缺点在于构建索引的速度非常慢，4c16g 500w 组数据使用并行构建大约花了 48 小时。具体参数配置可参考 PgVector官方
下面需要对数据库进行一些操作升级：
PgVector升级：Sealos 部署方案 link 点击Sealos桌面的数据库应用。 点击【pg】数据库的详情。 点击右上角的重启，等待重启完成。 点击左侧的一键链接，等待打开 Terminal。 依次输入下方 sql 命令 -- 升级插件名 ALTER EXTENSION vector UPDATE; -- 插件是否升级成功，成功的话，vector插件版本为 0.5.0，旧版的为 0.4.1 \dx -- 下面两个语句会设置 pg 在构建索引时可用的内存大小，需根据自身的数据库规格来动态配置，可配置为 1/4 的内存大小 alter system set maintenance_work_mem = &amp;#39;2400MB&amp;#39;; select pg_reload_conf(); -- 重构数据库索引和排序 REINDEX DATABASE postgres; -- 开始构建索引，该索引构建时间非常久，直接点击右上角的叉，退出 Terminal 即可 CREATE INDEX CONCURRENTLY vector_index ON modeldata USING hnsw (vector vector_ip_ops) WITH (m = 16, ef_construction = 64); -- 可以再次点击一键链接，进入 Terminal，输入下方命令，如果看到 &amp;#34;vector_index&amp;#34; hnsw (vector vector_ip_ops) WITH (m=&amp;#39;16&amp;#39;, ef_construction=&amp;#39;64&amp;#39;) 则代表构建完成（注意，后面没有 INVALID） \d modeldata PgVector升级：Docker-compose.</description></item><item><title>V4.4.7（需执行升级脚本）</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/447/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/447/</guid><description>执行初始化 API link发起 1 个 HTTP 请求（{{rootkey}} 替换成环境变量里的rootkey，{{host}}替换成自己域名）
https://xxxxx/api/admin/initv447 curl --location --request POST &amp;#39;https://{{host}}/api/admin/initv447&amp;#39; \ --header &amp;#39;rootkey: {{rootkey}}&amp;#39; \ --header &amp;#39;Content-Type: application/json&amp;#39; 初始化 pg 索引以及将 file_id 中空对象转成 manual 对象。如果数据多，可能需要较长时间，可以通过日志查看进度。
功能介绍 linkFast GPT V4.4.7 link 优化了数据库文件 crud。 兼容链接读取，作为 source。 区分手动录入和标注，可追数据至某个文件。 升级 openai sdk。</description></item><item><title>V4.4.6</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/446/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/446/</guid><description>功能介绍 link 高级编排新增模块 - 应用调用，可调用其他应用。 新增 - 必要连接校验 修复 - 下一步指引在免登录中身份问题。</description></item><item><title>V4.4.5(包含升级脚本)</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/445/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/445/</guid><description>执行初始化 API link发起 1 个 HTTP 请求（记得携带 headers.rootkey，这个值是环境变量里的）
https://xxxxx/api/admin/initv445 curl --location --request POST &amp;#39;https://{{host}}/api/admin/initv445&amp;#39; \ --header &amp;#39;rootkey: {{rootkey}}&amp;#39; \ --header &amp;#39;Content-Type: application/json&amp;#39; 初始化了 variable 模块，将其合并到用户引导模块中。
功能介绍 linkFast GPT V4.4.5 link 新增 - 下一步指引选项，可以通过模型生成 3 个预测问题。 商业版新增 - 分享链接限制及 hook 身份校验（可对接已有的用户系统）。 商业版新增 - Api Key 使用。增加别名、额度限制和过期时间。自带 appId，无需额外连接。 优化 - 全局变量与开场白合并成同一模块。</description></item><item><title>升级到 V4.4.2(包含升级脚本)</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/442/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/442/</guid><description>执行初始化 API link发起 1 个 HTTP 请求 (记得携带 headers.rootkey，这个值是环境变量里的)
https://xxxxx/api/admin/initv442 curl --location --request POST &amp;#39;https://{{host}}/api/admin/initv442&amp;#39; \ --header &amp;#39;rootkey: {{rootkey}}&amp;#39; \ --header &amp;#39;Content-Type: application/json&amp;#39; 会给初始化 Mongo 的 Bill 表的索引，之前过期时间有误。</description></item><item><title>升级到 V4.4.1(包含升级脚本)</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/441/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/441/</guid><description>执行初始化 API link发起 1 个 HTTP 请求（记得携带 headers.rootkey，这个值是环境变量里的）
https://xxxxx/api/admin/initv441 curl --location --request POST &amp;#39;https://{{host}}/api/admin/initv441&amp;#39; \ --header &amp;#39;rootkey: {{rootkey}}&amp;#39; \ --header &amp;#39;Content-Type: application/json&amp;#39; 会给初始化 Mongo 的 dataset.files，将所有数据设置为可用。</description></item><item><title>升级到 V4.4(包含升级脚本)</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/44/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/44/</guid><description>执行初始化 API link发起 1 个 HTTP 请求 (记得携带 headers.rootkey，这个值是环境变量里的)
https://xxxxx/api/admin/initv44 curl --location --request POST &amp;#39;https://{{host}}/api/admin/initv44&amp;#39; \ --header &amp;#39;rootkey: {{rootkey}}&amp;#39; \ --header &amp;#39;Content-Type: application/json&amp;#39; 会给初始化 Mongo 的部分字段。</description></item><item><title>升级到 V4.3(包含升级脚本)</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/43/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/43/</guid><description>执行初始化 API link发起 1 个 HTTP 请求 (记得携带 headers.rootkey，这个值是环境变量里的)
https://xxxxx/api/admin/initv43 curl --location --request POST &amp;#39;https://{{host}}/api/admin/initv43&amp;#39; \ --header &amp;#39;rootkey: {{rootkey}}&amp;#39; \ --header &amp;#39;Content-Type: application/json&amp;#39; 会给 PG 数据库的 modeldata 表插入一个新列 file_id，用于存储文件 ID。
增加环境变量 link增加一个 FILE_TOKEN_KEY 环境变量，用于生成文件预览链接，过期时间为 30 分钟。
FILE_TOKEN_KEY=filetokenkey</description></item><item><title>升级到 V4.2.1</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/421/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/421/</guid><description>私有部署，如果添加了配置文件，需要在配置文件中修改 VectorModels 字段。增加 defaultToken 和 maxToken，分别对应直接分段时的默认 token 数量和该模型支持的 token 上限 (通常不建议超过 3000)
&amp;#34;VectorModels&amp;#34;: [ { &amp;#34;model&amp;#34;: &amp;#34;text-embedding-ada-002&amp;#34;, &amp;#34;name&amp;#34;: &amp;#34;Embedding-2&amp;#34;, &amp;#34;price&amp;#34;: 0, &amp;#34;defaultToken&amp;#34;: 500, &amp;#34;maxToken&amp;#34;: 3000 } ] 改动目的是，我们认为不需要留有选择余地，选择一个最合适的模型去进行任务即可。</description></item><item><title>升级到 V4.2</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/42/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/42/</guid><description>99.9%用户不影响，升级 4.2 主要是修改了配置文件中 QAModel 的格式。从原先的数组改成对象：
&amp;#34;QAModel&amp;#34;: { &amp;#34;model&amp;#34;: &amp;#34;gpt-3.5-turbo-16k&amp;#34;, &amp;#34;name&amp;#34;: &amp;#34;GPT35-16k&amp;#34;, &amp;#34;maxToken&amp;#34;: 16000, &amp;#34;price&amp;#34;: 0 } 改动目的是，我们认为不需要留有选择余地，选择一个最合适的模型去进行任务即可。</description></item><item><title>升级到 V4.1</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/41/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/41/</guid><description>如果您是从旧版本升级到 V4.1，由于新版重新设置了对话存储结构，需要初始化原来的存储内容。
更新环境变量 linkV4.1 优化了 PostgreSQL 和 MongoDB 的连接变量，只需要填 1 个 URL 即可：
注意：/fastgpt 和 /postgres 是指数据库名称，需要和旧版的变量对应。
# mongo 配置，不需要改. 如果连不上，可能需要去掉 ?authSource=admin - MONGODB_URI=mongodb://username:password@mongo:27017/fastgpt?authSource=admin # pg配置. 不需要改 - PG_URL=postgresql://username:password@pg:5432/postgres 初始化 API link部署新版项目，并发起 1 个 HTTP 请求（记得携带 headers.rootkey，这个值是环境变量里的）
https://xxxxx/api/admin/initChatItem</description></item><item><title>升级到 V4.0</title><link>https://doc.tryfastgpt.ai/docs/development/upgrading/40/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/upgrading/40/</guid><description>如果您是从旧版本升级到 V4，由于新版 MongoDB 表变更比较大，需要按照本文档的说明执行一些初始化脚本。
重命名表名 link需要连接上 MongoDB 数据库，执行两条命令：
db.models.renameCollection(&amp;#34;apps&amp;#34;) db.sharechats.renameCollection(&amp;#34;outlinks&amp;#34;) warning 注意：从旧版更新到 V4， MongoDB 会自动创建空表，你需要先手动删除这两个空表，再执行上面的操作。
初始化几个表中的字段 link依次执行下面 3 条命令，时间比较长，不成功可以重复执行（会跳过已经初始化的数据），直到所有数据更新完成。
db.chats.find({appId: {$exists: false}}).forEach(function(item){ db.chats.updateOne( { _id: item._id, }, { &amp;#34;$set&amp;#34;: {&amp;#34;appId&amp;#34;:item.modelId}} ) }) db.collections.find({appId: {$exists: false}}).forEach(function(item){ db.collections.updateOne( { _id: item._id, }, { &amp;#34;$set&amp;#34;: {&amp;#34;appId&amp;#34;:item.modelId}} ) }) db.outlinks.find({shareId: {$exists: false}}).forEach(function(item){ db.outlinks.updateOne( { _id: item._id, }, { &amp;#34;$set&amp;#34;: {&amp;#34;shareId&amp;#34;:item._id.toString(),&amp;#34;appId&amp;#34;:item.modelId}} ) }) 初始化 API link部署新版项目，并发起 3 个 HTTP 请求（记得携带 headers.rootkey，这个值是环境变量里的）
https://xxxxx/api/admin/initv4 https://xxxxx/api/admin/initChat https://xxxxx/api/admin/initOutlink 1 和 2 有可能会因为内存不足挂掉，可以重复执行。</description></item><item><title>OpenAPI 介绍</title><link>https://doc.tryfastgpt.ai/docs/development/openapi/intro/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/openapi/intro/</guid><description>使用说明 linkFasGPT OpenAPI 接口允许你使用 Api Key 进行鉴权，从而操作 FastGPT 上的相关服务和资源，例如：调用应用对话接口、上传知识库数据、搜索测试等等。出于兼容性和安全考虑，并不是所有的接口都允许通过 Api Key 访问。
如何查看 BaseURL link注意：BaseURL 不是接口地址，而是所有接口的根地址，直接请求 BaseURL 是没有用的。
如何获取 Api Key linkFastGPT 的 API Key 有 2 类，一类是全局通用的 key (无法直接调用应用对话)；一类是携带了 AppId 也就是有应用标记的 key (可直接调用应用对话)。
我们建议，仅操作应用或者对话的相关接口使用 应用特定key，其他接口使用 通用key。
通用key 应用特定 key 基本配置 linkOpenAPI 中，所有的接口都通过 Header.Authorization 进行鉴权。
baseUrl: &amp;#34;https://api.fastgpt.in/api&amp;#34; headers: { Authorization: &amp;#34;Bearer {{apikey}}&amp;#34; } 发起应用对话示例
curl --location --request POST &amp;#39;https://api.fastgpt.in/api/v1/chat/completions&amp;#39; \ --header &amp;#39;Authorization: Bearer fastgpt-xxxxxx&amp;#39; \ --header &amp;#39;Content-Type: application/json&amp;#39; \ --data-raw &amp;#39;{ &amp;#34;chatId&amp;#34;: &amp;#34;111&amp;#34;, &amp;#34;stream&amp;#34;: false, &amp;#34;detail&amp;#34;: false, &amp;#34;messages&amp;#34;: [ { &amp;#34;content&amp;#34;: &amp;#34;导演是谁&amp;#34;, &amp;#34;role&amp;#34;: &amp;#34;user&amp;#34; } ] }&amp;#39; 自定义用户 ID linkv4.</description></item><item><title>对话接口</title><link>https://doc.tryfastgpt.ai/docs/development/openapi/chat/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/openapi/chat/</guid><description>如何获取 AppId link可在应用详情的路径里获取 AppId。
发起对话 link 🤖
该接口的 API Key 需使用应用特定的 key，否则会报错。 有些包调用时，BaseUrl需要添加v1路径，有些不需要，如果出现404情况，可补充v1重试。
请求简易应用和工作流 linkv1对话接口兼容GPT的接口！如果你的项目使用的是标准的GPT官方接口，可以直接通过修改BaseUrl和 Authorization来访问 FastGpt 应用，不过需要注意下面几个规则：
🤖
传入的model，temperature等参数字段均无效，这些字段由编排决定，不会根据 API 参数改变。
不会返回实际消耗Token值，如果需要，可以设置detail=true，并手动计算 responseData 里的tokens值。
请求 link 基础请求示例 图片/文件请求示例 参数说明 curl --location --request POST &amp;#39;http://localhost:3000/api/v1/chat/completions&amp;#39; \ --header &amp;#39;Authorization: Bearer fastgpt-xxxxxx&amp;#39; \ --header &amp;#39;Content-Type: application/json&amp;#39; \ --data-raw &amp;#39;{ &amp;#34;chatId&amp;#34;: &amp;#34;my_chatId&amp;#34;, &amp;#34;stream&amp;#34;: false, &amp;#34;detail&amp;#34;: false, &amp;#34;responseChatItemId&amp;#34;: &amp;#34;my_responseChatItemId&amp;#34;, &amp;#34;variables&amp;#34;: { &amp;#34;uid&amp;#34;: &amp;#34;asdfadsfasfd2323&amp;#34;, &amp;#34;name&amp;#34;: &amp;#34;张三&amp;#34; }, &amp;#34;messages&amp;#34;: [ { &amp;#34;role&amp;#34;: &amp;#34;user&amp;#34;, &amp;#34;content&amp;#34;: &amp;#34;导演是谁&amp;#34; } ] }&amp;#39; 仅messages有部分区别，其他参数一致。 目前不支持上传文件，需上传到自己的对象存储中，获取对应的文件链接。 curl --location --request POST &amp;#39;http://localhost:3000/api/v1/chat/completions&amp;#39; \ --header &amp;#39;Authorization: Bearer fastgpt-xxxxxx&amp;#39; \ --header &amp;#39;Content-Type: application/json&amp;#39; \ --data-raw &amp;#39;{ &amp;#34;chatId&amp;#34;: &amp;#34;abcd&amp;#34;, &amp;#34;stream&amp;#34;: false, &amp;#34;messages&amp;#34;: [ { &amp;#34;role&amp;#34;: &amp;#34;user&amp;#34;, &amp;#34;content&amp;#34;: [ { &amp;#34;type&amp;#34;: &amp;#34;text&amp;#34;, &amp;#34;text&amp;#34;: &amp;#34;导演是谁&amp;#34; }, { &amp;#34;type&amp;#34;: &amp;#34;image_url&amp;#34;, &amp;#34;image_url&amp;#34;: { &amp;#34;url&amp;#34;: &amp;#34;图片链接&amp;#34; } }, { &amp;#34;type&amp;#34;: &amp;#34;file_url&amp;#34;, &amp;#34;name&amp;#34;: &amp;#34;文件名&amp;#34;, &amp;#34;url&amp;#34;: &amp;#34;文档链接，支持 txt md html word pdf ppt csv excel&amp;#34; } ] } ] }&amp;#39; info headers.</description></item><item><title>知识库接口</title><link>https://doc.tryfastgpt.ai/docs/development/openapi/dataset/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/openapi/dataset/</guid><description>如何获取知识库ID（datasetId） 如何获取文件集合ID（collection_id） 创建训练订单 link 请求示例 响应示例 新例子
curl --location --request POST &amp;#39;http://localhost:3000/api/support/wallet/usage/createTrainingUsage&amp;#39; \ --header &amp;#39;Authorization: Bearer {{apikey}}&amp;#39; \ --header &amp;#39;Content-Type: application/json&amp;#39; \ --data-raw &amp;#39;{ &amp;#34;datasetId&amp;#34;: &amp;#34;知识库 ID&amp;#34;, &amp;#34;name&amp;#34;: &amp;#34;可选，自定义订单名称，例如：文档训练-fastgpt.docx&amp;#34; }&amp;#39; data 为 billId，可用于添加知识库数据时进行账单聚合。
{ &amp;#34;code&amp;#34;: 200, &amp;#34;statusText&amp;#34;: &amp;#34;&amp;#34;, &amp;#34;message&amp;#34;: &amp;#34;&amp;#34;, &amp;#34;data&amp;#34;: &amp;#34;65112ab717c32018f4156361&amp;#34; } 知识库 link创建一个知识库 link 请求示例 参数说明 响应示例 curl --location --request POST &amp;#39;http://localhost:3000/api/core/dataset/create&amp;#39; \ --header &amp;#39;Authorization: Bearer {{authorization}}&amp;#39; \ --header &amp;#39;Content-Type: application/json&amp;#39; \ --data-raw &amp;#39;{ &amp;#34;parentId&amp;#34;: null, &amp;#34;type&amp;#34;: &amp;#34;dataset&amp;#34;, &amp;#34;name&amp;#34;:&amp;#34;测试&amp;#34;, &amp;#34;intro&amp;#34;:&amp;#34;介绍&amp;#34;, &amp;#34;avatar&amp;#34;: &amp;#34;&amp;#34;, &amp;#34;vectorModel&amp;#34;: &amp;#34;text-embedding-ada-002&amp;#34;, &amp;#34;agentModel&amp;#34;: &amp;#34;gpt-3.</description></item><item><title>分享链接身份鉴权</title><link>https://doc.tryfastgpt.ai/docs/development/openapi/share/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/openapi/share/</guid><description>介绍 link在 FastGPT V4.6.4 中，我们修改了分享链接的数据读取方式，为每个用户生成一个 localId，用于标识用户，从云端拉取对话记录。但是这种方式仅能保障用户在同一设备同一浏览器中使用，如果切换设备或者清空浏览器缓存则会丢失这些记录。这种方式存在一定的风险，因此我们仅允许用户拉取近30天的20条记录。
分享链接身份鉴权设计的目的在于，将 FastGPT 的对话框快速、安全的接入到你现有的系统中，仅需 2 个接口即可实现。该功能目前只在商业版中提供。
使用说明 link免登录链接配置中，你可以选择填写身份验证栏。这是一个POST请求的根地址。在填写该地址后，分享链接的初始化、开始对话以及对话结束都会向该地址的特定接口发送一条请求。下面以host来表示凭身份验证根地址。服务器接口仅需返回是否校验成功即可，不需要返回其他数据，格式如下：
接口统一响应格式 link { &amp;#34;success&amp;#34;: true, &amp;#34;message&amp;#34;: &amp;#34;错误提示&amp;#34;, &amp;#34;msg&amp;#34;: &amp;#34;同message, 错误提示&amp;#34;, &amp;#34;data&amp;#34;: { &amp;#34;uid&amp;#34;: &amp;#34;用户唯一凭证&amp;#34; } } FastGPT 将会判断success是否为true决定是允许用户继续操作。message与msg是等同的，你可以选择返回其中一个，当success不为true时，将会提示这个错误。
uid是用户的唯一凭证，将会用于拉取对话记录以及保存对话记录。可参考下方实践案例。
触发流程 link 配置教程 link1. 配置身份校验地址 link 配置校验地址后，在每次分享链接使用时，都会向对应的地址发起校验和上报请求。
🤖
这里仅需配置根地址，无需具体到完整请求路径。
2. 分享链接中增加额外 query link在分享链接的地址中，增加一个额外的参数: authToken。例如：
原始的链接：https://share.tryfastgpt.ai/chat/share?shareId=648aaf5ae121349a16d62192
完整链接: https://share.tryfastgpt.ai/chat/share?shareId=648aaf5ae121349a16d62192&amp;amp;authToken=userid12345
这个authToken通常是你系统生成的用户唯一凭证（Token之类的）。FastGPT 会在鉴权接口的body中携带 token={{authToken}} 的参数。
3. 编写聊天初始化校验接口 link 请求示例 鉴权成功 鉴权失败 curl --location --request POST &amp;#39;{{host}}/shareAuth/init&amp;#39; \ --header &amp;#39;Content-Type: application/json&amp;#39; \ --data-raw &amp;#39;{ &amp;#34;token&amp;#34;: &amp;#34;{{authToken}}&amp;#34; }&amp;#39; { &amp;#34;success&amp;#34;: true, &amp;#34;data&amp;#34;: { &amp;#34;uid&amp;#34;: &amp;#34;用户唯一凭证&amp;#34; } } 系统会拉取该分享链接下，uid 为 username123 的对话记录。</description></item><item><title>Docker 部署问题</title><link>https://doc.tryfastgpt.ai/docs/faq/docker/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/faq/docker/</guid><description/></item><item><title>私有部署常见问题</title><link>https://doc.tryfastgpt.ai/docs/faq/privatedeploy/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/faq/privatedeploy/</guid><description/></item><item><title>聊天框问题</title><link>https://doc.tryfastgpt.ai/docs/faq/chat/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/faq/chat/</guid><description>我修改了工作台的应用，为什么在“聊天”时没有更新配置？ link应用需要点击发布后，聊天才会更新应用。
浏览器不支持语音输入 link 首先需要确保浏览器、电脑本身麦克风权限的开启。 确认浏览器允许该站点使用麦克风，并且选择正确的麦克风来源。 需有 SSL 证书的站点才可以使用麦克风。</description></item><item><title>应用使用问题</title><link>https://doc.tryfastgpt.ai/docs/faq/app/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/faq/app/</guid><description>多轮对话中如何使连续问题被问题分类节点正确的归类 link问题分类节点具有获取上下文信息的能力，当处理两个关联性较大的问题时，模型的判断准确性往往依赖于这两个问题之间的联系和模型的能力。例如，当用户先问“我该如何使用这个功能？”接着又询问“这个功能有什么限制？”时，模型借助上下文信息，就能够更精准地理解并响应。
但是，当连续问题之间的关联性较小，模型判断的准确度可能会受到限制。在这种情况下，我们可以引入全局变量的概念来记录分类结果。在后续的问题分类阶段，首先检查全局变量是否存有分类结果。如果有，那么直接沿用该结果；若没有，则让模型自行判断。
建议：构建批量运行脚本进行测试，评估问题分类的准确性。
定时执行的时机问题 link系统编排配置中的定时执行，如果用户打开分享的连接，停留在那个页面，定时执行触发问题：
定时执行会在应用发布后生效，会在后台生效。
V4.8.18-FIX2中提到“ 1. 修复 HTTP 节点， {{}} 格式引用变量兼容问题。建议尽快替换 / 模式取变量， {{}} 语法已弃用。”替换{{}}引用格式是仅仅只有在http节点，还是所有节点的都会有影响？ link只有 http 节点用到这个语法。
工作流类型的应用在运行预览可以正常提问返回，但是发布免登录窗口之后有问题。 link一般是没正确发布，在工作流右上角点击【保存并发布】。
如何解决猜你想问使用中文回答显示 link注意需要更新到V4.8.17及以上，把猜你想问的提示词改成中文。 AI对话回答要求中的Markdown语法取消 link修改知识库默认提示词, 默认用的是标准模板提示词，会要求按 Markdown 输出，可以去除该要求：
应用在不同来源效果不一致 linkQ: 应用在调试和正式发布后，效果不一致；在 API 调用时，效果不一致。
A: 通常是由于上下文不一致导致，可以在对话日志中，找到对应的记录，并查看运行详情来进行比对。
在针对知识库的回答要求里有, 要给它配置提示词，不然他就是默认的，默认的里面就有该语法。 工作流操作：一个工作流，以一个问题分类节点开始，根据不同的分类导入到不同的分支，访问相应的知识库和AI对话，AI对话返回内容后，怎么样不进入问题分类节点，而是将问题到知识库搜索，然后把历史记录一起作为背景再次AI查询。 link做个判断器，如果是初次开始对话也就是历史记录为0，就走问题分类；不为零直接走知识库和ai。
实时对话，设置 fastgpt 定时，比如每隔 3000MS 去拿一次 webhook发送过来的消息到AI页面 link定时执行没有这么高频率的去拿信息的，想要实现在企微里面的实时对话的机器人， 目前通过低代码的工作流构建应该是不行的，只能自己写代码，然后去调用 FastGPT 的 APIKey 回复。企业微信似乎没有提供「自动监听」群聊消息的接口（或是通过 at 机器人这种触发消息推送）。应该只能发消息给应用，接收这个 https://developer.work.weixin.qq.com/document/path/90238 文档中的消息推送实现实时对话。或者是定时去拿群聊消息，通过这个文档所示的接口https://developer.work.weixin.qq.com/document/path/98914，然后用这个接口 https://developer.work.weixin.qq.com/document/path/90248 去推送消息。
工作流连接数据库 link工作流提供该连接数据库功能，用这个数据库连接的 plugin 可以实现 text2SQL，但是相对危险，不建议做写入等操作。
关于循环体，协助理解循环体的循环条件和终止条件、循环的方式，循环体内参数调用后、在循环体内属于是局部作用域的参数还是全局作用域的参数 link可理解为 for 函数，传一个数组，每个数据都执行一次。
公式无法正常显示 link添加相关提示词，引导模型按 Markdown 输出公式</description></item><item><title>接入 Marker PDF 文档解析</title><link>https://doc.tryfastgpt.ai/docs/development/custom-models/marker/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/custom-models/marker/</guid><description>背景 linkPDF 是一个相对复杂的文件格式，在 FastGPT 内置的 pdf 解析器中，依赖的是 pdfjs 库解析，该库基于逻辑解析，无法有效的理解复杂的 pdf 文件。所以我们在解析 pdf 时候，如果遇到图片、表格、公式等非简单文本内容，会发现解析效果不佳。
市面上目前有多种解析 PDF 的方法，比如使用 Marker，该项目使用了 Surya 模型，基于视觉解析，可以有效提取图片、表格、公式等复杂内容。
在 FastGPT v4.9.0 版本中，开源版用户可以在config.json文件中添加systemEnv.customPdfParse配置，来使用 Marker 解析 PDF 文件。商业版用户直接在 Admin 后台根据表单指引填写即可。需重新拉取 Marker 镜像，接口格式已变动。
使用教程 link1. 安装 Marker link参考文档 Marker 安装教程，安装 Marker 模型。封装的 API 已经适配了 FastGPT 自定义解析服务。
这里介绍快速 Docker 安装的方法：
docker pull crpi-h3snc261q1dosroc.cn-hangzhou.personal.cr.aliyuncs.com/marker11/marker_images:v0.2 docker run --gpus all -itd -p 7231:7232 --name model_pdf_v2 -e PROCESSES_PER_GPU=&amp;#34;2&amp;#34; crpi-h3snc261q1dosroc.cn-hangzhou.personal.cr.aliyuncs.com/marker11/marker_images:v0.2 2. 添加 FastGPT 文件配置 link { xxx &amp;#34;systemEnv&amp;#34;: { xxx &amp;#34;customPdfParse&amp;#34;: { &amp;#34;url&amp;#34;: &amp;#34;http://xxxx.</description></item><item><title>使用 Xinference 接入本地模型</title><link>https://doc.tryfastgpt.ai/docs/development/custom-models/xinference/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/custom-models/xinference/</guid><description>Xinference 是一款开源模型推理平台，除了支持 LLM，它还可以部署 Embedding 和 ReRank 模型，这在企业级 RAG 构建中非常关键。同时，Xinference 还提供 Function Calling 等高级功能。还支持分布式部署，也就是说，随着未来应用调用量的增长，它可以进行水平扩展。
安装 Xinference linkXinference 支持多种推理引擎作为后端，以满足不同场景下部署大模型的需要，下面会分使用场景来介绍一下这三种推理后端，以及他们的使用方法。
1. 服务器 link如果你的目标是在一台 Linux 或者 Window 服务器上部署大模型，可以选择 Transformers 或 vLLM 作为 Xinference 的推理后端：
Transformers：通过集成 Huggingface 的 Transformers 库作为后端，Xinference 可以最快地 集成当今自然语言处理（NLP）领域的最前沿模型（自然也包括 LLM）。 vLLM: vLLM 是由加州大学伯克利分校开发的一个开源库，专为高效服务大型语言模型（LLM）而设计。它引入了 PagedAttention 算法， 通过有效管理注意力键和值来改善内存管理，吞吐量能够达到 Transformers 的 24 倍，因此 vLLM 适合在生产环境中使用，应对高并发的用户访问。 假设你服务器配备 NVIDIA 显卡，可以参考这篇文章中的指令来安装 CUDA，从而让 Xinference 最大限度地利用显卡的加速功能。
Docker 部署 link你可以使用 Xinference 官方的 Docker 镜像来一键安装和启动 Xinference 服务（确保你的机器上已经安装了 Docker），命令如下：
docker run -p 9997:9997 --gpus all xprobe/xinference:latest xinference-local -H 0.</description></item><item><title>知识库使用问题</title><link>https://doc.tryfastgpt.ai/docs/faq/dataset/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/faq/dataset/</guid><description>上传的文件内容出现中文乱码 link将文件另存为 UTF-8 编码格式。
知识库配置里的文件处理模型是什么？与索引模型有什么区别？ link 文件处理模型：用于数据处理的【增强处理】和【问答拆分】。在【增强处理】中，生成相关问题和摘要，在【问答拆分】中执行问答对生成。 索引模型：用于向量化，即通过对文本数据进行处理和组织，构建出一个能够快速查询的数据结构。 知识库支持Excel类文件的导入 linkxlsx等都可以上传的，不止支持CSV。
知识库tokens的计算方式 link统一按gpt3.5标准。
误删除重排模型后，重排模型怎么加入到fastgpt link config.json文件里面配置后就可以勾选重排模型
线上平台上创建了应用和知识库，到期之后如果短期内不续费，数据是否会被清理。 link免费版是三十天不登录后清空知识库，应用不会动。其他付费套餐到期后自动切免费版。 基于知识库的查询，但是问题相关的答案过多。ai回答到一半就不继续回答。 linkFastGPT回复长度计算公式:
最大回复=min(配置的最大回复（内置的限制），最大上下文（输入和输出的总和）-历史记录)
18K模型-&amp;gt;输入与输出的和
输出增多-&amp;gt;输入减小
所以可以：
检查配置的最大回复（回复上限） 减小输入来增大输出，即减小历史记录，在工作流其实也就是“聊天记录” 配置的最大回复：
另外私有化部署的时候，后台配模型参数，可以在配置最大上文时，预留一些空间，比如 128000 的模型，可以只配置 120000, 剩余的空间后续会被安排给输出
受到模型上下文的限制，有时候达不到聊天记录的轮次，连续对话字数过多就会报上下文不够的错误。 linkFastGPT回复长度计算公式:
最大回复=min(配置的最大回复（内置的限制），最大上下文（输入和输出的总和）-历史记录)
18K模型-&amp;gt;输入与输出的和
输出增多-&amp;gt;输入减小
所以可以：
检查配置的最大回复（回复上限） 减小输入来增大输出，即减小历史记录，在工作流其实也就是“聊天记录” 配置的最大回复：
另外，私有化部署的时候，后台配模型参数，可以在配置最大上文时，预留一些空间，比如 128000 的模型，可以只配置 120000, 剩余的空间后续会被安排给输出。</description></item><item><title>接入外部渠道</title><link>https://doc.tryfastgpt.ai/docs/faq/external_channel_integration/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/faq/external_channel_integration/</guid><description>接入cow，图文对话无法直接显示图片 link 提示词给引导，不要以markdown格式输出。图片需要二开 cow 实现图片链接截取并发送。
可以获取到用户发送问答的记录吗 link 在应用的对话日志里可以查看。</description></item><item><title>报错</title><link>https://doc.tryfastgpt.ai/docs/faq/error/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/faq/error/</guid><description>当前分组上游负载已饱和，请稍后再试(request id:202407100753411462086782835521) link 是oneapi渠道的问题，可以换个模型用or换一家中转站
使用API时在日志中报错Connection Error link 大概率是api-key填写了openapi，然后部署的服务器在国内，不能访问海外的api，可以使用中转或者反代的手段解决访问不到的问题</description></item><item><title>积分消耗</title><link>https://doc.tryfastgpt.ai/docs/faq/points_consumption/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/faq/points_consumption/</guid><description>接入oneapi后，为什么还会消耗fastgpt的积分 link 矢量数据库检索会默认消耗。可以查看看绑定提示和使用记录。</description></item><item><title>其他问题</title><link>https://doc.tryfastgpt.ai/docs/faq/other/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/faq/other/</guid><description>oneapi 官网是哪个 link只有开源的 README，没官网，GitHub: https://github.com/songquanpeng/one-api
想做多用户 link开源版未支持多用户，仅商业版支持。</description></item><item><title>接入 bge-rerank 重排模型</title><link>https://doc.tryfastgpt.ai/docs/development/custom-models/bge-rerank/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/custom-models/bge-rerank/</guid><description>不同模型推荐配置 link推荐配置如下：
模型名 内存 显存 硬盘空间 启动命令 bge-reranker-base &amp;gt;=4GB &amp;gt;=4GB &amp;gt;=8GB python app.py bge-reranker-large &amp;gt;=8GB &amp;gt;=8GB &amp;gt;=8GB python app.py bge-reranker-v2-m3 &amp;gt;=8GB &amp;gt;=8GB &amp;gt;=8GB python app.py 源码部署 link1. 安装环境 link Python 3.9, 3.10 CUDA 11.7 科学上网环境 2. 下载代码 link3 个模型代码分别为：
https://github.com/labring/FastGPT/tree/main/plugins/model/rerank-bge/bge-reranker-base https://github.com/labring/FastGPT/tree/main/plugins/model/rerank-bge/bge-reranker-large https://github.com/labring/FastGPT/tree/main/plugins/model/rerank-bge/bge-reranker-v2-m3 3. 安装依赖 link pip install -r requirements.txt 4. 下载模型 link3个模型的 huggingface 仓库地址如下：
https://huggingface.co/BAAI/bge-reranker-base https://huggingface.co/BAAI/bge-reranker-large https://huggingface.co/BAAI/bge-reranker-v2-m3 在对应代码目录下 clone 模型。目录结构：
bge-reranker-base/ app.py Dockerfile requirements.txt 5. 运行代码 link python app.py 启动成功后应该会显示如下地址：</description></item><item><title>接入 ChatGLM2-6B</title><link>https://doc.tryfastgpt.ai/docs/development/custom-models/chatglm2/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/custom-models/chatglm2/</guid><description>前言 linkFastGPT 允许你使用自己的 OpenAI API KEY 来快速调用 OpenAI 接口，目前集成了 GPT-3.5, GPT-4 和 embedding，可构建自己的知识库。但考虑到数据安全的问题，我们并不能将所有的数据都交付给云端大模型。
那么如何在 FastGPT 上接入私有化模型呢？本文就以清华的 ChatGLM2 为例，为各位讲解如何在 FastGPT 中接入私有化模型。
ChatGLM2-6B 简介 linkChatGLM2-6B 是开源中英双语对话模型 ChatGLM-6B 的第二代版本，具体介绍可参阅 ChatGLM2-6B 项目主页。
warning 注意，ChatGLM2-6B 权重对学术研究完全开放，在获得官方的书面许可后，亦允许商业使用。本教程只是介绍了一种用法，无权给予任何授权！
推荐配置 link依据官方数据，同样是生成 8192 长度，量化等级为 FP16 要占用 12.8GB 显存、int8 为 8.1GB 显存、int4 为 5.1GB 显存，量化后会稍微影响性能，但不多。
因此推荐配置如下：
类型 内存 显存 硬盘空间 启动命令 fp16 &amp;gt;=16GB &amp;gt;=16GB &amp;gt;=25GB python openai_api.py 16 int8 &amp;gt;=16GB &amp;gt;=9GB &amp;gt;=25GB python openai_api.py 8 int4 &amp;gt;=16GB &amp;gt;=6GB &amp;gt;=25GB python openai_api.</description></item><item><title>接入 M3E 向量模型</title><link>https://doc.tryfastgpt.ai/docs/development/custom-models/m3e/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/custom-models/m3e/</guid><description>前言 linkFastGPT 默认使用了 openai 的 embedding 向量模型，如果你想私有部署的话，可以使用 M3E 向量模型进行替换。M3E 向量模型属于小模型，资源使用不高，CPU 也可以运行。下面教程是基于 “睡大觉” 同学提供的一个的镜像。
部署镜像 link镜像名: stawky/m3e-large-api:latest
国内镜像： registry.cn-hangzhou.aliyuncs.com/fastgpt_docker/m3e-large-api:latest 端口号: 6008 环境变量：
# 设置安全凭证（即oneapi中的渠道密钥） 默认值：sk-aaabbbcccdddeeefffggghhhiiijjjkkk 也可以通过环境变量引入：sk-key。有关docker环境变量引入的方法请自寻教程，此处不再赘述。 接入 One API link添加一个渠道，参数如下：
测试 linkcurl 例子：
curl --location --request POST &amp;#39;https://domain/v1/embeddings&amp;#39; \ --header &amp;#39;Authorization: Bearer xxxx&amp;#39; \ --header &amp;#39;Content-Type: application/json&amp;#39; \ --data-raw &amp;#39;{ &amp;#34;model&amp;#34;: &amp;#34;m3e&amp;#34;, &amp;#34;input&amp;#34;: [&amp;#34;laf是什么&amp;#34;] }&amp;#39; Authorization 为 sk-key。model 为刚刚在 One API 填写的自定义模型。
接入 FastGPT link修改 config.json 配置文件，在 vectorModels 中加入 M3E 模型：</description></item><item><title>接入 ChatGLM2-m3e 模型</title><link>https://doc.tryfastgpt.ai/docs/development/custom-models/chatglm2-m3e/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/custom-models/chatglm2-m3e/</guid><description>前言 linkFastGPT 默认使用了 OpenAI 的 LLM 模型和向量模型，如果想要私有化部署的话，可以使用 ChatGLM2 和 m3e-large 模型。以下是由用户@不做了睡大觉 提供的接入方法。该镜像直接集成了 M3E-Large 和 ChatGLM2-6B 模型，可以直接使用。
部署镜像 link 镜像名: stawky/chatglm2-m3e:latest 国内镜像名: registry.cn-hangzhou.aliyuncs.com/fastgpt_docker/chatglm2-m3e:latest 端口号: 6006 # 设置安全凭证（即oneapi中的渠道密钥）
默认值：sk-aaabbbcccdddeeefffggghhhiiijjjkkk
也可以通过环境变量引入：sk-key。有关docker环境变量引入的方法请自寻教程，此处不再赘述。 接入 One API link为 chatglm2 和 m3e-large 各添加一个渠道，参数如下：
这里我填入 m3e 作为向量模型，chatglm2 作为语言模型
测试 linkcurl 例子：
curl --location --request POST &amp;#39;https://domain/v1/embeddings&amp;#39; \
--header &amp;#39;Authorization: Bearer sk-aaabbbcccdddeeefffggghhhiiijjjkkk&amp;#39; \
--header &amp;#39;Content-Type: application/json&amp;#39; \
--data-raw &amp;#39;{
&amp;#34;model&amp;#34;: &amp;#34;m3e&amp;#34;,
&amp;#34;input&amp;#34;: [&amp;#34;laf是什么&amp;#34;]
}&amp;#39; curl --location --request POST &amp;#39;https://domain/v1/chat/completions&amp;#39; \
--header &amp;#39;Authorization: Bearer sk-aaabbbcccdddeeefffggghhhiiijjjkkk&amp;#39; \
--header &amp;#39;Content-Type: application/json&amp;#39; \
--data-raw &amp;#39;{
&amp;#34;model&amp;#34;: &amp;#34;chatglm2&amp;#34;,
&amp;#34;messages&amp;#34;: [{&amp;#34;role&amp;#34;: &amp;#34;user&amp;#34;, &amp;#34;content&amp;#34;: &amp;#34;Hello!</description></item><item><title>使用 Ollama 接入本地模型</title><link>https://doc.tryfastgpt.ai/docs/development/custom-models/ollama/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/custom-models/ollama/</guid><description>Ollama 是一个开源的AI大模型部署工具，专注于简化大语言模型的部署和使用，支持一键下载和运行各种大模型。
安装 Ollama linkOllama 本身支持多种安装方式，但是推荐使用 Docker 拉取镜像部署。如果是个人设备上安装了 Ollama 后续需要解决如何让 Docker 中 FastGPT 容器访问宿主机 Ollama的问题，较为麻烦。
Docker 安装（推荐） link你可以使用 Ollama 官方的 Docker 镜像来一键安装和启动 Ollama 服务（确保你的机器上已经安装了 Docker），命令如下：
docker pull ollama/ollama docker run --rm -d --name ollama -p 11434:11434 ollama/ollama 如果你的 FastGPT 是在 Docker 中进行部署的，建议在拉取 Ollama 镜像时保证和 FastGPT 镜像处于同一网络，否则可能出现 FastGPT 无法访问的问题，命令如下：
docker run --rm -d --name ollama --network （你的 Fastgpt 容器所在网络） -p 11434:11434 ollama/ollama 主机安装 link如果你不想使用 Docker ，也可以采用主机安装，以下是主机安装的一些方式。
MacOS link如果你使用的是 macOS，且系统中已经安装了 Homebrew 包管理器，可通过以下命令来安装 Ollama：</description></item><item><title>Nginx 中转</title><link>https://doc.tryfastgpt.ai/docs/development/proxy/nginx/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/proxy/nginx/</guid><description>登录 Sealos linkSealos
创建应用 link打开 「应用管理」，点击「新建应用」：
填写基本配置 link务必开启外网访问，复制外网访问提供的地址。
添加配置文件 link 复制下面这段配置文件，注意 server_name 后面的内容替换成第二步的外网访问地址。
user nginx; worker_processes auto; worker_rlimit_nofile 51200; events { worker_connections 1024; } http { resolver 8.8.8.8; proxy_ssl_server_name on; access_log off; server_names_hash_bucket_size 512; client_header_buffer_size 64k; large_client_header_buffers 4 64k; client_max_body_size 50M; proxy_connect_timeout 240s; proxy_read_timeout 240s; proxy_buffer_size 128k; proxy_buffers 4 256k; server { listen 80; server_name tgohwtdlrmer.cloud.sealos.io; # 这个地方替换成 Sealos 提供的外网地址 location ~ /openai/(.*) { proxy_pass https://api.openai.com/$1$is_args$args; proxy_set_header Host api.openai.com; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; # 如果响应是流式的 proxy_set_header Connection &amp;#39;&amp;#39;; proxy_http_version 1.</description></item><item><title>HTTP 代理中转</title><link>https://doc.tryfastgpt.ai/docs/development/proxy/http_proxy/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/proxy/http_proxy/</guid><description>如果你有代理工具（例如 Clash 或者 sing-box），也可以使用 HTTP 代理来访问 OpenAI。只需要添加以下两个环境变量即可：
AXIOS_PROXY_HOST= AXIOS_PROXY_PORT= 以 Clash 为例，建议指定 api.openai.com 走代理，其他请求都直连。示例配置如下：
mixed-port: 7890 allow-lan: false bind-address: &amp;#39;*&amp;#39; mode: rule log-level: warning dns: enable: true ipv6: false nameserver: - 8.8.8.8 - 8.8.4.4 cache-size: 400 proxies: - proxy-groups: - { name: &amp;#39;♻️ 自动选择&amp;#39;, type: url-test, proxies: [香港V01×1.5], url: &amp;#39;https://api.openai.com&amp;#39;, interval: 3600} rules: - &amp;#39;DOMAIN-SUFFIX,api.openai.com,♻️ 自动选择&amp;#39; - &amp;#39;MATCH,DIRECT&amp;#39; 然后给 FastGPT 添加两个环境变量：
AXIOS_PROXY_HOST=127.0.0.1 AXIOS_PROXY_PORT=7890</description></item><item><title>Cloudflare Worker 中转</title><link>https://doc.tryfastgpt.ai/docs/development/proxy/cloudflare/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/proxy/cloudflare/</guid><description>参考 &amp;ldquo;不做了睡觉&amp;rdquo; 的教程
workers 配置文件
const TELEGRAPH_URL = &amp;#39;https://api.openai.com&amp;#39;; addEventListener(&amp;#39;fetch&amp;#39;, (event) =&amp;gt; { event.respondWith(handleRequest(event.request)); }); async function handleRequest(request) { // 安全校验 if (request.headers.get(&amp;#39;auth&amp;#39;) !== &amp;#39;auth_code&amp;#39;) { return new Response(&amp;#39;UnAuthorization&amp;#39;, { status: 403 }); } const url = new URL(request.url); url.host = TELEGRAPH_URL.replace(/^https?:\/\//, &amp;#39;&amp;#39;); const modifiedRequest = new Request(url.toString(), { headers: request.headers, method: request.method, body: request.body, redirect: &amp;#39;follow&amp;#39; }); const response = await fetch(modifiedRequest); const modifiedResponse = new Response(response.body, response); // 添加允许跨域访问的响应头 modifiedResponse.</description></item><item><title>数据集</title><link>https://doc.tryfastgpt.ai/docs/development/design/dataset/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/design/dataset/</guid><description>文件与数据的关系 link在 FastGPT 中，文件会通过 MongoDB 的 FS 存储，而具体的数据会通过 PostgreSQL 存储，PG 中的数据会有一列 file_id，关联对应的文件。考虑到旧版本的兼容，以及手动输入、标注数据等，我们给 file_id 增加了一些特殊的值，如下：
manual: 手动输入 mark: 手动标注的数据 注意，file_id 仅在插入数据时会写入，变更时无法修改。
文件导入流程 link 上传文件到 MongoDB 的 FS 中，获取 file_id，此时文件标记为 unused 状态 浏览器解析文件，获取对应的文本和 chunk 给每个 chunk 打上 file_id 点击上传数据：将文件的状态改为 used，并将数据推送到 mongo training 表中等待训练 由训练线程从 mongo 中取数据，并在获取向量后插入到 pg。</description></item><item><title>线上版定价</title><link>https://doc.tryfastgpt.ai/docs/shopping_cart/saas/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/shopping_cart/saas/</guid><description>线上版价格按套餐订阅模式，具体价格和计费请查看（请正确选择版本，账号不互通）：
海外版 国内版</description></item><item><title>商业版</title><link>https://doc.tryfastgpt.ai/docs/shopping_cart/intro/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/shopping_cart/intro/</guid><description>简介 linkFastGPT 商业版是基于 FastGPT 开源版的增强版本，增加了一些独有的功能。只需安装一个商业版镜像，并在开源版基础上填写对应的内网地址，即可快速使用商业版。
功能差异 link 开源版 商业版 线上版 应用管理与高级编排 ✅ ✅ ✅ 文档知识库 ✅ ✅ ✅ 外部使用 ✅ ✅ ✅ API 知识库 ✅ ✅ ✅ 最大应用数量 500 无限制 由付费套餐决定 最大知识库数量（单个知识库内容无限制） 30 无限制 由付费套餐决定 自定义版权信息 ❌ ✅ 设计中 多租户与支付 ❌ ✅ ✅ 团队空间 &amp;amp; 权限 ❌ ✅ ✅ 应用发布安全配置 ❌ ✅ ✅ 内容审核 ❌ ✅ ✅ web站点同步 ❌ ✅ ✅ 主流文档库接入（目前支持：语雀、飞书） ❌ ✅ ✅ 增强训练模式 ❌ ✅ ✅ 第三方应用快速接入（飞书、公众号） ❌ ✅ ✅ 管理后台 ❌ ✅ 不需要 SSO 登录（可自定义，也可使用内置：Github、公众号、钉钉、谷歌等） ❌ ✅ 不需要 图片知识库 ❌ 设计中 设计中 对话日志运营分析 ❌ 设计中 设计中 完整商业授权 ❌ ✅ ✅ 商业版软件价格 linkFastGPT 商业版软件根据不同的部署方式，分为 3 类收费模式。下面列举各种部署方式一些常规内容，如仍有问题，可联系咨询</description></item><item><title>开源协议</title><link>https://doc.tryfastgpt.ai/docs/agreement/open-source/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/agreement/open-source/</guid><description>FastGPT 项目在 Apache License 2.0 许可下开源，但包含以下附加条件：
FastGPT 允许被用于商业化，例如作为其他应用的“后端即服务”使用，或者作为应用开发平台提供给企业。然而，当满足以下条件时，必须联系作者获得商业许可：
多租户 SaaS 服务：除非获得 FastGPT 的明确书面授权，否则不得使用 tryfastgpt.ai 的源码来运营与 tryfastgpt.ai 服务类似的多租户 SaaS 服务。 LOGO 及版权信息：在使用 FastGPT 的过程中，不得移除或修改 FastGPT 控制台内的 LOGO 或版权信息。 请通过电子邮件 yujinlong@sealos.io 联系我们咨询许可事宜。
作为贡献者，你必须同意将你贡献的代码用于以下用途：
生产者有权将开源协议调整为更严格或更宽松的形式。 可用于商业目的，例如 FastGPT 的云服务。 除此之外，所有其他权利和限制均遵循 Apache License 2.0。如果你需要更多详细信息，可以参考 Apache License 2.0 的完整版本。本产品的交互设计受到外观专利保护。© 2023 Sealos.</description></item><item><title>服务协议</title><link>https://doc.tryfastgpt.ai/docs/agreement/terms/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/agreement/terms/</guid><description>最后更新时间：2024年3月3日
FastGPT 服务协议是您与珠海环界云计算有限公司（以下简称“我们”或“本公司”）之间就FastGPT云服务（以下简称“本服务”）的使用等相关事项所订立的协议。请您仔细阅读并充分理解本协议各条款，特别是免除或者限制我们责任的条款、对您权益的限制条款、争议解决和法律适用条款等。如您不同意本协议任一内容，请勿注册或使用本服务。
第1条 服务内容
我们将向您提供存储、计算、网络传输等基于互联网的信息技术服务。 我们将不定期向您通过站内信、电子邮件或短信等形式向您推送最新的动态。 我们将为您提供相关技术支持和客户服务，帮助您更好地使用本服务。 我们将为您提供稳定的在线服务，保证每月服务可用性不低于99%。 第2条 用户注册与账户管理
您在使用本服务前需要注册一个账户。您保证在注册时提供的信息真实、准确、完整，并及时更新。 您应妥善保管账户名和密码，对由此产生的全部行为负责。如发现他人使用您的账户，请及时修改账号密码或与我们进行联系。 我们有权对您的账户进行审查，如发现您的账户存在异常或违法情况，我们有权暂停或终止向您提供服务。 第3条 使用规则
您不得利用本服务从事任何违法活动或侵犯他人合法权益的行为，包括但不限于侵犯知识产权、泄露他人商业机密等。 您不得通过任何手段恶意注册账户，包括但不限于以牟利、炒作、套现等目的。 您不得利用本服务传播任何违法、有害、恶意软件等信息。 您应遵守相关法律法规及本协议的规定，对在本服务中发布的信息及使用本服务所产生的结果承担全部责任。 我们禁止使用我们对接的模型服务生成可能对个人或社会造成伤害的内容。保障平台的安全性，是长期稳定运营的关键。如发现任何利用平台接入模型能力进行违规内容生成和使用，将立即封号，账号余额不退。违规内容包括但不限于： 剥削和虐待 禁止描述、展示或宣扬儿童性剥削或性虐待的内容，无论法律是否禁止。这包括涉及儿童或使儿童色情的内容。 禁止描述或用于培养儿童的内容。修饰是成年人以剥削，特别是性剥削为目的与儿童建立关系的行为。这包括以性剥削、贩运或其他形式剥削为目的与儿童交流。 未经同意的私密内容 服务禁止描述、提供或宣传未经同意的亲密活动的内容。 禁止描述、提供特征或宣传或用于招揽商业性活动和性服务的内容。这包括鼓励和协调真正的性活动。 禁止描述或用于人口贩运目的的内容。这包括招募人员、便利交通、支付和助长对人的剥削，如强迫劳动、家庭奴役、役、强迫婚姻和强迫医疗程序。 自杀和自残，禁止描述、赞美、支持、促进、美化、鼓励和/或指导个人自残或自杀的内容。 暴力内容和行为 禁止描述、展示或宣扬血腥暴力或血腥的内容。 禁止描绘恐怖主义行为的内容；赞扬或支持恐怖组织、恐怖行为者或暴力恐怖意识形态；鼓励恐怖活动；向恐怖组织或恐怖事业提供援助；或协助恐怖组织招募成员。 禁止通过暴力威胁或煽动来鼓吹或宣扬对他人的暴力行为的内容。 仇恨言论和歧视 禁止基于实际或感知的种族、民族、国籍、性别、性别认同、性取向、宗教信仰、年龄、残疾状况、种姓或与系统性偏见或边缘化相关的任何其他特征等特征攻击、诋毁、恐吓、降级、针对或排斥个人或群体的内容。 禁止针对个人或群体进行威胁、恐吓、侮辱、贬低或贬低的语言或图像、宣扬身体伤害或其他虐待行为（如跟踪）的内容。 禁止故意欺骗并可能对公共利益产生不利影响的内容，包括与健康、安全、选举诚信或公民参与相关的欺骗性或不真实内容。 直接支持非法主动攻击或造成技术危害的恶意软件活动的内容，例如提供恶意可执行文件、组织拒绝服务攻击或管理命令和控制服务器。 第4条 费用及支付
您同意支付与本服务相关的费用，具体费用标准以我们公布的价格为准。 我们可能会根据运营成本和市场情况调整费用标准。最新价格以您付款时刻的价格为准。 第5条 服务免责与责任限制
本服务按照现有技术和条件所能达到的水平提供。我们不能保证本服务完全无故障或满足您的所有需求。 对于因您自身误操作导致的数据丢失、损坏等情况，我们不承担责任。 由于生成式 AI 的特性，其在不同国家的管控措施也会有所不同，请所有使用者务必遵守所在地的相关法律。如果您以任何违反 FastGPT 可接受使用政策的方式使用，包括但不限于法律、法规、政府命令或法令禁止的任何用途，或任何侵犯他人权利的使用；由使用者自行承担。我们对由客户使用产生的问题概不负责。下面是各国对生成式AI的管控条例的链接： 中国生成式人工智能服务管理办法（征求意见稿）
第6条 知识产权
我们对本服务及相关软件、技术、文档等拥有全部知识产权，除非经我们明确许可，您不得进行复制、分发、出租、反向工程等行为。 您在使用本服务过程中产生的所有数据和内容（包括但不限于文件、图片等）的知识产权归您所有。我们不会对您的数据和内容进行使用、复制、修改等行为。 在线服务中其他用户的数据和内容的知识产权归原用户所有，未经原用户许可，您不得进行使用、复制、修改等行为。 第7条 其他条款
如本协议中部分条款因违反法律法规而被视为无效，不影响其他条款的效力。 本公司保留对本协议及隐私政策的最终解释权。如您对本协议或隐私政策有任何疑问，请联系我们：yujinlong@sealos.io。</description></item><item><title>隐私政策</title><link>https://doc.tryfastgpt.ai/docs/agreement/privacy/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/agreement/privacy/</guid><description>最后更新时间：2024年3月3日
我们非常重视您的隐私保护，在您使用FastGPT云服务时(以下简称为“本服务”)，我们将按照以下政策收集、使用、披露和保护您的个人信息。请您仔细阅读并充分理解本隐私政策。
我们可能需要收集的信息
在您注册或使用本服务时，我们可能收集您的姓名、电话号码、电子邮件地址、地址等个人信息。 在您使用本服务过程中产生的信息，如操作日志、访问IP地址、设备型号等。 我们可能会通过 Cookies 或其他技术收集和存储您访问本服务的相关信息，以便为您提供更好的用户体验。 我们如何使用收集的信息？
我们会根据法律法规规定以及与用户之间的约定来处理用户的个人信息。 我们可能会将收集到的信息用于改进服务质量、开发新产品或功能等目的。 我们可能会将收集到的信息用于向您推送与本服务相关的通知或广告。 信息披露
我们不会向任何第三方披露您的个人信息，除非：
您事先同意； 法律法规要求； 为维护我们或其他用户的合法权益。 我们可能与关联公司、合作伙伴分享您的个人信息，但我们会采取相应的保密措施，确保信息安全。
信息保护
我们采取各种安全措施，包括加密、访问控制等技术手段，以保护您的个人信息免受未经授权的访问、使用或泄露。 我们会定期对收集、存储和处理的个人信息进行安全评估，以确保个人信息安全。 在发生个人信息泄露等安全事件时，我们会立即启动应急预案，并在法律法规规定的范围内向您及时告知。 我们不会使用您的数据进行额外的备份存储或用于模型训练。 您在本服务进行的数据删除均为物理删除，不可恢复。如有非物理删除的操作，我们会在服务中特别指出。 用户权利
您有权随时查阅、更正或删除您的个人信息。 您有权拒绝我们收集您的个人信息，但这可能导致您无法使用本服务的部分功能。 您有权要求我们停止处理您的个人信息，但这可能导致您无法继续使用本服务。 隐私政策更新
我们可能会对本隐私政策进行修改。如本隐私政策发生变更，我们将在本服务页面上发布修改后的隐私政策。如您继续使用本服务，则视为同意修改后的隐私政策。 我们鼓励您定期查阅本隐私政策，以了解我们如何保护您的个人信息。 未成年人保护
我们非常重视对未成年人个人信息的保护，如您为未成年人，请在监护人指导下使用本服务，并请监护人帮助您在使用本服务过程中正确处理个人信息。
跨境数据传输
由于我们的服务器可能位于不同国家或地区，您同意我们可能需要将您的个人信息传输至其他国家或地区，并在该等国家或地区存储和处理以向您提供服务。我们会采取适当措施确保跨境传输的数据仍然受到适当保护。
联系我们
如您对本隐私政策有任何疑问、建议或投诉，请通过以下方式与我们联系：yujinlong@sealos.io。 我们将尽快回复并解决您提出的问题。</description></item><item><title>加入社区</title><link>https://doc.tryfastgpt.ai/docs/community/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/community/</guid><description>FastGPT 是一个由用户和贡献者参与推动的开源项目，如果您对产品使用存在疑问和建议，可尝试以下方式寻求支持。我们的团队与社区会竭尽所能为您提供帮助。
📱 扫码加入社区微信交流群👇
🐞 请将任何 FastGPT 的 Bug、问题和需求提交到 GitHub Issue。</description></item></channel></rss>